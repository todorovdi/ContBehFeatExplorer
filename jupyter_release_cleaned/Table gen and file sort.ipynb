{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting to sens,spec table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import globvars as gv\n",
    "import utils\n",
    "import utils_tSNE as utsne\n",
    "import utils_preproc as upre\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import mne\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import multiprocessing as mpr\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "import gc;\n",
    "import scipy.signal as sig\n",
    "import pandas as pd \n",
    "\n",
    "import numpy as np\n",
    "import utils_postprocess as upost\n",
    "\n",
    "data_dir = gv.data_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fname_full = os.path.join(data_dir, 'S02_off_hold_resample_notch_highpass_raw.fif')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdelta.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_subj_info = gv.gen_subj_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawnames =   ['S01_off_hold', 'S01_off_move'] + ['S01_on_hold', 'S01_on_move']\n",
    "rawnames +=  ['S02_off_hold', 'S02_off_move'] + ['S02_on_hold', 'S02_on_move'] \n",
    "rawnames +=  ['S03_off_hold', 'S03_off_move']\n",
    "rawnames +=  ['S04_off_hold', 'S04_off_move'] + ['S04_on_hold', 'S04_on_move'] \n",
    "rawnames +=  ['S05_off_hold', 'S05_off_move'] + ['S05_on_hold', 'S05_on_move'] \n",
    "rawnames +=  ['S07_off_hold', 'S07_off_move'] + ['S07_on_hold', 'S07_on_move'] \n",
    "\n",
    "rawnames = rawnames[::2] # we have joined them anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawnames =   ['S01_off_hold']\n",
    "rawnames +=  ['S02_off_hold'] \n",
    "rawnames +=  ['S04_off_hold'] \n",
    "rawnames +=  ['S07_off_hold'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawnames =   ['S01_off_hold']\n",
    "rawnames +=  ['S02_off_hold'] \n",
    "rawnames +=  ['S03_off_hold']\n",
    "rawnames +=  ['S04_off_hold'] \n",
    "rawnames +=  ['S05_off_hold'] \n",
    "rawnames +=  ['S07_off_hold'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawnames =   ['S01_off_hold', 'S01_off_move'] + ['S01_on_hold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawnames =  ['S01_off_hold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawnames =  ['S99_off_hold', 'S99_off_move']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawnames = ['S01_off_hold', 'S02_off_hold', 'S02_on_hold', \n",
    "#             'S03_off_hold', 'S04_off_hold', 'S04_on_hold',\n",
    "#            'S05_off_hold', 'S05_on_hold', 'S07_off_hold'] #,'S01_on_hold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = ['all',\n",
    "'allb_trem',    \n",
    "'allb_beta',    \n",
    "'allb_gamma',   \n",
    "'allb_trembeta',\n",
    "'allnoHFO',\n",
    "'modLFP',\n",
    "'modLFPnoHFO',\n",
    "'modSrc',\n",
    "'onlyTD',\n",
    "'onlyFD',\n",
    "'conH',\n",
    "'onlyH',\n",
    "'onlyBpcorr',\n",
    "'onlyBpcorrNoHFO',\n",
    "'onlyRbcorr',\n",
    "'onlyCon',\n",
    "'onlyConNoHFO',\n",
    "'LFPrel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = ['all',\n",
    "'allb_trem',    \n",
    "'allb_beta',    \n",
    "'allb_gamma',   \n",
    "'modLFP',\n",
    "'modSrc',\n",
    "'modSrc_self',\n",
    "'onlyMotorSrc',\n",
    "'onlyRestSrc', \n",
    "'onlyCBSrc'    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = ['all',\n",
    "'allb_trem',    \n",
    "'allb_beta',    \n",
    "'allb_gamma',  \n",
    "'allb_HFO',\n",
    "'modLFP',\n",
    "'modSrc',\n",
    "'modSrc_self',\n",
    "'LFPrel_noself',\n",
    "'LFPrel_noself_onlyCon',            \n",
    "'LFPrel_noself_onlyRbcorr',            \n",
    "'LFPrel_noself_onlyBpcorr',                        \n",
    "'onlyTD', 'onlyFD', 'allb_trembeta',\n",
    "'onlyMotorSrc','onlyRestSrc','onlyCBSrc' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawnames = ['S01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#%debug\n",
    "#label_types = ['allsep', 'trem_vs_all', 'trem_vs_quiet']\n",
    "#label_types = ['allsep']\n",
    "\n",
    "nraws_used_PCA = 2\n",
    "\n",
    "set_explicit_nraws_used_PCA = 1\n",
    "set_explicit_n_feats_PCA = 0\n",
    "set_explicit_dim_PCA = 0\n",
    "\n",
    "\n",
    "\n",
    "sources_type = 'parcel_aal'  # or ''\n",
    "\n",
    "try:\n",
    "    print(output_per_raw.keys() )\n",
    "except (NameError,AttributeError) as e:\n",
    "    output_per_raw = None\n",
    "    \n",
    "#subdir='SSS'\n",
    "subdir =''\n",
    "#%debug\n",
    "r = upost.collectPerformanceInfo(rawnames,prefixes,                                                                                                   \n",
    "                                          sources_type = sources_type, \n",
    "                                           printFilenames=1,                                 \n",
    "                                                         ndays_before=20,\n",
    "                                             subdir=subdir, old_file_format=1)\n",
    "output_per_raw,Ximp_per_raw,gis_per_raw = r\n",
    "\n",
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_per_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_per_raw['S01_off_hold'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '()' by default means grouping (functional)\n",
    "import re\n",
    "r = re.match('.*\\+.+\\((\\d+)\\)','  fdsfd+f (5454)')\n",
    "print(r)\n",
    "print( r.groups() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.regs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_S01_parcel_aal_grp10-0_modSrc_short_ML_nr1_7chs_nfeats612_pcadim268_skip32_wsz256__(merge_all_not_trem,trem_vs_quiet).npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ximp_per_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_per_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Collect feature numbers\n",
    "feat_nums_perraw0 = {}\n",
    "feat_nums_perraw = {}\n",
    "feat_nums_red_perraw = {}\n",
    "for rn in output_per_raw:\n",
    "    #feat_nums_perprefix = {}\n",
    "    feat_nums0 = {}\n",
    "    feat_nums_per_prefix = {}\n",
    "    feat_nums_red_per_prefix = {}\n",
    "    for prefix,pg in output_per_raw[rn].items():        \n",
    "        feat_nums_red_pgs = {}\n",
    "        feat_nums_pgs = {}\n",
    "        for g,pitset in pg.items():\n",
    "            if g == 'feature_names_filtered':\n",
    "                continue            \n",
    "            for it_set,lda_output in pitset.items():                \n",
    "                if lda_output is None:\n",
    "                    continue\n",
    "                lda_anver = lda_output['lda_analysis_versions']\n",
    "                nfeats = len( lda_anver['all_present_features']['CV_aver']['ldaobj'].scalings_ )\n",
    "                siXGB = lda_output.get('strong_inds_XGB',None )\n",
    "                if siXGB is not None:\n",
    "                    nfeats_red_XGB = len(  siXGB )\n",
    "                else:\n",
    "                    nfeats_red_XGB = -1\n",
    "                #X = lda_output['transformed_imputed_CV']                \n",
    "                #nfeats = len( lda_output['MI_per_Feati'].feature_importances_ )\n",
    "                #if 'XGBobj' in lda_output:\n",
    "                #    nfeats = len( lda_output['XGBobj'].feature_importances_ )\n",
    "                #else:\n",
    "                #print(rn,prefix,g,it_set,X.shape)\n",
    "                #n = feat_nums.get(prefix,-1)\n",
    "#                 if n >= 0:\n",
    "#                     assert nfeats == n, (nfeats,n)\n",
    "#                 else:\n",
    "#                     nfeats = -1\n",
    "                    \n",
    "                feat_nums0[prefix] = nfeats\n",
    "                feat_nums_pgs[(g,it_set)] = nfeats\n",
    "                feat_nums_red_pgs[(g,it_set)] = nfeats_red_XGB\n",
    "        feat_nums_red_per_prefix[prefix] = feat_nums_red_pgs\n",
    "        feat_nums_per_prefix[prefix] = feat_nums_pgs\n",
    "        #feat_nums_perprefix[prefix ] = feat_nums\n",
    "    feat_nums_perraw0[rn] = feat_nums0\n",
    "    feat_nums_perraw[rn] = feat_nums_per_prefix\n",
    "    feat_nums_red_perraw[rn] = feat_nums_red_per_prefix\n",
    "\n",
    "#feat_nums_perraw\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "     \n",
    "\n",
    "# prefix_labels_perraw = {}\n",
    "# for rawn in output_per_raw:\n",
    "#     ks = list( feat_nums_perraw[rawn].keys() )\n",
    "#     labs = ['{}:{}'.format(prefix,feat_nums_perraw[rawn][prefix] ) \\\n",
    "#             for prefix in ks ]\n",
    "#     prefix_labels_perraw[rawn] = dict(zip(ks,labs))\n",
    "# print( prefix_labels_perraw )\n",
    "\n",
    "# prefix_labels_all_appeared = set()\n",
    "# for rn,plp in prefix_labels_perraw.items():\n",
    "#     prefix_labels_all_appeared.update(plp)\n",
    "# # has wrong sort\n",
    "# prefix_labels_all_appeared = list(sorted(prefix_labels_all_appearaed))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_nums_perraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_nums_red_perraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_output.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of sens,spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_show = [('allsep','merge_nothing','basic'), ('trem_vs_all','merge_all_not_trem','basic'),\n",
    "        ('trem_vs_quiet','merge_all_not_trem','trem_vs_quiet')]\n",
    "\n",
    "to_show = [('allsep','merge_nothing','basic'),\n",
    "           ('trem_vs_quiet','merge_nothing','trem_vs_quiet'),\n",
    "           ('trem_vs_all','merge_all_not_trem','basic'),\n",
    "           ('medcond','merge_within_medcond','subj_medcond'),\n",
    "          ('dataset','merge_within_task','subj_medcond_task') ]\n",
    "\n",
    "use_CV_perf = True\n",
    "\n",
    "perf_to_use_list = ['perfs_XGB', 'perfs_XGB_red', 'all_present_features',\n",
    "                    'strongest_features_LDA_selMinFeatSet', \n",
    "                    'strongest_features_XGB_opinion', \n",
    "                    'best_PCA-derived_features_0.6']\n",
    "\n",
    "#label_types = [tpl[0] for tpl in to_show]\n",
    "#print(label_types)\n",
    "show_F1 = False\n",
    "show_numfeats = False\n",
    "\n",
    "assert output_per_raw is not None\n",
    "rname_crop = slice(0,-5) # keeping medcond info\n",
    "rname_crop = slice(0,3) # keeping medcond info\n",
    "\n",
    "import pandas as pd \n",
    "for perf_to_use in perf_to_use_list:\n",
    "    red_mode = False\n",
    "    if perf_to_use.endswith('_red'):\n",
    "        red_mode = True\n",
    "    #table =  [ [''] +  prefix_labels_perraw[rawnames[0] ]\n",
    "    #table =  [ [''] +  [ dct.get(prefix,prefix) for dct in prefix_labels_perraw] ]\n",
    "    table =  [ [''] +  prefixes ]\n",
    "    was_valid = False\n",
    "    for rn in output_per_raw:\n",
    "        for lt, it_grp, it_set in to_show:\n",
    "        #for lt in label_types:\n",
    "            # raw and label type (grouping+int_types) name goes here\n",
    "            # this will be a row name\n",
    "            row_name = '{}_{}'.format(rn[rname_crop], lt)\n",
    "            table_row = [row_name ]\n",
    "            for prefix in prefixes:\n",
    "                #sens,spec = res[rn].get(pref, (np.nan, np.nan))\n",
    "                r = output_per_raw[rn].get(prefix, None)     \n",
    "                if (r is not None) and (it_grp not in r or it_set not in r[it_grp]):\n",
    "                    r = None\n",
    "                \n",
    "                perfs = None\n",
    "                if r is None:\n",
    "                    print('Warning :',rn,prefix)\n",
    "                else:\n",
    "                    lda_output = r[it_grp][it_set]  \n",
    "                    if lda_output is not None:\n",
    "                        if perf_to_use in ['perfs_XGB','perfs_XGB_red']:\n",
    "                            if 'perfs_XGB' in lda_output and lda_output['perfs_XGB'] is not None:\n",
    "                                perfs_XGB = lda_output['perfs_XGB']\n",
    "                                if perf_to_use == 'perfs_XGB':\n",
    "                                    ind = 0\n",
    "                                elif perf_to_use == 'perfs_XGB_red':\n",
    "                                    ind = -1\n",
    "                                perfs_noCV = perfs_XGB[ind][-2]\n",
    "                                perfs_CV = perfs_XGB[ind][-1]                                                                                                    \n",
    "                        else:\n",
    "                            lda_anver = lda_output['lda_analysis_versions']                        \n",
    "                            anver_cur = lda_anver.get(perf_to_use,None)\n",
    "                            if anver_cur is not None:\n",
    "                                perfs_CV = anver_cur['CV']['CV_perfs']\n",
    "                                perfs_CV = np.mean(np.array(perfs_CV), axis=0)\n",
    "                                perfs_CV2 = anver_cur['CV_aver']['perfs']\n",
    "                                perfs_noCV = anver_cur['fit_to_all_data']['perfs']              \n",
    "                        \n",
    "                        if use_CV_perf:\n",
    "                            perfs = perfs_CV\n",
    "                        else:\n",
    "                            perfs = perfs_noCV\n",
    "                        \n",
    "                if perfs is None:\n",
    "                    print('Warning :',rn,prefix,lt)\n",
    "                    sens,spec,F1 = np.nan, np.nan, np.nan\n",
    "                else:\n",
    "                    sens,spec,F1 = perfs\n",
    "                    was_valid = True\n",
    "                #str_to_put = '{:.0f},{:.0f}'.format(100*sens,100*spec)\n",
    "                if show_F1:\n",
    "                    str_to_put =  '{:.0f},{:.0f},{:.0f}'.format(100*sens,100*spec,100*F1)  \n",
    "                else:\n",
    "                    str_to_put =  '{:.0f},{:.0f}'.format(100*sens,100*spec)  \n",
    "                try:\n",
    "                    if show_numfeats:\n",
    "                        num = feat_nums_perraw[rn][prefix][(it_grp,it_set)]\n",
    "                        num_red = feat_nums_red_perraw[rn][prefix][(it_grp,it_set)]\n",
    "                        if red_mode:\n",
    "                            s = ' :{}/{}'.format(num_red,num)\n",
    "                        else:\n",
    "                            s = ' :{}/{}'.format(num,num)\n",
    "                        str_to_put = str_to_put + s\n",
    "                except KeyError as e:\n",
    "                    print('AAAAA ',perf_to_use,rn,prefix,it_grp,it_set,e)\n",
    "                table_row += [ str_to_put  ]\n",
    "                print(rn,lt,prefix,str_to_put)\n",
    "\n",
    "            table += [table_row]\n",
    "\n",
    "        #rn,pref,lt\n",
    "\n",
    "#         table = np.array(table)\n",
    "        if not was_valid:\n",
    "             print('All nan, skipping')\n",
    "             continue\n",
    "\n",
    "        table_fname = \"pptable_{}_{}_nr{}_nprefixes{}_nlts{}_{}_CV{}.csv\".\\\n",
    "        format(sources_type, subdir, len(rawnames), len(prefixes),\n",
    "               len(to_show), perf_to_use, int(use_CV_perf) )\n",
    "        table_fname_full = os.path.join(gv.dir_fig, table_fname)\n",
    "        print(table_fname_full)\n",
    "        \n",
    "        pd.DataFrame(table).to_csv(table_fname_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of strongest feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_per_raw['S99_off_hold']['test'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for perf_to_use in perf_to_use_list:\n",
    "    table =  [ [''] +  prefix_labels_perraw[rawnames[0]]]\n",
    "    was_valid = False\n",
    "    for rn in output_per_raw:\n",
    "        for lt, it_grp, it_set in to_show:\n",
    "        #for lt in label_types:\n",
    "            # raw and label type (grouping+int_types) name goes here\n",
    "            # this will be a row name\n",
    "            row_name = '{}_{}'.format(rn[rname_crop], lt)\n",
    "            table_row = [row_name ]\n",
    "            for prefix in prefixes:\n",
    "                #sens,spec = res[rn].get(pref, (np.nan, np.nan))\n",
    "                r = output_per_raw[rn].get(prefix, None)     \n",
    "                if (r is not None) and (it_grp not in r or it_set not in r[it_grp]):\n",
    "                    r = None\n",
    "                \n",
    "                perfs = None\n",
    "                if r is None:\n",
    "                    print('Warning :',rn,prefix)\n",
    "                else:\n",
    "                    lda_output = r[it_grp][it_set]  \n",
    "                    if lda_output is not None:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kord = list(res.keys())\n",
    "#[k[:-5] for k in kord ]\n",
    "table =  [ [''] +  prefixes]\n",
    "for rn in kord:\n",
    "    for lt in label_types:\n",
    "        table_row = ['{}_{}'.format(rn[:-5], lt) ]\n",
    "        for pref in prefixes:\n",
    "            #sens,spec = res[rn].get(pref, (np.nan, np.nan))\n",
    "            r = res[rn].get(pref, None)\n",
    "            if r is None:\n",
    "                print('Warning :',rn,pref)\n",
    "                sfn = ''\n",
    "            else:\n",
    "                sfn = res_strongfeat[rn][pref][lt]\n",
    "            print('{} {} {}\\n  {}'.format(rn,lt,pref,sfn) )\n",
    "            table_row += [ sfn  ]\n",
    "        table += [table_row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = np.array(table)\n",
    "\n",
    "table_fname = \"strongest_feat_table.csv\"\n",
    "\n",
    "\n",
    "pd.DataFrame(table).to_csv(table_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_strongfeat.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at most important LFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chnames_LFP = ['LFPR01', 'LFPR12', 'LFPR23']\n",
    "groupings_to_use = ['merge_nothing']\n",
    "#rawnames_to_use = ['S99_off_move']\n",
    "rawnames_to_use = rawnames\n",
    "prefixes_to_use = ['modLFP', 'LFPrel']\n",
    "prefixes_to_use = ['modLFP', 'LFPrel_noself']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selLFP_calcPerfDrops(chnames_LFP, rawnames_to_use = None, groupings_to_use = None,\n",
    "                         prefixes_to_use = None, clf_type = 'XGB' ):\n",
    "    perf_drops = {}\n",
    "    # if all raws were processed together, they'll have same performances saved, no need to repeat\n",
    "\n",
    "    #for k in output_per_raw:\n",
    "    for ki,k in enumerate(rawnames_to_use):\n",
    "        output_per_prefix = output_per_raw[k]\n",
    "        #for prefix in output_per_prefix:\n",
    "        for prefix in prefixes_to_use:\n",
    "            output_per_grouping = output_per_prefix.get(prefix,None)\n",
    "            if output_per_grouping is None:\n",
    "                continue\n",
    "            #for grouping in output_per_grouping:\n",
    "            for grouping in groupings_to_use:\n",
    "                output_per_int_types = output_per_grouping[grouping]\n",
    "                for int_type in output_per_int_types:\n",
    "                    output_cur = output_per_int_types[int_type]\n",
    "                    #s = '{}:{}:{}:{}'.format(k,prefix,grouping,int_type)\n",
    "                    s = '{}:{}:{}:{}'.format(ki,prefix,grouping,int_type)\n",
    "                    if output_cur is None:\n",
    "                        #print(k,prefix,grouping,int_type,'=None')\n",
    "                        continue\n",
    "                    lda_anver = output_cur['{}_analysis_versions'.format(clf_type)]\n",
    "                    anver_full = lda_anver['all_present_features']\n",
    "                    perfs_full = anver_full['CV_aver']['perfs']\n",
    "                    perfs_full = np.array(perfs_full)\n",
    "                    perfs_str_full = utsne.sprintfPerfs(perfs_full)\n",
    "                    print('{}:: Full avCV perfs {}'.format(s,perfs_str_full))\n",
    "                    perf_drops[s] = {}\n",
    "                    for chn in chnames_LFP:\n",
    "                        key = 'all_present_features_but_{}'.format(chn)\n",
    "                        anver = lda_anver.get(key,None)\n",
    "                        if anver is None:\n",
    "                            #print(s,' fail')\n",
    "                            break\n",
    "                        perfs = np.mean(anver['CV']['CV_perfs'], axis=0)\n",
    "                        perfs = np.array(perfs)\n",
    "\n",
    "                        #print(perfs_full, perfs)\n",
    "                        perfs_str = utsne.sprintfPerfs(perfs)\n",
    "\n",
    "                        print('{}:: No {} avCV perfs {}'.format(s,chn,perfs_str))\n",
    "                        perf_drop = perfs_full - perfs\n",
    "\n",
    "                        perf_drops[s][chn] = perf_drop\n",
    "                        print('  Perf drop: ', utsne.sprintfPerfs(perf_drop) )\n",
    "                    if len(perf_drops[s]) == 0:\n",
    "                        del perf_drops[s]\n",
    "                    #print(lda_anver.keys())\n",
    "    return perf_drops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winnder_chans = {}\n",
    "for s,pdcurd in perf_drops.items():\n",
    "    pds = []\n",
    "    # I want ordered access across \n",
    "    for chn in chnames_LFP:\n",
    "        pds += [pdcurd[chn]]\n",
    "    pds = np.vstack(pds)\n",
    "    # axis 0 -- index of channel\n",
    "    maxdrop_perchan = np.max(pds,axis=1)\n",
    "    maxdrop_perchan = np.maximum(maxdrop_perchan,0)\n",
    "    \n",
    "    mindrop_perchan = np.min(pds,axis=1)\n",
    "    mindrop_perchan = np.minimum(mindrop_perchan,0)\n",
    "    # dropping channel should maximum worsen and minimum improve (mindrop is neg)\n",
    "    inds = np.argsort(maxdrop_perchan + mindrop_perchan)\n",
    "    win_ind = inds[-1]\n",
    "    winnder_chans[s] = chnames_LFP[win_ind]\n",
    "    #print(pds*100)\n",
    "    print('{:50} {} {}'.format( s, chnames_LFP[ win_ind ], utsne.sprintfPerfs( pds[win_ind] ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best features plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_output_pg_cur.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_output_pg_cur.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rncur = rawnames[0]\n",
    "#prefix = 'all'\n",
    "#prefix = 'LFPrel_noself'\n",
    "#prefix = 'allb_beta'\n",
    "#prefix = 'modSrc'\n",
    "prefix = 'LFPrel_noself'\n",
    "prefix = 'all'\n",
    "prefix = 'modSrc_self'\n",
    "it_grouping = 'merge_nothing'\n",
    "it_set = 'basic'\n",
    "nbest = 50\n",
    "#nbest_MI = nbest\n",
    "slice_best_feats = slice(-nbest,None)\n",
    "\n",
    "lda_output_pg_cur = output_per_raw[rncur][prefix]\n",
    "lda_output = lda_output_pg_cur[it_grouping][it_set]\n",
    "featnames_filtered = lda_output_pg_cur['feature_names_filtered']\n",
    "\n",
    "sind_str,mc,tk = utils.getParamsFromRawname(rncur)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfts = ['LDA', 'MI', 'XGB']\n",
    "bft = bfts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sind_str,mc,tk  = utils.getParamsFromRawname(rncur)\n",
    "sources_type='parcel_aal'\n",
    "src_file_grouping_ind = 10\n",
    "src_rec_info_fn = '{}_{}_grp{}_src_rec_info'.format(rncur,\n",
    "                                                    sources_type,src_file_grouping_ind)\n",
    "src_rec_info_fn_full = os.path.join(gv.data_dir, src_rec_info_fn + '.npz')\n",
    "rec_info = np.load(src_rec_info_fn_full, allow_pickle=True)\n",
    "\n",
    "\n",
    "print( list(rec_info.keys()) )\n",
    "\n",
    "labels_dict = rec_info['label_groups_dict'][()]\n",
    "srcgroups_dict = rec_info['srcgroups_dict'][()]\n",
    "coords = rec_info['coords_Jan_actual'][()]\n",
    "srcgrouping_names_sorted = rec_info['srcgroups_key_order'][()]\n",
    "sgdn = 'all_raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feats_dict = {}\n",
    "#feat_info_pri\n",
    "featnames_nice = utils.nicenFeatNames(featnames_filtered,\n",
    "                                    labels_dict,srcgrouping_names_sorted)\n",
    "featnames_nice = np.array(featnames_nice)\n",
    "\n",
    "\n",
    "if 'MI_per_feati' in lda_output:\n",
    "    MI = lda_output['MI_per_feati']\n",
    "\n",
    "    strong_inds = np.argsort(MI)\n",
    "    # increasing oder\n",
    "    best_feats_dict['MI'] = strong_inds\n",
    "\n",
    "if 'strong_inds_LDA' in lda_output:\n",
    "    # increasing oder\n",
    "    strong_inds = lda_output['strong_inds_LDA']\n",
    "    best_feats_dict['LDA'] = strong_inds\n",
    "    \n",
    "# increasing oder\n",
    "strong_inds = lda_output['strong_inds_XGB']\n",
    "best_feats_dict['XGB'] = strong_inds\n",
    "\n",
    "# increasing oder\n",
    "strong_inds = lda_output['inds_important']\n",
    "best_feats_dict['LDA_naive'] = strong_inds\n",
    "\n",
    "# pca_derived_featinds_perthr = lda_output['pca_derived_featinds_perthr']\n",
    "# feat_variance_q_thr = lda_output['feat_variance_q_thr']\n",
    "\n",
    "# for thri,thr in feat_variance_q_thr:\n",
    "#     best_feats_dict['PCA_{:.2f}'.format(thr)] = pca_derived_featinds_perthr[thri] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bft = 'XGB'\n",
    "strong_inds = best_feats_dict[bft][slice_best_feats]\n",
    "#feat_names_cur = featnames_nice[strong_inds]\n",
    "feat_names_cur = featnames_filtered[strong_inds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('{}_{}:_{}_{}_{}__{}best descending order\\n'.format(sind_str,prefix,\n",
    "#                                               it_grouping,it_set,bft,nbest))\n",
    "# feat_names_cur_nice = featnames_nice[strong_inds]\n",
    "# for fn in feat_names_cur_nice[::-1]:\n",
    "#     print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{}_{}:_{}_{}_{}__{}best descending order\\n'.format(sind_str,prefix,\n",
    "                                              it_grouping,it_set,bft,nbest))\n",
    "feat_names_cur_nice = featnames_nice[strong_inds]\n",
    "for fn in feat_names_cur_nice[::-1]:\n",
    "    print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "src_chns_per_feat_nice = []\n",
    "src_chns_all_nice = []\n",
    "parcel_indices = []\n",
    "parcel_indices_all = []\n",
    "for fni,fn in enumerate(feat_names_cur):\n",
    "    p = 'msrc._[0-9]+_[0-9]+_c[0-9]+'\n",
    "    source_chns_cur_featname = re.findall(p, fn)\n",
    "    if len(source_chns_cur_featname) == 0:\n",
    "        continue\n",
    "    \n",
    "    sides,groupis,parcelis,compis = utils.parseMEGsrcChnamesShortList(source_chns_cur_featname)\n",
    "    parcel_indices_all += parcelis\n",
    "    parcel_indices += [parcelis]\n",
    "    \n",
    "    tmp = list(srcgrouping_names_sorted) * 10  # because we have 9 there\n",
    "    nice_chns_cur_featname = utils.nicenMEGsrc_chnames(source_chns_cur_featname,labels_dict,tmp,\n",
    "                            prefix='msrc_')\n",
    "    nice_chns_cur_featname = list(set(nice_chns_cur_featname))\n",
    "    src_chns_per_feat_nice += [nice_chns_cur_featname]\n",
    "    src_chns_all_nice += nice_chns_cur_featname\n",
    "    print(fn,nice_chns_cur_featname)\n",
    "\n",
    "sgdn='all_raw'\n",
    "parcel_indices_all = list(set(parcel_indices_all))\n",
    "#parcel_indices_all\n",
    "\n",
    "roi_labels = np.array(  labels_dict[sgdn] )\n",
    "rls = ['unlabeled'] + list( roi_labels[parcel_indices_all] )\n",
    "\n",
    "srcgrp = np.zeros( srcgroups_dict[sgdn].shape, dtype=srcgroups_dict[sgdn].dtype)\n",
    "\n",
    "for pii,pi in enumerate(parcel_indices_all):\n",
    "    srcgrp[srcgroups_dict[sgdn] == pi] = pii + 1 #list(roi_labels).index( rls[pii])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrs =  utils.vizGroup2(sind_str,coords,rls,srcgrp, show=False, alpha=.1,\n",
    "                       figsize_mult=1.5,msz=30, printLog=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "figname = '{}_{}:_{}_{}_{}_srcmap_{}best'.format(sind_str,prefix,\n",
    "                                              it_grouping,it_set,bft,nbest)\n",
    "plt.gcf().axes[0].set_title(figname)\n",
    "plt.savefig(figname+'.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_per_raw['S01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_per_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rncur = rawnames[0]\n",
    "#prefix = 'all'\n",
    "#prefix = 'LFPrel_noself'\n",
    "#prefix = 'allb_beta'\n",
    "#prefix = 'modSrc'\n",
    "#prefix = 'LFPrel_noself'\n",
    "prefix = 'modLFP'\n",
    "it_grouping = 'merge_nothing'\n",
    "it_set = 'basic'\n",
    "nbest = 10\n",
    "#nbest_MI = nbest\n",
    "slice_best_feats = slice(-nbest,None)\n",
    "\n",
    "lda_output_pg_cur = output_per_raw[rncur][prefix]\n",
    "lda_output = lda_output_pg_cur[it_grouping][it_set]\n",
    "featnames_filtered = lda_output_pg_cur['feature_names_filtered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_anver = lda_output['lda_analysis_versions']\n",
    "print(lda_anver.keys())\n",
    "featset_name = 'all_present_features'\n",
    "model = lda_anver[featset_name]['CV_aver']['ldaobj']\n",
    "perfs = lda_anver[featset_name]['CV_aver']['perfs']\n",
    "utsne.sprintfPerfs(perfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Ximp_per_raw[rncur][prefix]\n",
    "gi = gis_per_raw[rncur][prefix]\n",
    "X_to_fit = X[gi]\n",
    "print(X_to_fit.shape)\n",
    "nsamples = 30\n",
    "Xsubset = shap.utils.sample(X_to_fit, nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "21 * 20 * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute SHAP values\n",
    "explainer= shap.Explainer(model.predict, Xsubset,feature_names=featnames_filtered)\n",
    "shap_values = explainer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values, max_display=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.scatter(shap_values[:,1], color=shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ind = 3\n",
    "shap.plots.waterfall(shap_values[sample_ind]) #, max_display=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resort output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "newdir = os.path.join(gv.dir_fig, 'tSNE-like' )\n",
    "if not os.path.exists(newdir):\n",
    "    os.mkdir( newdir )\n",
    "newdir_outer = newdir\n",
    "\n",
    "import shutil\n",
    "subskip_val = 1\n",
    "dirname_suffix = 'subskip{}'.format(subskip_val)\n",
    "\n",
    "for rawname_ in rawnames:\n",
    "    subj,medcond,task = utils.getParamsFromRawname(rawname_)\n",
    "    for prefix in prefixes:\n",
    "    #    rawname_ = 'S04_off_move'\n",
    "\n",
    "\n",
    "        #prefix = 'all'\n",
    "        regex = '{}_{}.*{}_tSNE_.*_subskip{}.pdf'.format(subj,medcond,prefix,subskip_val)\n",
    "        fnfound = utsne.findByPrefix(gv.dir_fig, None, prefix, regex=regex)\n",
    "        print(regex,len(fnfound))\n",
    "        if len(fnfound):\n",
    "            newdir = os.path.join(newdir_outer, '{}_{}_{}'.format(subj, medcond, dirname_suffix) )\n",
    "\n",
    "            if not os.path.exists(newdir):\n",
    "                os.mkdir( newdir )\n",
    "\n",
    "            for fn in fnfound:\n",
    "                fnfull_old = os.path.join(gv.dir_fig,fn)\n",
    "                fnfull = os.path.join(newdir,fn)\n",
    "                shutil.move(fnfull_old,fnfull)\n",
    "\n",
    "#    fnfound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdir = os.path.join(gv.dir_fig, 'PCA-like' )\n",
    "if not os.path.exists(newdir):\n",
    "    os.mkdir( newdir )\n",
    "newdir_outer = newdir\n",
    "\n",
    "import shutil\n",
    "dirname_suffix = ''\n",
    "\n",
    "for rawname_ in rawnames:\n",
    "    subj,medcond,task = utils.getParamsFromRawname(rawname_)\n",
    "    for prefix in prefixes:\n",
    "    #    rawname_ = 'S04_off_move'\n",
    "\n",
    "\n",
    "        #prefix = 'all'\n",
    "        regex = '{}_{}.*{}_PCA.*.pdf'.format(subj,medcond,prefix)\n",
    "        fnfound = utsne.findByPrefix(gv.dir_fig, None, prefix, regex=regex)\n",
    "        print(regex,len(fnfound))\n",
    "        if len(fnfound):\n",
    "            newdir = os.path.join(newdir_outer, '{}_{}_{}'.format(subj, medcond, dirname_suffix) )\n",
    "\n",
    "            if not os.path.exists(newdir):\n",
    "                os.mkdir( newdir )\n",
    "\n",
    "            for fn in fnfound:\n",
    "                fnfull_old = os.path.join(gv.dir_fig,fn)\n",
    "                fnfull = os.path.join(newdir,fn)\n",
    "                shutil.move(fnfull_old,fnfull)\n",
    "\n",
    "#    fnfound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a pic\n",
    "## Load table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfns = []\n",
    "tfns += [('XGB','pptable_parcel_aal__nr6_nprefixes18_nlts5_perfs_XGB_CV1.csv')]\n",
    "tfns += [('LDA','pptable_parcel_aal__nr6_nprefixes18_nlts5_all_present_features_CV1.csv')]\n",
    "\n",
    "#tfns += [('first',\"pred_power_table.csv\")]\n",
    "#tfns += [('Hisrch','pred_power_table_nprefixes4_nlts3_perfs_XGB_CV1_Hisrch.csv')]\n",
    "#tfns += [('full','pptable_parcel_aal_nprefixes9_nlts1_perfs_XGB_CV1_red1.csv')]\n",
    "#tfns += ['pred_power_table_nprefixes4_nlts3_perfs_XGB_CV1_red1.csv']\n",
    "#tfns += ['pred_power_table_nprefixes4_nlts3_perfs_XGB_CV1_red0.csv']\n",
    "\n",
    "#tfns += ['pptable_parcel_aal_nprefixes6_nlts1_perfs_XGB_CV1_red1.csv']\n",
    "#tfns += ['pptable_parcel_aal_nprefixes6_nlts1_perfs_XGB_CV1_red0.csv']\n",
    "\n",
    "#tfns += ['pptable_parcel_aal_nprefixes9_nlts1_perfs_XGB_CV1_red0.csv']\n",
    "# table_fnames_dict = {'red':table_fname1, 'full':table_fname2, 'Hirsch':table_fname3,\n",
    "#                     'full2':table_fname4, 'red2':table_fname5, 'full3':table_fname6,\n",
    "#                     'red3':table_fname7}\n",
    "#table_labels = list(sorted(table_fnames_dict.keys() ))\n",
    "#table_labels = list((table_fnames_dict.keys() ))\n",
    "\n",
    "table_labels = [tfn[0] for tfn in tfns]\n",
    "#table_labels = ['Hirsch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#df['0'][0],df['0'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_fname = tfns[0][1]\n",
    "\n",
    "table_fname_full = os.path.join(gv.dir_fig, table_fname)\n",
    "print(table_fname_full)\n",
    "        \n",
    "df = pd.read_csv(table_fname_full)\n",
    "num_featsets = len(df.keys())\n",
    "#for tfn in table_labels:\n",
    "print(num_featsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq = np.linspace(0,1,num_featsets-2)\n",
    "seq = np.random.permutation(num_featsets).astype(float); seq /= np.max(seq)\n",
    "cmap = plt.cm.gist_rainbow\n",
    "#cmap = plt.cm.hsv\n",
    "cyc = plt.cycler(\"color\", cmap(seq ))\n",
    "\n",
    "plt.cm.gist_rainbow\n",
    "\n",
    "# for ci,c in enumerate(cyc):\n",
    "#     print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_label = 'allsep'\n",
    "des_label = 'medcond'\n",
    "des_featsets = ['all', 'allb_beta', 'modLFP', 'modSrc_self', 'modSrc', 'LFPrel_noself']\n",
    "featset_dispname = ['MEG+LFP', 'MEG beta+LFP beta', 'LFP', 'MEG', 'MEG_conn', 'cross LFP-MEG']\n",
    "\n",
    "des_featsets = ['all', 'allb_beta', 'modLFP', 'modSrc_self', 'LFPrel_noself']\n",
    "featset_dispname = ['MEG+LFP', 'MEG beta+LFP beta', 'LFP', 'MEG', 'cross LFP-MEG']\n",
    "\n",
    "des_label_disp_name = {'allsep':'tremor', 'medcond':'ON/OFF'}\n",
    "dlb = des_label_disp_name[des_label]\n",
    "\n",
    "table_dispname = ['Entire hemisphere', '4 sources', 'Entire hemisphere2']\n",
    "table_dispname = ['XGB {}'.format(dlb), 'LDA {}'.format(dlb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww = 7\n",
    "hh = ww\n",
    "nr = len(table_labels)\n",
    "nc = 2\n",
    "fig,axs = plt.subplots(nr,nc, figsize=(ww*2,hh*nr))\n",
    "axs = axs.reshape((nr,nc))\n",
    "defsz = 20; larger= ['all', 'modLFP', 'modSrc', 'allb_beta']\n",
    "defsz = 120; larger = [];\n",
    "legend_alpha = 0.3\n",
    "legend_fontsz=17\n",
    "title_fontsz=25\n",
    "title2_fontsz=15\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.set_xlim(-3,103)\n",
    "    ax.set_ylim(-3,103)\n",
    "    ax.set_ylim(50,103)\n",
    "    ax.set_xlabel('Sensitivity',fontsize=22)\n",
    "    ax.set_ylabel('Specificity',fontsize=22)\n",
    "\n",
    "for rowi in range(nr):\n",
    "    table_lbl_cur = table_labels[rowi]\n",
    "    #tfn = table_fnames_dict[table_lbl_cur]\n",
    "    tfn = tfns[rowi][1]\n",
    "    tfn_full = os.path.join(gv.dir_fig, tfn)\n",
    "    df = pd.read_csv(tfn_full)\n",
    "    \n",
    "    ax  = axs[rowi,0]\n",
    "    ax1 = axs[rowi,1]\n",
    "\n",
    "    num_featsets_cur = len(df.keys())\n",
    "    featsetcolori = 0\n",
    "    for ind in range(num_featsets_cur): #range(1,num_featsets-1):\n",
    "    #ind = 1\n",
    "        indd = 0\n",
    "        try:\n",
    "            indd = int(df.keys()[ind])  #column\n",
    "        except (ValueError,KeyError) as e:\n",
    "            indd = 0\n",
    "        \n",
    "        if indd <= 0:\n",
    "            continue\n",
    "        cc  = list(cyc)[featsetcolori]\n",
    "        key = str(indd)\n",
    "        featset_name = df[key][0]\n",
    "        if featset_name not in des_featsets:\n",
    "            continue\n",
    "            \n",
    "        featsetcolori += 1\n",
    "        print('{}: featset name {}'.format(table_lbl_cur,featset_name) )\n",
    "        \n",
    "        l = len(df[key])\n",
    "        l = 0\n",
    "        nice_inds = []\n",
    "        for i in range(1,len(df[key])):\n",
    "            if df['0'][i].find(des_label) >= 0:\n",
    "                #print(df['0'][i])\n",
    "                l += 1\n",
    "                nice_inds += [i]\n",
    "\n",
    "        # specs over patients\n",
    "#         senss = (l-1)*[0]\n",
    "#         specs = (l-1)*[0]\n",
    "        senss = (l)*[np.nan]\n",
    "        specs = (l)*[np.nan]\n",
    "        #print(len(specs),nice_inds)\n",
    "        #for i in range(1,l):\n",
    "        for ii,i in enumerate(nice_inds):\n",
    "            s = df[key][i]\n",
    "            try:\n",
    "                r = list(map(int,s.split(',')) )\n",
    "            except ValueError as ve:\n",
    "                continue\n",
    "            se = r[0]\n",
    "            sp = r[1]\n",
    "            if len(r) > 2:\n",
    "                f1 =  r[2]\n",
    "            #print(i)\n",
    "            senss[ii] = se\n",
    "            specs[ii] = sp\n",
    "            #print( se,sp  )\n",
    "        #print('fd0')\n",
    "                \n",
    "        clrs = len(specs) *  [ cc['color'] ]\n",
    "        sz = defsz\n",
    "        mrk = 'o'\n",
    "        if featset_name in larger:\n",
    "            sz *= 8        \n",
    "            mrk = 'o'\n",
    "        ase = np.mean(np.array(senss)[~np.isnan(senss) ])\n",
    "        asp = np.mean(np.array(specs)[~np.isnan(specs) ])\n",
    "        lbl = '{} ~ {:.0f},{:.0f}'.format(featset_name, ase, asp)\n",
    "        lbl = featset_dispname[des_featsets.index(featset_name)]\n",
    "        \n",
    "        #print('fd1')\n",
    "        ax.scatter(senss,specs, c=clrs , label=lbl, s= sz, marker=mrk, alpha=0.8)\n",
    "\n",
    "        ax1.scatter([ase],[asp], c=[clrs[0]] , label=lbl, s= sz, marker=mrk)\n",
    "\n",
    "    ax.legend(loc='lower left',fontsize=legend_fontsz,framealpha=legend_alpha); \n",
    "    ttl = table_lbl_cur\n",
    "    ttl = table_dispname[rowi]\n",
    "    ax.set_title('{} across 6 patients'.format(ttl),\n",
    "                                              fontsize=title_fontsz)\n",
    "    ax1.legend(loc='lower left',framealpha=legend_alpha); \n",
    "    ax1.set_title('{} Average predictive powers'.format(table_lbl_cur),\n",
    "                                                fontsize=title2_fontsz)\n",
    "    ax.grid(1)\n",
    "    ax1.grid(1)\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.savefig('pred_power_scatter_o{}_{}.pdf'.format(table_fname,des_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rawnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some older stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#%debug\n",
    "#%run -i run_PCA.py -r S01_off_hold,S01_off_move --pcexpl 0.95 --discard 0.01 --show_plots 0 --prefix all --load_only 1\n",
    "%run -i run_PCA.py -r S01_off_hold,S01_off_move --pcexpl 0.95 --discard 0.01 --show_plots 0 \\\n",
    "--prefix all --load_only 0\n",
    "\n",
    "nfeats_per_comp_LDA = 16\n",
    "r = utsne.getImporantCoordInds(lda.scalings_.T, \n",
    "                               nfeats_show = nfeats_per_comp_LDA, q=0.8, printLog = 1)\n",
    "inds_toshow, strong_inds_pc, strongest_inds_pc  = r\n",
    "\n",
    "\n",
    "for dim,feat_inds in enumerate(strong_inds_pc):\n",
    "    print(dim, np.array(feature_names_pri[dim])[feat_inds] )\n",
    "    #print(dim,feat_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%debug\n",
    "#%run -i run_PCA.py -r S01_off_hold,S01_off_move --pcexpl 0.95 --discard 0.01 --show_plots 0 --prefix all --load_only 1\n",
    "%run -i run_PCA.py -r S02_off_hold,S02_off_move --pcexpl 0.95 --discard 0.01 --show_plots 0 \\\n",
    "--prefix all --load_only 0\n",
    "\n",
    "nfeats_per_comp_LDA = 16\n",
    "r = utsne.getImporantCoordInds(lda.scalings_.T, \n",
    "                               nfeats_show = nfeats_per_comp_LDA, q=0.8, printLog = 1)\n",
    "inds_toshow, strong_inds_pc, strongest_inds_pc  = r\n",
    "\n",
    "\n",
    "for dim,feat_inds in enumerate(strong_inds_pc):\n",
    "    print(dim, np.array(feature_names_pri[dim])[feat_inds] )\n",
    "    #print(dim,feat_inds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01_off_hold\n",
    "0 ['H_mob_LFPR01' 'H_act_LFPR01' 'H_act_msrcR_0' 'H_compl_msrcR_0'\n",
    " 'H_compl_msrcR_4' 'H_compl_msrcR_2' 'H_act_LFPR12' 'H_compl_LFPR12']\n",
    " \n",
    "1 ['H_compl_LFPR01' 'con_tremor_msrcR_4,msrcR_6' 'H_mob_LFPR01'\n",
    " 'H_compl_LFPR23' 'H_act_msrcR_6' 'H_compl_msrcR_6' 'H_act_LFPR12'\n",
    " 'H_compl_LFPR12']\n",
    "\n",
    "01_on_hold\n",
    "0 ['H_compl_LFPR12' 'rbcorr_corr_tremor_msrcR_6,tremor_msrcR_6'\n",
    " 'H_act_msrcR_0' 'con_tremor_msrcR_0,msrcR_0' 'H_mob_msrcR_4'\n",
    " 'con_tremor_msrcR_2,LFPR01' 'H_compl_msrcR_4' 'H_compl_msrcR_0']\n",
    " \n",
    "1 ['con_high_beta_msrcR_4,LFPR01' 'H_mob_msrcR_6' 'H_compl_msrcR_0'\n",
    " 'H_act_LFPR23' 'H_mob_LFPR01' 'H_mob_msrcR_4' 'H_compl_msrcR_4'\n",
    " 'H_mob_LFPR23']\n",
    " \n",
    " 02_off_hold\n",
    " 0 ['H_mob_msrcR_4' 'con_high_gamma_msrcR_4,msrcR_4'\n",
    " 'con_tremor_msrcR_0,msrcR_0' 'H_act_LFPR12' 'H_compl_LFPR12'\n",
    " 'H_compl_LFPR01' 'H_compl_msrcR_4' 'con_tremor_msrcR_2,LFPR01']\n",
    " \n",
    "1 ['H_mob_msrcR_0' 'H_act_LFPR01' 'H_compl_LFPR01'\n",
    " 'con_tremor_msrcR_2,LFPR01' 'con_tremor_msrcR_4,msrcR_6'\n",
    " 'rbcorr_corr_high_gamma_msrcR_6,high_gamma_msrcR_6'\n",
    " 'rbcorr_corr_high_gamma_LFPR12,high_gamma_msrcR_6' 'H_compl_LFPR23']\n",
    " \n",
    " 02_on_hold\n",
    " 0 ['rbcorr_corr_low_gamma_msrcR_6,low_gamma_msrcR_6' 'H_compl_LFPR01'\n",
    " 'con_tremor_msrcR_0,LFPR12' 'con_high_beta_msrcR_2,msrcR_6'\n",
    " 'H_act_LFPR23' 'rbcorr_corr_tremor_msrcR_6,tremor_msrcR_6'\n",
    " 'con_tremor_msrcR_2,LFPR01' 'H_act_LFPR01']\n",
    " \n",
    "1 ['con_tremor_msrcR_2,LFPR23' 'H_act_LFPR12'\n",
    " 'rbcorr_corr_tremor_msrcR_6,tremor_msrcR_6'\n",
    " 'rbcorr_corr_low_gamma_LFPR12,low_gamma_msrcR_6'\n",
    " 'con_tremor_msrcR_4,msrcR_6' 'H_compl_LFPR23' 'H_compl_LFPR12'\n",
    " 'H_compl_LFPR01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_pri[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%debug\n",
    "utsne.plotPCA(pcapts,pca, nPCAcomponents_to_plot,feature_names_all, colors, markers,\n",
    "            mrk, mrknames, color_per_int_type, tasks,\n",
    "            pdf=None,neutcolor=neutcolor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcapts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "X_LDA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fi = feat_file_pri[0]['feat_info'][()]\n",
    "# nedgeBins = fi['nedgeBins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.scalings_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "r = utsne.getImporantCoordInds(lda.scalings_.T, nfeats_show = 140, q=0.8, printLog = 1)\n",
    "inds_toshow, strong_inds_pc, strongest_inds_pc  = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(inds_toshow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_pri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawnames = rawnames_for_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn_str = ','.join(rawnames)\n",
    "fn = 'rbcorr'\n",
    "#fn = 'bpcorr'\n",
    "fn = 'H_.*'\n",
    "Xfeat_cur, names = utsne.selFeatsRegex(Xconcat.T, feature_names_pri[0], ['{}.*'.format(fn)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utsne.plotBasicStatsMultiCh(Xfeat_cur, names, printMeans = True, singleAx = 1, shift_std_mult = 6)\n",
    "plt.savefig('{}_{}_feat_stats.pdf'.format(rn_str,fn))\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
