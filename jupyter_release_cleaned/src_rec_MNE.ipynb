{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3159ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from globvars import dir_fig, data_dir\n",
    "import argparse\n",
    "from os.path import join as pjoin\n",
    "\n",
    "\n",
    "def sifnn(s,sep=','):\n",
    "    if s is None:\n",
    "        return None\n",
    "    else:\n",
    "        return s.split(sep)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--subjects')\n",
    "parser.add_argument('--medconds')\n",
    "parser.add_argument('--tasks')\n",
    "parser.add_argument('--rawnames')\n",
    "parser.add_argument('--use_data_afterICA',type=int)\n",
    "parser.add_argument('--input_subdir')\n",
    "parser.add_argument('--output_subdir')\n",
    "parser.add_argument('--input_rawname_type')\n",
    "parser.add_argument('--roi')\n",
    "\n",
    "DEBUG = 1\n",
    "if DEBUG:\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"--------DEBUG    --------------\")\n",
    "    print(\"-------------------------------\")\n",
    "    arglist = ['--rawnames','S01_off_move','--input_rawname_type', 'resample,notch',\n",
    "              '--use_data_afterICA','0']\n",
    "    args = parser.parse_args(arglist)\n",
    "else:\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    \n",
    "rawnames = sifnn(args.rawnames)\n",
    "if rawnames is None:\n",
    "    rawnames = [\"S01_off_hold\"];\n",
    "    \n",
    "subjstrs = sifnn(args.subjects)\n",
    "if subjstrs is None:\n",
    "    subjstrs = [\"S01\", \"S02\", \"S03\", \"S04\", \"S05\", \"S06\", \"S07\", \"S08\", \"S09\", \"S10\" ];\n",
    "\n",
    "medconds = sifnn(args.medconds)\n",
    "if medconds is None:\n",
    "    medconds = [\"off\", \"on\"];\n",
    "    \n",
    "tasks = sifnn(args.tasks)\n",
    "if tasks is None:\n",
    "    tasks = [\"hold\", \"move\"];\n",
    "    \n",
    "input_rawname_type = sifnn(args.input_rawname_type)\n",
    "if input_rawname_type is None:\n",
    "    input_rawname_type = [\"resample\", \"notch\", \"highpass\"]; # default\n",
    "# %input_rawname_type = [\"resample\", \"afterICA\"]\n",
    "# %input_rawname_type = [\"SSS\", \"notch\", \"highpass\", \"resample\", \"afterICA\"]\n",
    "    \n",
    "input_subdir = args.input_subdir\n",
    "if input_subdir is None:\n",
    "    input_subdir = \"\";\n",
    "\n",
    "output_subdir = args.output_subdir\n",
    "if output_subdir is None:\n",
    "    output_subdir = \"\";\n",
    "\n",
    "use_data_afterICA = args.use_data_afterICA\n",
    "if use_data_afterICA is None:\n",
    "    use_data_afterICA = 1;\n",
    "    \n",
    "roi = args.roi\n",
    "if roi is None:\n",
    "    roi = \"parcel_aal_surf\";\n",
    "    \n",
    "\n",
    "if use_data_afterICA:\n",
    "  input_rawname_type = input_rawname_type + [ \"afterICA\"]\n",
    "rawname_suffix = '';\n",
    "# for i in range(len(input_rawname_type) ):\n",
    "#   rawname_suffix = \"%s_%s\" % (rawname_suffix,input_rawname_type[i] );\n",
    "# rawname_suffix = \"%s_%s\" % (rawname_suffix,\"raw\" );\n",
    "rawname_suffix = '_'.join( input_rawname_type + ['raw'] )\n",
    "\n",
    "resname_add_str = '';\n",
    "# %if any(contains(input_rawname_type, \"SSS\" ) ) \n",
    "# %  if any(strcmp(input_rawname_type, \"afterICA\" ) )   \n",
    "if rawname_suffix.find(\"SSS\") >= 0:\n",
    "  remove_bad_channels = 0;\n",
    "#   % I better control it with setting subfolder names\n",
    "#   %resname_add_str = \"SSS\"\n",
    "#   %if contains(rawname_suffix, \"afterICA\")\n",
    "#   %  resname_add_str = strcat(resname_add_str, \"_afterICA\")\n",
    "#   %end\n",
    "else:\n",
    " remove_bad_channels = 1\n",
    "#end\n",
    "\n",
    "# % Brodmann 4 -- M1,   Brodmann 6 -- PMC\n",
    "# %roi = {\"Brodmann area 4\"};\n",
    "# %roi = {\"Brodmann area 6\"};\n",
    "# %roi = {\"HirschPt2011,2013\"}\n",
    "# %roi = {\"HirschPt2011,2013\",\"Thalamus\"}\n",
    "# %\n",
    "# %roi = {\"Brodmann area 4\",\"Brodmann area 6\"};\n",
    "# %roi = {\"HirschPt2011\"};\n",
    "save_srcrec          = 1;\n",
    "if DEBUG:\n",
    "  save_srcrec          = 0;\n",
    "\n",
    "use_DICS = 0;\n",
    "\n",
    "import pymatreader as pymr\n",
    "#% Load Jan-provided info\n",
    "#if os.path.exists(\"Info.mat\"):\n",
    "info = pymr.read_mat(pjoin(data_dir,\"Info.mat\"))\n",
    "\n",
    "\n",
    "highpass_freq = 1.5;\n",
    "\n",
    "#f_scalemat = pymr.read_mat(pjoin(code_dir,('head_scalemat.mat') ) );\n",
    "#some info about \"spacing\" parameter\n",
    "#https://mne.tools/stable/overview/cookbook.html#setting-up-source-space\n",
    "#add_dist = Add distance and patch information to the source space\n",
    "#add_dist Can also be ‘patch’ to only compute patch information (requires SciPy 1.3+).\n",
    "\n",
    "#https://mne.tools/stable/generated/mne.setup_source_space.html#mne.setup_source_space\n",
    "\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7673f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce2d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cfd61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "rawname = rawnames[0]\n",
    "\n",
    "fname_raw_full = pjoin(data_dir, f'{rawname}_{rawname_suffix}.fif' )\n",
    "assert os.path.exists(fname_raw_full)\n",
    "mtime = datetime.fromtimestamp( os.stat(fname_raw_full).st_mtime ) \n",
    "display(mtime)\n",
    "raw = mne.io.read_raw(fname_raw_full)\n",
    "\n",
    "raw_grad = raw.copy()\n",
    "raw_mag  = raw.copy()\n",
    "megtype2subraw = {'grad':raw_grad, 'mag':raw_mag}\n",
    "for megtype,subraw in megtype2subraw.items():\n",
    "    megtype2subraw[megtype] = subraw.pick_types(megtype)\n",
    "\n",
    "## TODO: read MEG artifacts here\n",
    "## TODO maybe -- use code from collect artifacts to reject everything non-rest\n",
    "\n",
    "# from the documentation example values\n",
    "reject = dict(grad=4000e-13, # T / m (gradiometers)\n",
    "              mag=4e-12, # T (magnetometers)                           \n",
    "              )\n",
    "#eeg=40e-6, # V (EEG channels)\n",
    "#eog=250e-6 # V (EOG channels)\n",
    "\n",
    "megtype2data_cov = {}\n",
    "for megtype,subraw in megtype2subraw.items():\n",
    "    reject_sub = {}\n",
    "    reject_sub[megtype] = reject[megtype]\n",
    "    \n",
    "    # bad channels count here a lot\n",
    "    # also does rescaling according to hardcorded values, so it is necessary \n",
    "    # that it was not recaled before\n",
    "    data_cov = mne.compute_raw_covariance(subraw, picks='meg', tmin=0, tmax=None, \n",
    "                               reject_by_annotation=True, n_jobs=-1, reject=reject_sub)\n",
    "    megtype2data_cov[megtype] = data_cov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495df40b",
   "metadata": {},
   "source": [
    "## BEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2517ffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = rawname.split('_')[0]; subject\n",
    "subjects_dir = pjoin(data_dir,'subjects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027d1dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_full_trans = pjoin(subjects_dir,f'{subject}_transform.fif')\n",
    "trans = mne.read_trans(fname_full_trans)\n",
    "\n",
    "fname_full_bem = pjoin(data_dir,f'{subject}-bem.fif')\n",
    "load_bem = 1\n",
    "\n",
    "if os.path.exists(fname_full_bem) and load_bem:\n",
    "    bem = mne.read_bem_solution(fname_full_bem)\n",
    "else:\n",
    "    conductivity = (0.3,)  # for single layer\n",
    "    # conductivity = (0.3, 0.006, 0.3)  # for three layers\n",
    "    model = mne.make_bem_model(subject=subject, ico=4,\n",
    "                               conductivity=conductivity,\n",
    "                               subjects_dir=subjects_dir)\n",
    "    bem = mne.make_bem_solution(model)\n",
    "    #########\n",
    "\n",
    "\n",
    "    mne.write_bem_solution(fname_full_bem,bem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aa8901",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(mne.setup_source_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0019590",
   "metadata": {},
   "source": [
    "## SRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a543af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82edade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_src = 1\n",
    "fname_full_src_space = pjoin(data_dir,f'{subject}-src.fif')\n",
    "fname_full_src_space_noCB = pjoin(data_dir,f'{subject}_noCB-src.fif')\n",
    "fname_full_src_space_CB = pjoin(data_dir,f'{subject}_CB-src.fif')\n",
    "CB_spacing = 12 #in mm\n",
    "\n",
    "if os.path.exists(fname_full_src_space) and load_src:\n",
    "    print('Loading source spaces')\n",
    "#source_space_noCB = mne.read_source_spaces(fname_full_src_space)\n",
    "    source_space_noCB = mne.read_source_spaces(fname_full_src_space_noCB)\n",
    "    source_space_CB   = mne.read_source_spaces(fname_full_src_space_CB)\n",
    "    source_space = source_space_noCB + source_space_CB\n",
    "else:\n",
    "### recalc\n",
    "    # subject should correspond to freesurfer fiels\n",
    "    source_space_noCB = mne.setup_source_space(subject, spacing='oct4', add_dist=True,\n",
    "                                 subjects_dir=subjects_dir, n_jobs = -1)\n",
    "\n",
    "    #around 258 for each hemi    \n",
    "    mne.write_source_spaces(fname_full_src_space_noCB ,source_space_noCB,overwrite=True)\n",
    "\n",
    "    \n",
    "    # mindist : float\n",
    "    #     Exclude points closer than this distance (mm) to the bounding surface.\n",
    "    # exclude : float\n",
    "    #     Exclude points closer than this distance (mm) from the center of mass\n",
    "    #     of the bounding surface.\n",
    "\n",
    "    volume_label = 'Left-Cerebellum-Cortex'\n",
    "    #sphere = (0, 0, 0, 0.12)\n",
    "    lh_cereb = mne.setup_volume_source_space(\n",
    "        subject,  volume_label=volume_label, bem=bem, \n",
    "        subjects_dir=subjects_dir, pos=CB_spacing)\n",
    "\n",
    "    volume_label = 'Right-Cerebellum-Cortex'\n",
    "    rh_cereb = mne.setup_volume_source_space(\n",
    "        subject,  volume_label=volume_label, bem=bem, \n",
    "        subjects_dir=subjects_dir, pos=CB_spacing)\n",
    "    #mri=aseg_fname,exclude=10\n",
    "    \n",
    "    source_space_CB = lh_cereb + rh_cereb\n",
    "    mne.write_source_spaces(fname_full_src_space_CB ,source_space_CB,overwrite=True)\n",
    "\n",
    "    # Combine the source spaces\n",
    "    #source_space_ext_left = source_space[0] + lh_cereb\n",
    "    source_space = source_space_noCB + lh_cereb + rh_cereb\n",
    "    mne.write_source_spaces(fname_full_src_space, source_space, overwrite=True)\n",
    "\n",
    "srcd = {'cortex':source_space_noCB, 'CB':source_space_CB}\n",
    "#srcd_sided = {'cortex_left':source_space_noCB, 'CB':source_space_CB}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b799e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c32481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_bem(subject, subjects_dir=subjects_dir, src=source_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ea3f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_space[0]['type'], source_space[0]['subject_his_id'], \\\n",
    "    source_space[0]['coord_frame'], source_space[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cee86a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = mne.viz.plot_alignment(subject=subject, subjects_dir=subjects_dir,\n",
    "#                              surfaces='white', coord_frame='mri',\n",
    "#                              src=source_space)\n",
    "# mne.viz.set_3d_view(fig, azimuth=173.78, elevation=101.75,\n",
    "#                     distance=0.30, focalpoint=(-0.03, -0.01, 0.03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4408023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1977933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write_source_spaces('sample-oct6-src.fif', src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4c3e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.io.pick import channel_type\n",
    "[channel_type(raw.info, ind) for ind in range(len(raw.info.ch_names) )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c76f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.channels.channels import  _contains_ch_type\n",
    "_contains_ch_type(raw.info, 'grad' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea441010",
   "metadata": {},
   "source": [
    "## Forward solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aada48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "101 lh\n",
    "102 rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733020cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "src['id'],src['seg_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4278a679",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalc_forward_solution = 1\n",
    "if not recalc_forward_solution:\n",
    "    sys.exit(0)\n",
    "# we need to do separate forward solutions for each of the source spaces\n",
    "for megtype,subraw in megtype2subraw.items():\n",
    "    for src_type,src in srcd.items():\n",
    "        # head<->MRI transform *-trans.fif file produced during coregistration. \n",
    "        fwd = mne.make_forward_solution(subraw.info, trans=trans, src=src, \n",
    "                                        bem=bem,\n",
    "                                        meg=True, eeg=False, mindist=5.0, n_jobs=-1,\n",
    "                                        verbose=0)\n",
    "        print(fwd)\n",
    "        #leadfield = fwd['sol']['data']\n",
    "\n",
    "\n",
    "\n",
    "        fname_full_fwd = pjoin(data_dir,f'{rawname}_{src_type}_{megtype}-fwd.fif')\n",
    "        mne.write_forward_solution(fname_full_fwd,fwd,overwrite=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c9c09c",
   "metadata": {},
   "source": [
    "## Inverse solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04a4300",
   "metadata": {},
   "outputs": [],
   "source": [
    "megtype2subraw.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e03c237",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalc_lcmv = 1\n",
    "\n",
    "from mne.beamformer import make_lcmv, apply_lcmv, apply_lcmv_raw\n",
    "noise_cov = None\n",
    "depth = 0.8  # val from MNE doc\n",
    "# bads are not used here\n",
    "# gives error: Source reconstruction with several sensor types \n",
    "# requires a noise covariance matrix to be able to apply whitening\n",
    "megtype2filters = {}\n",
    "for megtype,subraw in megtype2subraw.items():\n",
    "    megtype2filters[megtype] = {}\n",
    "    for src_type,src in srcd.items():\n",
    "        fname_full_inv = pjoin(data_dir,f'{rawname}_{src_type}_{megtype}-lcmv.h5')\n",
    "        if not recalc_lcmv:\n",
    "            filters = mne.beamformer.read_beamformer(fname_full_inv)\n",
    "        else:\n",
    "\n",
    "            fname_full_fwd = pjoin(data_dir,f'{rawname}_{src_type}_{megtype}-fwd.fif')\n",
    "        #fname_full_fwd = pjoin(data_dir,f'{rawname}_{megtype}-fwd.fif')\n",
    "            forward = mne.read_forward_solution(fname_full_fwd)\n",
    "\n",
    "            filters = make_lcmv(subraw.info, forward, megtype2data_cov[megtype],\n",
    "                                reg=0.05,\n",
    "                                noise_cov=noise_cov, pick_ori='max-power',\n",
    "                                weight_norm='unit-noise-gain', rank=None, depth=depth)        \n",
    "            filters.save(fname_full_inv, overwrite=True)\n",
    "        megtype2filters[megtype][src_type] = filters\n",
    "    \n",
    "megtype2stc = {}\n",
    "for megtype,subraw in megtype2subraw.items():\n",
    "    megtype2stc[megtype] = {}\n",
    "    for src_type,src in srcd.items():\n",
    "        stc = apply_lcmv_raw(subraw, megtype2filters[megtype][src_type])\n",
    "        megtype2stc[megtype][src_type] = stc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4022582c",
   "metadata": {},
   "source": [
    "### plot inverse solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155cf33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lims = [0.3, 0.45, 0.6]\n",
    "kwargs = dict(src=src, subject=subject, subjects_dir=subjects_dir,\n",
    "              initial_time=0.087, verbose=True)\n",
    "#clim=dict(kind='value', pos_lims=lims),\n",
    "stc.plot( **kwargs)\n",
    "#mode='stat_map', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db26e160",
   "metadata": {},
   "outputs": [],
   "source": [
    "stc.plot(mode='glass_brain', clim=dict(kind='value', lims=lims), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ac3071",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = stc_vec.plot_3d(\n",
    "    clim=dict(kind='value', lims=lims), hemi='both', size=(600, 600),\n",
    "    views=['sagittal'],\n",
    "    # Could do this for a 3-panel figure:\n",
    "    # view_layout='horizontal', views=['coronal', 'sagittal', 'axial'],\n",
    "    brain_kwargs=dict(silhouette=True),\n",
    "    **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba536c5",
   "metadata": {},
   "source": [
    "### Morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38f7167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ebb54a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca9ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(morph.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46877e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "morphd = {}\n",
    "for src_type,stc in d.items():\n",
    "    #stc = megtype2stc['mag']['cortex']\n",
    "    if src_type == 'cortex':\n",
    "        morph = mne.compute_source_morph(src_type, subject_from=subject,                        \n",
    "                             subjects_dir=subjects_dir, verbose=True)\n",
    "\n",
    "    else:\n",
    "        morph = mne.compute_source_morph(srcd[src_type], \n",
    "                subject_from=subject, subjects_dir=subjects_dir,\n",
    "        niter_affine=[10, 10, 5], niter_sdr=[10, 10, 5],  # just for speed\n",
    "        verbose=True)\n",
    "\n",
    "    fname_full_morph = pjoin(data_dir, f'{subject}_{src_type}-morph.h5' )\n",
    "    morph.save(fname_full_morph)\n",
    "    morphd[src_type] = morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe399837",
   "metadata": {},
   "outputs": [],
   "source": [
    "mne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db3975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subject_to='fsaverage', src_to=src_to,\n",
    "megtype2stc_fsav = {}\n",
    "for megtype,d in megtype2stc.items():\n",
    "    megtype2stc_fsav[megtype] = {}\n",
    "    for src_type,stc in d.items():\n",
    "        fname_full_morph = pjoin(data_dir, f'{subject}_{src_type}-morph.h5' )\n",
    "        #stc = megtype2stc['mag']['cortex']\n",
    "#         if src_type == 'cortex':\n",
    "#             morph = mne.compute_source_morph(stc, subject_from=subject,                        \n",
    "#                                  subjects_dir=subjects_dir, verbose=True)\n",
    "            \n",
    "#         else:\n",
    "#             morph = mne.compute_source_morph(srcd[src_type], \n",
    "#                     subject_from=subject, subjects_dir=subjects_dir,\n",
    "#             niter_affine=[10, 10, 5], niter_sdr=[10, 10, 5],  # just for speed\n",
    "#             verbose=True)\n",
    "            \n",
    "#         morph.save(pjoin(data_dir, f'{subject}_{src_type}'))\n",
    "        \n",
    "        morph = morphd[src_type]\n",
    "        stc_fsaverage = morph.apply(stc)\n",
    "        megtype2stc_fsav[megtype][src_type] = stc_fsaverage\n",
    "#src must be an instance of source space or surface source estimate, got <class 'mne.source_estimate.MixedSourceEstimate'> instead.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933a58b4",
   "metadata": {},
   "source": [
    "## Working with parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d991dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = mne.read_labels_from_annot(\n",
    "    'fsaverage', 'HCPMMP1_combined', 'lh', subjects_dir=subjects_dir)\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070d1b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0].subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ab1402",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_arg = labels # (aal_path,  atlas.labels[:3] )\n",
    "stc = megtype2stc_fsav['mag']['cortex']\n",
    "tca = mne.extract_label_time_course([stc], labels_arg,srcd['cortex'], \n",
    "                          mode = 'mean', allow_empty=False, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1034723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e83a6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inds_to_coords(i, j, k, affine):\n",
    "    \"\"\"\n",
    "    Return X, Y, Z coordinates for i, j, k\n",
    "    Parameters\n",
    "    ----------\n",
    "    i, j, k : int\n",
    "        indices for aal_img.get_fdata()\n",
    "    affine : np.array of shape (4, 4)\n",
    "        The affine transformation from indices to coordinates\n",
    "        given by nibabel.nifti1.Nifti1Image.affine\n",
    "    Returns\n",
    "    -------\n",
    "    coords : np.array of shape (3, )\n",
    "        The indices i, j, k transformed to coordinates in mm.\n",
    "    References\n",
    "    ----------\n",
    "    https://nipy.org/nibabel/coordinate_systems.html#applying-the-affine\n",
    "    \"\"\"\n",
    "\n",
    "    M = affine[:3, :3]\n",
    "    abc = affine[:3, 3]\n",
    "\n",
    "    return M.dot([i, j, k]) + abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d02acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from nilearn.datasets import fetch_atlas_aal\n",
    "mne_sample_data_path = mne.datasets.sample.data_path()\n",
    "atlas = fetch_atlas_aal(data_dir=mne_sample_data_path)\n",
    "maps = 'maps'\n",
    "atlas_img = nib.load(atlas[maps])\n",
    "\n",
    "value_to_label_dict = dict()\n",
    "for idx, label in enumerate(atlas['labels']):\n",
    "    value_to_label_dict[int(atlas['indices'][idx])] = label\n",
    "\n",
    "value_to_label_dict['0'] = 'Background'\n",
    "\n",
    "atlas_data = atlas_img.get_fdata()\n",
    "affine = atlas_img.affine\n",
    "\n",
    "mni_inuse = np.where(atlas_data > 0)\n",
    "# get for mni_inuse the label indices\n",
    "mni_label_inds = atlas_data[mni_inuse]\n",
    "\n",
    "print(atlas_img.affine.shape, atlas_img.header.get_xyzt_units())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de412b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_to_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2be2d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmax, ymax, zmax = atlas_data.shape\n",
    "\n",
    "coords_shape = list(atlas_data.shape)\n",
    "coords_shape.append(3)\n",
    "atlas_coords = np.empty(coords_shape)\n",
    "\n",
    "for idx_x in range(xmax):\n",
    "    for idx_y in range(ymax):\n",
    "        for idx_z in range(zmax):\n",
    "            atlas_coords[idx_x, idx_y, idx_z] = \\\n",
    "                inds_to_coords(idx_x, idx_y, idx_z, affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a8896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mni_label_inds = mni_label_inds.astype(int)\n",
    "atlas_data_i = atlas_data.astype(int)\n",
    "indsu = np.unique(atlas_data_i)\n",
    "\n",
    "d = {}\n",
    "for a in indsu:\n",
    "    indsofinds = np.where(atlas_data_i == a)\n",
    "    d[a] = indsofinds    \n",
    "    \n",
    "# atlas_coords[d[0]].shape #(717224, 3)\n",
    "# atlas_coords.shape #(91, 109, 91, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448de6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbls = []\n",
    "sidedict = {'L':'lh', 'R':'rh'}\n",
    "for a in indsu:\n",
    "    if a == 0:\n",
    "        continue\n",
    "    pos = atlas_coords[d[a]] / 1000.\n",
    "    label = value_to_label_dict[a]\n",
    "    print(label)\n",
    "    side = sidedict.get(label[-1],None)\n",
    "    if side is None:\n",
    "        continue\n",
    "    \n",
    "    lbl = mne.Label(vertices=np.arange(len(pos) ), pos=pos, name=label,\n",
    "              subject=subject, hemi=side)\n",
    "    lbls.append(lbl)\n",
    "    \n",
    "    #vertices array, shape (N,)\n",
    "    #    Vertex indices (0 based).\n",
    "\n",
    "\n",
    "    #vertices=(), pos=None, values=None, hemi=None, comment='', \n",
    "    # name=None, filename=None, subject=None, color=None, *, verbose=None\n",
    "\n",
    "    # verticesarray, shape (N,)\n",
    "\n",
    "    #     Vertex indices (0 based).\n",
    "    # posarray, shape (N, 3) | None\n",
    "\n",
    "    #     Locations in meters. If None, then zeros are used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aeccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_space[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8166b17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_space[0]['inuse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35f0601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q: is there a canonical space MNE refers points to?\n",
    "# Q: what are the labels one can use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf82dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_space.in_label()\n",
    "#Get a source estimate object restricted to a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4caf1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_src_vertno_sel(label, src):\n",
    "    \"\"\"Find vertex numbers and indices from label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c1bc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne import extract_label_time_course\n",
    "extract_label_time_course(stcs, lbls, src, mode='auto', allow_empty=False, \n",
    "                              return_generator=False, *, mri_resolution=True,\n",
    "                          verbose=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39011a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parc = 'aparc' \n",
    "labels_parc = mne.read_labels_from_annot(\n",
    "    subject, parc=parc, subjects_dir=subjects_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c97269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec0704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(['Frontal_Sup_Orb_L', 'Frontal_Mid_Orb_L', \n",
    "     'Frontal_Inf_Oper_L', 'Rolandic_Oper_L', \n",
    "     'Olfactory_L', 'Frontal_Med_Orb_L', 'Rectus_L', \n",
    "     'Cingulum_Post_L', 'Hippocampus_L', 'ParaHippocampal_L',\n",
    "     'Amygdala_L', 'Amygdala_R', 'Occipital_Inf_L', \n",
    "     'Angular_L', 'Caudate_L', 'Putamen_L', 'Pallidum_L', \n",
    "     'Pallidum_R', 'Thalamus_L', 'Heschl_L', 'Heschl_R', \n",
    "     'Temporal_Pole_Mid_L', \n",
    "     'Cerebelum_3_L', 'Cerebelum_3_R', 'Cerebelum_4_5_L',\n",
    "     'Cerebelum_7b_L', 'Cerebelum_9_L', 'Cerebelum_10_L', 'Cerebelum_10_R'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4415c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e25c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "aal_path = pjoin(mne_sample_data_path, 'aal_SPM12/aal/atlas/AAL.nii')\n",
    "\n",
    "#labels_arg -- a two-element list or tuple, the first element being a path to an atlas, \n",
    "# and the second being a list or dict of volume_labels to extract \n",
    "# (see mne.setup_volume_source_space() for details).\n",
    "\n",
    "# returns   label_tcarray | list (or generator) of array, shape (n_labels[, n_orient], n_times)\n",
    "#  Extracted time course for each label and source estimate.\n",
    "\n",
    "\n",
    "labels_arg = lbls # (aal_path,  atlas.labels[:3] )\n",
    "stc = megtype2stc['mag']\n",
    "tca = mne.extract_label_time_course([stc], labels_arg,source_space, \n",
    "                          mode = 'mean', allow_empty=False, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c30743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mne.extract_label_time_course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f079da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mne.datasets.fetch_hcp_mmp_parcellation(subjects_dir=subjects_dir,\n",
    "#                                         verbose=True)\n",
    "\n",
    "# mne.datasets.fetch_aparc_sub_parcellation(subjects_dir=subjects_dir,\n",
    "#                                           verbose=True)\n",
    "\n",
    "labels = mne.read_labels_from_annot(\n",
    "    'fsaverage', 'HCPMMP1', 'lh', subjects_dir=subjects_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc79d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = mne.read_labels_from_annot(\n",
    "    subject, 'aparc', 'lh', subjects_dir=subjects_dir)\n",
    "# No such file /home/demitau/data/subjects/S01/label/lh.HCPMMP1.annot, candidate parcellations in that directory:\n",
    "# aparc\n",
    "# aparc.a2009s\n",
    "# aparc.DKTatlas\n",
    "# BA_exvivo\n",
    "# BA_exvivo.thresh\n",
    "# mpm.vpnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85e9b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3586a899",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eab7b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = mne.read_labels_from_annot(\n",
    "    'fsaverage', 'HCPMMP1_combined', 'lh', subjects_dir=subjects_dir)\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87530f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[1] + labels[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9ae4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52f158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6d8117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch_fsaverage(subjects_dir)  # ensure fsaverage src exists\n",
    "# fname_fs_src = subjects_dir / 'fsaverage' / 'bem' / 'fsaverage-vol-5-src.fif'\n",
    "\n",
    "# src_fs = mne.read_source_spaces(fname_fs_src)\n",
    "# morph = mne.compute_source_morph(\n",
    "#     src, subject_from='sample', src_to=src_fs, subjects_dir=subjects_dir,\n",
    "#     niter_sdr=[5, 5, 2], niter_affine=[5, 5, 2], zooms=7,  # just for speed\n",
    "#     verbose=True)\n",
    "# stc_fs = morph.apply(stc)\n",
    "# del stc\n",
    "\n",
    "# stc_fs.plot(\n",
    "#     src=src_fs, mode='stat_map', initial_time=0.085, subjects_dir=subjects_dir,\n",
    "#     clim=dict(kind='value', pos_lims=lims), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63830c21",
   "metadata": {},
   "source": [
    "# Matlab code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74606f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_type = \"aal\"\n",
    "if strcmp(atlas_type, \"aal\")\n",
    "  aal = ft_read_atlas('~/soft/fieldtrip/template/atlas/aal/ROI_MNI_V4.nii');\n",
    "  atlas = aal;\n",
    "elseif strcmp(atlas_type, \"afni\")  % has Brodmann areas, no sides\n",
    "  afni = ft_read_atlas('~/soft/fieldtrip/template/atlas/afni/TTatlas+tlrc.HEAD');  % goes deeper in the sulcus\n",
    "  atlas = afni;\n",
    "end\n",
    "%singleshell = load('~/soft/fieldtrip/template/headmodel/standard_singleshell');\n",
    "source_grid = load('~/soft/fieldtrip/template/sourcemodel/standard_sourcemodel3d5mm');\n",
    "source_grid.sourcemodel.coordsys = 'mni';\n",
    "% pts_converted = mni2icbm_spm( pts )\n",
    "% atlas.  pts_converted = mni2icbm_spm( pts )\n",
    "atlas = ft_convert_units(atlas,'cm'); % ftrop and our sourcemodels have cm units\n",
    "atlas.coordsys = 'mni';\n",
    "\n",
    "% if roi is found in the atlas. Here I assume that if one is from the atlas than other rois too\n",
    "if isfield(atlas, \"tissuelabel\")\n",
    "  tlarr = atlas.tissuelabel;\n",
    "elseif isfield(atlas, \"brick0label\")  \n",
    "  tlarr = cat ( 1, {atlas.brick0label{:},atlas.brick1label{:} } );\n",
    "end\n",
    "\n",
    "read_upd_bads = 0;\n",
    "\n",
    "%TODO: first read and do reject artifact, then append data then call source reconstruction\n",
    "%cfg = [];\n",
    "%data_merged =  ft_appenddata(cfg, data1_resampled, data2);\n",
    "\n",
    "num_prcessed = 0;\n",
    "for rawi = 1:length(rawnames)\n",
    "  r = split(rawnames(rawi),'_');\n",
    "  subjstr = r(1); medstr=r(2); taskstr=r(3);\n",
    "\n",
    "%for subji = 1:length(subjstrs)\n",
    "%  subjstr = subjstrs(subji);\n",
    "  fprintf(\" current subjstr=%s\\n\",subjstr)\n",
    "\n",
    "  basename_head = sprintf('/headmodel_grid_%s.mat',subjstr);\n",
    "  fname_head = strcat(data_dir, basename_head );\n",
    "  hdmf = load(fname_head);   %hdmf.hdm, hdmf.mni_aligned_grid\n",
    "\n",
    "%  for medcondi = 1:length(medconds)\n",
    "%    medstr = medconds(medcondi);\n",
    "%    for taski = 1:length(tasks)\n",
    "%      taskstr = tasks(taski);\n",
    "\n",
    "      % rawnames_suffix starts with '_'\n",
    "      basename = sprintf('/%s_%s_%s%s.fif',subjstr,medstr,taskstr,rawname_suffix);\n",
    "\n",
    "      %if use_data_afterICA\n",
    "      %  basename = sprintf('/%s_%s_%s_resample_afterICA_raw.fif',subjstr,medstr,taskstr);\n",
    "      %else\n",
    "      %  % resample was notched but not highpassed\n",
    "      %  %basename = sprintf('/%s_%s_%s_resample_raw.fif',subjstr,medstr,taskstr);\n",
    "      %  basename = sprintf('/%s_%s_%s_resample_notch_highpass_raw.fif',subjstr,medstr,taskstr);\n",
    "      %end\n",
    "      fprintf(\" Using basename=%s\\n\",basename)\n",
    "      %basename = sprintf('/%s_%s_%s_resample_maxwell_raw.fif',subjstr,medstr,taskstr);\n",
    "      fname = fullfile(data_dir, input_subdir, basename );\n",
    "      if isfile(fname)   % if file exists\n",
    "        fprintf(\"%s\\n\",fname)\n",
    "\n",
    "        cfgload = [];\n",
    "        cfgload.dataset = char(fname);          % fname should be char array (single quotes), not string (double quotes)\n",
    "        cfgload.chantype = {'meg'};\n",
    "        cfgload.coilaccuracy = 1;   % 0 1 or 2, idk what each of them means -- it is about combining grad and mag\n",
    "\n",
    "        %cfgload.hpfilter = 'yes';\n",
    "        %cfgload.hpfreq = highpass_freq;  % NO, I don't want to do it in FT because it will not take care of artifacts\n",
    "\n",
    "        datall_ = ft_preprocessing(cfgload);   \n",
    "\n",
    "        bads = {};\n",
    "        if isfield(Info, subjstr)\n",
    "          if isfield(Info.(subjstr).bad_channels, medstr) &&  isfield(Info.(subjstr).bad_channels.(medstr), taskstr)\n",
    "            bads = Info.(subjstr).bad_channels.(medstr).(taskstr);\n",
    "          end\n",
    "\n",
    "          if read_upd_bads;\n",
    "              fname_bads_mat = sprintf('%s_MEGch_bads_upd.mat',fname_noext);\n",
    "              fname_bads_mat_full = fullfile( data_dir, fname_bads_mat);\n",
    "              bads_upd = load(fname_bads_mat_full).bads;\n",
    "              bads = bads_upd;\n",
    "          end\n",
    "        else\n",
    "          fprintf('!!!! Info.mat does not contain %s field, assuming no bad channels',subjstr)\n",
    "        end\n",
    "\n",
    "        chanselarr = {'meg'};\n",
    "        if remove_bad_channels && length(bads) > 0\n",
    "          for chani = 1:length(bads)\n",
    "            chanselarr{chani + 1} = sprintf('-%s',bads{chani});   % marks channel for removal from seelction\n",
    "          end\n",
    "        end\n",
    "\n",
    "        selchan = ft_channelselection(chanselarr, datall_.label);\n",
    "        bads = {};\n",
    "        % I could also do ft_repairchannel\n",
    "        \n",
    "        cfgsel = [];\n",
    "        cfgsel.channel = selchan;\n",
    "        datall  = ft_selectdata(cfgsel, datall_);\n",
    "\n",
    "        %else\n",
    "        %  datall  = datall_;\n",
    "        %end\n",
    "\n",
    "        %if use_data_afterICA  % because we also do SSS which restores bad channels\n",
    "        %  bads = {}\n",
    "        %end\n",
    "        %else\n",
    "        %  datall  = datall_;\n",
    "        %end\n",
    "\n",
    "\n",
    "        %deal with artifacts\n",
    "        %fname_srcrec_exclude = sprintf('/%s_%s_%s_ann_MEGartif.txt', subjstr,medstr,taskstr);\n",
    "        fname_srcrec_exclude = sprintf('/%s_%s_%s_ann_srcrec_exclude.txt', subjstr,medstr,taskstr);\n",
    "        filename      = fullfile(data_dir,fname_srcrec_exclude);\n",
    "        FID = fopen(filename);\n",
    "        fgets(FID); fgets(FID); % skip first 2 lines\n",
    "        form='%f,%f,%s'; % we have 7 columns, then use 7 %f\n",
    "        out = textscan(FID, form);\n",
    "        times_artif = [ out{1}, out{1}+out{2} ];  %third column is interval type, which I don't need\n",
    "        bins_artif = datall_.fsample * times_artif;  \n",
    "        bins_artif = 1 + round(bins_artif);\n",
    "        %bins_artif = times_artif;\n",
    "        fclose(FID);\n",
    "\n",
    "\n",
    "        cfg_ar = [];\n",
    "        cfg_ar.artfctdef.imported.artifact = bins_artif;\n",
    "        %cfg_ar.artfctdef.muscle.artifact = bins_artif;\n",
    "\n",
    "        cfg_ar.artfctdef.reject          = 'partial';\n",
    "        %cfg_ar.artfctdef.reject          = 'nan';\n",
    "        %cfg_ar.artfctdef.reject          = 'value';\n",
    "        %cfg_ar.artfctdef.value           = 1e-2\n",
    "\n",
    "        cfg_ar.artfctdef.minaccepttim    = 1; %min length of remaining trial in seconds\n",
    "        %   cfg.artfctdef.feedback        = 'yes' or 'no' (default = 'no')\n",
    "        %   cfg.artfctdef.invert          = 'yes' or 'no' (default = 'no') -- invert artifact selection\n",
    "        \n",
    "        % unfortunately it cannot reduce trial size, just throw away it \n",
    "        % completely, so I do some dirty work later        \n",
    "        data_cleaned = ft_rejectartifact(cfg_ar,datall) \n",
    "        %return\n",
    "\n",
    "        for roii = 1:length(roi) \n",
    "          roicur = roi{roii};\n",
    "\n",
    "          % scaling matrix, no longer used, kept for compatibility\n",
    "          if isKey(f_scalemat.scalemat,subjstr)\n",
    "            S = f_scalemat.scalemat(subjstr);\n",
    "          else\n",
    "            S = eye(3);\n",
    "          end\n",
    "\n",
    "          % do we find roi in the atlas?\n",
    "          roimask = contains(cellstr(tlarr), roicur );\n",
    "          if sum(roimask) == 1 \n",
    "            cfg_vlookup = [];\n",
    "            cfg_vlookup.atlas = atlas;\n",
    "            cfg_vlookup.roi = roi;\n",
    "            %cfg_vlookup.roi = atlas.tissuelabel; % this would lookup for all possible\n",
    "            cfg_vlookup.inputcoord = 'mni';  % coord of the source\n",
    "            %cfg_vlookup.inputcoord = 'tal';\n",
    "            source_grid_mask = ft_volumelookup(cfg_vlookup,source_grid.sourcemodel);  % selecting only a subset\n",
    "            fprintf(\"%s: Num of sources = %d\\n\",roicur,sum(source_grid_mask) )\n",
    "          else\n",
    "            fprintf(\"%s not found in atlas\\n\",roicur )\n",
    "            source_grid_mask = [];\n",
    "          end\n",
    "\n",
    "          source_data = srcrec(subjstr,datall,data_cleaned,hdmf,{roicur},bads,S,source_grid,source_grid_mask,use_DICS);\n",
    "\n",
    "          for fbi = 1:length(source_data) \n",
    "            source_data{fbi}.source_data.roi = {roicur};\n",
    "          end\n",
    "\n",
    "          if save_srcrec\n",
    "            basename_srcd = sprintf(\"/srcd_%s_%s_%s_%s%s.mat\",subjstr,medstr,taskstr,roicur,resname_add_str);\n",
    "            %data_dir_out = strcat(\n",
    "            fname_srcd = fullfile(data_dir, output_subdir, basename_srcd );\n",
    "            fprintf(\"Saving to %s\\n\",fname_srcd)\n",
    "            save(fname_srcd,\"source_data\",\"-v7.3\");\n",
    "          end\n",
    "        end\n",
    "      else\n",
    "        fprintf(\" file not found! %s\",fname)\n",
    "      end\n",
    "%    end\n",
    "%  end\n",
    " \n",
    "  num_prcessed = num_prcessed + 1;\n",
    "end\n",
    "\n",
    "if num_prcessed == 0\n",
    "  fprintf('AAAAAA')\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_oscbagdis",
   "language": "python",
   "name": "conda_oscbagdis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
