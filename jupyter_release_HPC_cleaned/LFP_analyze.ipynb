{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "\n",
    "code_dir = os.path.expandvars('$OSCBAGDIS_DATAPROC_CODE')\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "import mne\n",
    "import utils  #my code\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "if os.environ.get('DATA_DUSS') is not None:\n",
    "    data_dir = os.path.expandvars('$DATA_DUSS')\n",
    "else:\n",
    "    data_dir = '/home/demitau/data'\n",
    "    \n",
    "\n",
    "\n",
    "#rawname_ = 'S01_off_hold'\n",
    "#rawname_ = 'S01_off_move'\n",
    "#rawname_ = 'S01_on_hold'\n",
    "#rawname_ = 'S01_on_move'\n",
    "\n",
    "#rawname_ = 'S02_off_hold'\n",
    "#rawname_ = 'S02_off_move'\n",
    "#rawname_ = 'S02_on_hold'\n",
    "#rawname_ = 'S02_on_move'\n",
    "\n",
    "#rawname_ = 'S03_off_hold'\n",
    "#rawname_ = 'S03_off_move'\n",
    "\n",
    "#rawname_ = 'S04_off_hold'\n",
    "#rawname_ = 'S04_off_move'\n",
    "#rawname_ = 'S04_on_hold'\n",
    "#rawname_ = 'S04_on_move'\n",
    "\n",
    "#rawname_ = 'S05_off_hold'\n",
    "#rawname_ = 'S05_off_move'\n",
    "#rawname_ = 'S05_on_hold'\n",
    "#rawname_ = 'S05_on_move'\n",
    "\n",
    "# rawname_ = 'S06_off_hold'\n",
    "# rawname_ = 'S06_off_move'\n",
    "# rawname_ = 'S06_on_hold'\n",
    "#rawname_ = 'S06_on_move'\n",
    "\n",
    "#rawname_ = 'S07_off_hold'\n",
    "#rawname_ = 'S07_off_move'\n",
    "#rawname_ = 'S07_on_hold'\n",
    "#rawname_ = 'S07_on_move'\n",
    "\n",
    "#rawname_ = 'S08_off_rest'\n",
    "#rawname_ = 'S08_on_rest'\n",
    "\n",
    "#rawname_ = 'S09_off_rest'\n",
    "\n",
    "#rawname_ = 'S10_off_rest'\n",
    "#rawname_ = 'S10_off_move'\n",
    "\n",
    "rawname_ = 'S99_off_move'\n",
    "\n",
    "rawname = rawname_ + '_resample_raw.fif'\n",
    "fname_full = os.path.join(data_dir,rawname)\n",
    "    \n",
    "# read file -- resampled to 256 Hz,  Electa MEG, EMG, LFP, EOG channels\n",
    "raw = mne.io.read_raw_fif(fname_full, None)\n",
    "sfreq = raw.info['sfreq']\n",
    "\n",
    "import utils_preproc as upre\n",
    "mod_info, infos = upre.readInfo(rawname_, raw)\n",
    "raw.info = mod_info\n",
    "\n",
    "anns_fn = rawname_ + '_anns.txt'\n",
    "anns_fn_full = os.path.join(data_dir, anns_fn)\n",
    "anns = mne.read_annotations(anns_fn_full)\n",
    "raw.set_annotations(anns)\n",
    "\n",
    "# get info about bad MEG channels (from separate file)\n",
    "with open('subj_info.json') as info_json:\n",
    "        #raise TypeError\n",
    "\n",
    "    #json.dumps({'value': numpy.int64(42)}, default=convert)\n",
    "    gen_subj_info = json.load(info_json)\n",
    "    \n",
    "subj,medcond,task  = utils.getParamsFromRawname(rawname_)\n",
    "subj_num = int(subj[1:])\n",
    "if subj_num < 8:\n",
    "    badchlist = gen_subj_info[subj]['bad_channels'][medcond][task]\n",
    "else:\n",
    "    badchlist = gen_subj_info[subj]['bad_channels'][medcond]['hold']\n",
    "raw.info['bads'] = badchlist\n",
    "print('bad channels are ',badchlist)\n",
    "for chn in badchlist:\n",
    "    if chn.find('LFP') >= 0:\n",
    "        print('WARNING: bad LFP channel: {}'.format(chn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw.annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import utils\n",
    "# trem_times_fn = 'trem_times_tau.json'\n",
    "# with open(trem_times_fn ) as jf:\n",
    "#     trem_times_byhand = json.load(jf)   \n",
    "# trem_times_nms_fn = 'trem_times_tau_nms.json'\n",
    "# with open(trem_times_nms_fn ) as jf:\n",
    "#     trem_times_nms_byhand = json.load(jf)   \n",
    "\n",
    "# #%debug\n",
    "# tremIntervalJan, artif         = utils.unpackTimeIntervals(trem_times_byhand, mainSide = True, \n",
    "#                                                            gen_subj_info=gen_subj_info, skipNotLoadedRaws=0)\n",
    "# tremIntervalJan_nms, artif_nms = utils.unpackTimeIntervals(trem_times_nms_byhand, mainSide = False, \n",
    "#                                                            gen_subj_info=gen_subj_info, skipNotLoadedRaws=0)\n",
    "# for rawn in [rawname_]:\n",
    "#     if rawn in artif_nms and rawn not in artif:\n",
    "#         artif[rawn] = artif_nms[rawn]\n",
    "#     else:\n",
    "#         if rawn in artif_nms:\n",
    "#             artif[rawn].update(artif_nms[rawn] )\n",
    "        \n",
    "# for rawn in tremIntervalJan:\n",
    "#     sind_str,medcond,task = utils.getParamsFromRawname(rawn)\n",
    "#     maintremside = gen_subj_info[sind_str]['tremor_side']\n",
    "#     opside= utils.getOppositeSideStr(maintremside)\n",
    "#     if rawn in tremIntervalJan_nms:\n",
    "#         tremIntervalJan[rawn][opside] = tremIntervalJan_nms[rawn][opside] \n",
    "\n",
    "\n",
    "# mvtTypes = ['tremor', 'no_tremor', 'unk_activity']\n",
    "\n",
    "# plotTremNegOffset = 2.\n",
    "# plotTremPosOffset = 2.\n",
    "# maxPlotLen = 6   # for those interval that are made for plotting, not touching intervals for stats\n",
    "# addIntLenStat = 5\n",
    "# plot_time_end = 150\n",
    "\n",
    "# timeIntervalPerRaw_processed = utils.processJanIntervals(tremIntervalJan, maxPlotLen, addIntLenStat, \n",
    "#                           plotTremNegOffset, plotTremPosOffset, plot_time_end, mvtTypes=mvtTypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for current raw\n",
    "maintremside = gen_subj_info[subj]['tremor_side']\n",
    "mts_letter = maintremside[0].upper()\n",
    "print(maintremside)\n",
    "\n",
    "#raw.info['bads'] = []\n",
    "\n",
    "raw_lfponly = raw.copy()\n",
    "raw_lfponly.info['bads'] = []\n",
    "#raw_lfponly.crop(0,300)\n",
    "raw_lfponly.load_data()\n",
    "\n",
    "#hand_side = 'L'\n",
    "#hand_side = 'R'\n",
    "hand_side = ''\n",
    "\n",
    "if hand_side == 'L':\n",
    "    brain_side  = 'R'\n",
    "elif hand_side == 'R':\n",
    "    brain_side  = 'L'\n",
    "else:\n",
    "    brain_side = ''\n",
    "chis = mne.pick_channels_regexp(raw.ch_names, 'LFP{}.*'.format(brain_side))\n",
    "chnames_lfp = [raw.ch_names[chi] for chi in chis]\n",
    "print(chnames_lfp)\n",
    "\n",
    "raw_lfponly.pick_channels(   chnames_lfp  )\n",
    "print(raw_lfponly.ch_names)\n",
    "\n",
    "print( raw_lfponly.get_channel_types() )\n",
    "\n",
    "y = {}\n",
    "for chname in raw_lfponly.ch_names:\n",
    "    y[chname] = 'eeg'\n",
    "raw_lfponly.set_channel_types(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_info_fname_noext = rawname_ + '_supp_info'\n",
    "supp_info_fname = supp_info_fname_noext + '.npz'\n",
    "supp_info_fname_full = os.path.join(data_dir,supp_info_fname)\n",
    "supp_info = np.load(supp_info_fname_full,allow_pickle=1)['supp_info'][()]\n",
    "pairs = supp_info['artfiacts_intervals_LFP']\n",
    "anns_LFPartif = utils.intervals2anns(pairs,int_name='BAD_LFP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raws = {}\n",
    "raws['untouched'] = raw_lfponly\n",
    "\n",
    "cutoff_freq = 2\n",
    "rawcur = raw_lfponly.copy()\n",
    "freqsToKill = np.arange(50, 128, 50) # harmonics of 50\n",
    "rawcur.notch_filter(freqsToKill, picks=['eeg'])\n",
    "raws['raw_lfponly_notched'] = rawcur\n",
    "\n",
    "rawcur = raws['raw_lfponly_notched'].copy()\n",
    "rawcur.filter(l_freq=cutoff_freq,h_freq=None)\n",
    "raws['raw_lfponly_notched_filtered'] = rawcur\n",
    "\n",
    "rawcur = raws['raw_lfponly_notched'].copy()\n",
    "pad_type = 'symmetric'\n",
    "rawcur.filter(l_freq=cutoff_freq,h_freq=None,pad=pad_type)\n",
    "raws['raw_lfponly_notched_filtered_pad={}'.format(pad_type)] = rawcur\n",
    "\n",
    "rawcur = raws['raw_lfponly_notched'].copy()\n",
    "rawcur.set_annotations(anns_LFPartif)\n",
    "rawcur.filter(l_freq=cutoff_freq,h_freq=None,pad=pad_type,\n",
    "                                         skip_by_annotation='BAD_LFP')\n",
    "raws['raw_lfponly_notched_filtered_safe_pad={}'.format(pad_type)] = rawcur\n",
    "\n",
    "#%matplotlib qt\n",
    "\n",
    "#help(raw_lfponly.plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chn = 'LFPR01'\n",
    "figsz = (12,3)\n",
    "for rl in raws:\n",
    "    r = raws[rl]\n",
    "    chd,ts = r[chn]\n",
    "    plt.figure(figsize=figsz)\n",
    "    plt.plot(ts,chd[0])\n",
    "    #plt.xlim(5.6,12.5)\n",
    "    plt.title(rl)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawbest = raws['raw_lfponly_notched_filtered_safe_pad=symmetric'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = rawbest.get_data()\n",
    "\n",
    "%matplotlib inline\n",
    "raw_lfponly.plot_psd(fmin=0,fmax=30);\n",
    "\n",
    "#%matplotlib inline\n",
    "raw_lfponly.plot_psd(fmin=30,fmax=sfreq/2);\n",
    "#raw_lfponly.filter(l_freq=cutoff_freq,h_freq=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(raw_lfponly.plot_psd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawname_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chi in range(len(rawbest.ch_names)):\n",
    "    chn = rawbest.ch_names[chi]\n",
    "    #raw_lfponly.plot_psd(fmin=0,fmax=30, picks=chn);\n",
    "    fig = rawbest.plot_psd(fmin=0, picks=chn, show=False);\n",
    "    #fig.suptitle(chn)\n",
    "    fig.gca().set_title(chn)\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawname_LFPonly = rawname_ + '_LFPonly'+ '.fif'\n",
    "rawname_LFPonly_full = os.path.join( data_dir, rawname_LFPonly )\n",
    "rawbest.save(rawname_LFPonly_full,overwrite=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_lfponly.ch_names)\n",
    "chdata = raw_lfponly.get_data()\n",
    "\n",
    "#chdata = chdata[:,:256*20]\n",
    "\n",
    "#pha.shape\n",
    "\n",
    "#amp.shape\n",
    "plt.figure(figsize=(15,5))\n",
    "ax = plt.gca()\n",
    "sh = 0\n",
    "for chi in range(len(chdata) ):\n",
    "    dd = chdata[chi,:]\n",
    "    dd = np.diff(dd)\n",
    "    ax.plot(raw.times[1:],dd + sh, label=raw_lfponly.ch_names[chi])\n",
    "    sh += ( np.quantile(dd,.95)-np.quantile(dd,.05) ) * 2.3\n",
    "    \n",
    "ax.legend(loc='upper right')\n",
    "ax.set_xlim(raw.times[0],raw.times[-1])\n",
    "plt.suptitle('Raw diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rawbest.ch_names)\n",
    "chdata = rawbest.get_data()\n",
    "\n",
    "#chdata = chdata[:,:256*20]\n",
    "\n",
    "#pha.shape\n",
    "\n",
    "#amp.shape\n",
    "plt.figure(figsize=(15,5))\n",
    "ax = plt.gca()\n",
    "sh = 0\n",
    "for chi in range(len(chdata) ):\n",
    "    dd = chdata[chi,:]\n",
    "    ax.plot(raw.times,dd + sh, label=rawbest.ch_names[chi])\n",
    "    sh += ( np.quantile(dd,.95)-np.quantile(dd,.05) ) * 2.3\n",
    "    \n",
    "ax.legend(loc='upper right')\n",
    "ax.set_xlim(raw.times[0],raw.times[-1])\n",
    "plt.suptitle('Raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_lfponly = rawbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import globvars as gv\n",
    "#gv.fbands\n",
    "fbands_to_use = ['tremor', 'beta', 'gamma'] #, 'HFO']\n",
    "\n",
    "raw_per_fb = {}\n",
    "for fbcur in fbands_to_use:\n",
    "    fb0,fb1 = gv.fbands[fbcur]\n",
    "    raw_lfponly_cb = raw_lfponly.copy()\n",
    "    raw_lfponly_cb.filter(l_freq=fb0,h_freq=fb1)\n",
    "    raw_per_fb[fbcur] = raw_lfponly_cb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "print(maintremside)\n",
    "\n",
    "y = filter(lambda x: x.startswith('LFP'), badchlist)\n",
    "list(y)\n",
    "\n",
    "print(badchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt\n",
    "#raw_lfponly.plot(duration = 50, scalings={'eeg':'auto'} );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(anns.description)\n",
    "\n",
    "onset = []\n",
    "dur = []\n",
    "descr = []\n",
    "for i,ann in enumerate(raw_lfponly.annotations):\n",
    "    if ann['description'].find('_{}'.format(mts_letter)) >= 0:\n",
    "        onset.append(ann['onset'])\n",
    "        dur.append(ann['duration'])\n",
    "        descr.append(ann['description'])\n",
    "ann_mainside = mne.Annotations(onset,dur,descr)\n",
    "print(ann_mainside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maintremside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt\n",
    "raw_per_fb['beta'].set_annotations( ann_mainside)\n",
    "#raw_per_fb['beta'].plot(duration = 50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt\n",
    "raw_per_fb['gamma'].set_annotations( ann_mainside)\n",
    "#raw_per_fb['gamma'].plot(duration = 50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(plt.hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata_flt = raw_lfponly.get_data()\n",
    "rawdata_flt.shape\n",
    "\n",
    "pctshift = 1\n",
    "pct = [pctshift, 100-pctshift]\n",
    "b0 = np.inf; b1 = -np.inf\n",
    "center = 0\n",
    "normalize = 0\n",
    "for ind in range(rawdata_flt.shape[0] ):\n",
    "    cd = rawdata_flt[ind].copy()\n",
    "    if center:\n",
    "        cd -= np.mean(cd)\n",
    "    if normalize:\n",
    "        b0_,b1_ = np.percentile(cd, pct)\n",
    "        cd /= (b1_-b0_)\n",
    "    b0_,b1_ = np.percentile(cd, pct)\n",
    "    plt.hist(cd, bins=100, alpha=0.7, \n",
    "             label='{}'.format(raw_lfponly.ch_names[ind]), range=(b0_,b1_))\n",
    "    b0 = min(b0,b0_)\n",
    "    b1 = max(b1,b1_)\n",
    "plt.xlim(b0,b1)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(mne.time_frequency.tfr_array_multitaper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsz_sec = 1\n",
    "wsz_bins = wsz_sec * int(sfreq)\n",
    "\n",
    "# I want 256 window sz\n",
    "cf =  wsz_bins/ ( 5/(2*np.pi) * wsz_bins  ) \n",
    "print(cf)\n",
    "\n",
    "#help(raw_lfponly.get_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strec = 0\n",
    "# endrec = raw_lfponly.times[-1]\n",
    "# epdur = endrec\n",
    "# events_one = mne.make_fixed_length_events(raw_lfponly, start=strec, stop=endrec, duration=epdur)\n",
    "# epochs_one = mne.Epochs(raw_lfponly,events_one, tmin=0,tmax = epdur, baseline=None)\n",
    "decim = 8\n",
    "#tfr_array_morlet\n",
    "min_freq = 3\n",
    "freq_step = 2\n",
    "freqs = np.arange(min_freq,100,freq_step)\n",
    "#freq2cycles_mult = 0.75\n",
    "freq2cycles_mult = cf  # 1.2566370614359172\n",
    "# tfrres = mne.time_frequency.tfr_array_morlet(raw_lfponly.get_data()[None,:], \n",
    "#     raw.info['sfreq'], freqs, freqs * freq2cycles_mult, n_jobs=10, decim = decim)\n",
    "tfrres = mne.time_frequency.tfr_array_multitaper(raw_lfponly.get_data()[None,:], \n",
    "        raw.info['sfreq'], freqs, freqs * freq2cycles_mult, n_jobs=10, decim = decim)\n",
    "tfrres = tfrres[0]\n",
    "\n",
    "times = raw_lfponly.times[::decim]\n",
    "print( tfrres.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "baseline = [times[0],times[-1]]\n",
    "#baseline = [400,600]\n",
    "nr = len(tfrres)\n",
    "hh = 3\n",
    "fig,axs = plt.subplots(nr, 1, figsize=(24,hh*nr))\n",
    "plt.subplots_adjust(right=0.99,left=0.05,top=0.96,bottom=0.03)\n",
    "import matplotlib as mpl\n",
    "baseline_bins = np.where(np.logical_and(times>= baseline[0], times< baseline[1] ) )[0]\n",
    "for i in range(nr):\n",
    "    ax = axs[i]\n",
    "    dat_ = np.abs( tfrres[i] )\n",
    "    qs = np.percentile(dat_[:,baseline_bins], [5,95])\n",
    "    norm = mpl.colors.LogNorm(vmin = qs[0], vmax = qs[1])\n",
    "    ax.pcolormesh(raw.times[::decim], freqs, dat_, norm=norm )\n",
    "    ax.set_ylabel(raw_lfponly.ch_names[i])\n",
    "plt.savefig(os.path.join(gv.dir_fig, '{}_LFP_TFR.png'.format(rawname_)) )\n",
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "print(raw.info['bads'])\n",
    "print(gen_subj_info[subj].get('bad_lfp', None ) )\n",
    "print(gen_subj_info[subj]['lfpchan_used_in_paper'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rawname_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFR Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure()\n",
    "nshow = 7\n",
    "\n",
    "nr = len(tfrres)\n",
    "hh = 3\n",
    "fig,axs = plt.subplots(nr, 1, figsize=(15,hh*nr), sharex='col')\n",
    "import matplotlib as mpl\n",
    "for i in range(nr):\n",
    "    ax = axs[i]\n",
    "    #N =  tfres_.shape[0] \n",
    "    dat_ = np.abs( tfrres[i] )\n",
    "    #qs = np.percentile(dat_, [5,95])\n",
    "    #norm = mpl.colors.LogNorm(vmin = qs[0], vmax = qs[1])\n",
    "    for ind in range( 0, len(freqs), len(freqs)//nshow ):\n",
    "        ax.hist( np.abs( dat_[ind] ) , bins=100, alpha=0.7, \n",
    "               label='{:.1f}'.format(freqs[ind]))\n",
    "    ax.set_ylabel(raw_lfponly.ch_names[i])\n",
    "    ax.legend(loc='upper right')\n",
    "import gc; gc.collect()    \n",
    "    \n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look if we have something evidently weird in ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfrres.shape\n",
    "\n",
    "#np.abs( tfrres[i].T )[256:-256].shape\n",
    "\n",
    "#tfrres[i].shape\n",
    "\n",
    "n_edge_bins_TFR = wsz_bins // decim\n",
    "print(n_edge_bins_TFR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICA per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "ica_res = []\n",
    "n_components = 3\n",
    "for i in range(len(tfrres)):\n",
    "    Xfull = tfrres[i].T [n_edge_bins_TFR:-n_edge_bins_TFR]  # to avaoid edge artifact due to wavelet computation\n",
    "    print(i)\n",
    "    if decim == 1:\n",
    "        skip = 10\n",
    "    else:\n",
    "        skip = 1\n",
    "    X = np.log( np.abs( Xfull[::skip] ) )\n",
    "    Xtimes = times[n_edge_bins_TFR:-n_edge_bins_TFR:skip]\n",
    "    #print(X.shape, Xtimes.shape)\n",
    "    assert(X.shape[0] == len(Xtimes)),   [X.shape, Xtimes.shape]\n",
    "\n",
    "    ica = FastICA(n_components=n_components, random_state=0)\n",
    "    S_ = ica.fit_transform(X)  \n",
    "    ica_res += [S_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "hh=3\n",
    "nr = len(ica_res)\n",
    "fig,axs = plt.subplots(nr, 1, figsize=(24,hh*nr))\n",
    "plt.subplots_adjust(right=0.99,left=0.05,top=0.96,bottom=0.03)\n",
    "    \n",
    "for chi in range(len(ica_res)):\n",
    "    S_ = ica_res[chi]\n",
    "    sh = 0.07\n",
    "    #descrs = ['trem']\n",
    "    #plt.figure(figsize=(15,2))\n",
    "    ax = axs[chi]\n",
    "    for i in range(S_.shape[-1]):\n",
    "        ax.plot(Xtimes, S_[:,i] + i*sh, label=str(i))\n",
    "        ax.set_ylabel('{} = {}'.format(chi,raw_lfponly.ch_names[chi]) )\n",
    "        ax.set_xlim(Xtimes[0],Xtimes[-1])\n",
    "        #for i in ivalis\n",
    "    ax.legend(loc='upper left')\n",
    "        \n",
    "plt.savefig(os.path.join(gv.dir_fig, '{}_LFP_ICA_per_chan.png'.format(rawname_)) )\n",
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICA per brain side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chns_perside = {}\n",
    "chis_perside = {}\n",
    "for side in ['R', 'L']:\n",
    "    sidelet = side\n",
    "    chis = mne.pick_channels_regexp(raw_lfponly.ch_names, 'LFP'+sidelet)\n",
    "    chis_perside[side] = chis\n",
    "    chns_perside[side] = [raw_lfponly.ch_names[i] for i in chis]\n",
    "print(chns_perside)\n",
    "\n",
    "#tfrres[ chis_perside['L'] ].shape\n",
    "#help(tfrres.reshape)\n",
    "n_components = 3\n",
    "\n",
    "ica_res_perside = {}\n",
    "for side in chns_perside:\n",
    "    predat =  tfrres[ chis_perside[side] ]\n",
    "    predat = predat.reshape( (predat.shape[0] * predat.shape[1], predat.shape[2]) )\n",
    "    Xfull = predat.T [n_edge_bins_TFR:-n_edge_bins_TFR]  # to avaoid edge artifact due to wavelet computation\n",
    "\n",
    "    if decim == 1:\n",
    "        skip = 10\n",
    "    else:\n",
    "        skip = 1\n",
    "    X = np.log( np.abs( Xfull[::skip] ) )\n",
    "    Xtimes = times[n_edge_bins_TFR:-n_edge_bins_TFR:skip]\n",
    "    print(X.shape, Xtimes.shape)\n",
    "\n",
    "\n",
    "    ica = FastICA(n_components=n_components, random_state=0)\n",
    "    S_ = ica.fit_transform(X)  \n",
    "    ica_res_perside[side] = S_\n",
    "\n",
    "%matplotlib inline\n",
    "for side in chns_perside:\n",
    "    S_ = ica_res_perside[side]\n",
    "    sh = 0.07\n",
    "    #descrs = ['trem']\n",
    "    plt.figure(figsize=(15,3))\n",
    "    ax = plt.gca()\n",
    "    for i in range(S_.shape[-1]):\n",
    "        ax.plot(Xtimes, S_[:,i] + i*sh, label=str(i))\n",
    "        ax.set_ylabel(side)\n",
    "        ax.set_xlim(Xtimes[0],Xtimes[-1])\n",
    "        #for i in ivalis\n",
    "    ax.legend(loc='upper left')\n",
    "\n",
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( S_.shape )\n",
    "\n",
    "#%matplotlib qt\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( rawname_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wsz_bins = 256\n",
    "# decim = 8\n",
    "#print( width_conv_bins )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control detection of thr crossing for name something artifact (for the component)\n",
    "mults = [2.5 ] * len(ica_res)  \n",
    "# controls where the mean it taken from when centering the component\n",
    "baselines = [[200,250]] * len(ica_res)\n",
    "# controls \n",
    "width_conv_sec = 0.5\n",
    "width_conv_bins = int( wsz_bins / decim * width_conv_sec )\n",
    "print('width_conv_bins = ',width_conv_bins)\n",
    "thr = 2 / width_conv_bins; \n",
    "#extFactorLs = [-0.3] * len(ica_res); extFactorRs = [-0.1] * len(ica_res)\n",
    "extFactorLs = [0.1] * len(ica_res); extFactorRs = [0.1] * len(ica_res)\n",
    "percentthr = 0.9\n",
    "ind_component_to_use_per_channel = [[0]] * len(ica_res)\n",
    "if rawname_ == 'S02_off_hold':\n",
    "    baselines = [[0,250]] * len(ica_res)\n",
    "    mults[1] = 2.2\n",
    "    extFactorLs[1] = 0\n",
    "    extFactorRs[1] = 0\n",
    "    ind_component_to_use_per_channel[3] = [2]\n",
    "    ind_component_to_use_per_channel[4] = [2]\n",
    "if rawname_ == 'S02_off_move':\n",
    "    baselines = [[200,400]] * len(ica_res)\n",
    "    ind_component_to_use_per_channel[1] = [1]\n",
    "    ind_component_to_use_per_channel[3] = [2]\n",
    "    ind_component_to_use_per_channel[4] = [1]\n",
    "if rawname_ == 'S02_on_hold':\n",
    "    baselines = [[700,times[-1]]] * len(ica_res)\n",
    "    ind_component_to_use_per_channel[0] = [1]\n",
    "    ind_component_to_use_per_channel[1] = [1]\n",
    "    ind_component_to_use_per_channel[3] = [2]\n",
    "if rawname_ == 'S01_on_move':\n",
    "    mults = [3 ] * len(mults)\n",
    "    baselines = [[0,100]] * len(ica_res)  # first you plot with some values then set it\n",
    "    #thr = 0.05\n",
    "    #width_conv_bins=100\n",
    "if rawname_ == 'S03_off_hold':\n",
    "    baselines = [[400,800]] * len(ica_res)  # first you plot with some values then set it\n",
    "if rawname_ == 'S03_off_move':\n",
    "    baselines = [[100,550]] * len(ica_res) \n",
    "    ind_component_to_use_per_channel[3] = [1]\n",
    "    ind_component_to_use_per_channel[4] = [1]\n",
    "    ind_component_to_use_per_channel[5] = [0,2]\n",
    "if rawname_ == 'S04_off_hold':\n",
    "    baselines = [[320,470]] * len(ica_res) \n",
    "    mults[0] = 3\n",
    "    mults[4] = 4\n",
    "    ind_component_to_use_per_channel[0] = [1]\n",
    "    ind_component_to_use_per_channel[3] = [1]\n",
    "    ind_component_to_use_per_channel[4] = [1]\n",
    "    ind_component_to_use_per_channel[5] = [2]\n",
    "if rawname_ == 'S04_off_move':\n",
    "    baselines = [[110,210]] * len(ica_res)\n",
    "    mults[3] = 3\n",
    "    mults[4] = 3.5\n",
    "    ind_component_to_use_per_channel[4] = [0,2]\n",
    "    #ind_component_to_use_per_channel[4] = [2]\n",
    "    ind_component_to_use_per_channel[5] = [2]\n",
    "if rawname_ == 'S04_on_hold':\n",
    "    baselines = [[500,600]] * len(ica_res)\n",
    "    mults[1] = 2\n",
    "    ind_component_to_use_per_channel[1] = [1]\n",
    "    ind_component_to_use_per_channel[3] = [1]\n",
    "    ind_component_to_use_per_channel[4] = [1,2]\n",
    "    ind_component_to_use_per_channel[5] = [2]\n",
    "if rawname_ == 'S04_on_move':\n",
    "    baselines = [[600,700]] * len(ica_res)\n",
    "    mults[3] = 1.8\n",
    "    mults[4] = 1.8\n",
    "    ind_component_to_use_per_channel[0] = [1]\n",
    "    ind_component_to_use_per_channel[3] = [2]\n",
    "    ind_component_to_use_per_channel[4] = [2]\n",
    "if rawname_ == 'S05_on_hold':\n",
    "    ind_component_to_use_per_channel[0] = [2]\n",
    "    ind_component_to_use_per_channel[1] = [2]\n",
    "    ind_component_to_use_per_channel[2] = [2]\n",
    "    ind_component_to_use_per_channel[3] = [2]\n",
    "    ind_component_to_use_per_channel[5] = [2]\n",
    "if rawname_ == 'S05_on_move':\n",
    "    ind_component_to_use_per_channel[0] = [2]\n",
    "    ind_component_to_use_per_channel[1] = [2]\n",
    "    ind_component_to_use_per_channel[2] = [2]\n",
    "    ind_component_to_use_per_channel[3] = [2]\n",
    "    ind_component_to_use_per_channel[4] = [2]\n",
    "    extFactorRs[:] = [0.2] * len(ica_res)\n",
    "if rawname_ == 'S07_off_hold':\n",
    "    ind_component_to_use_per_channel[4] = [1]\n",
    "    ind_component_to_use_per_channel[5] = [2]\n",
    "if rawname_ == 'S08_on_rest':\n",
    "    ind_component_to_use_per_channel[8] = [1]\n",
    "    ind_component_to_use_per_channel[9] = [2]\n",
    "    ind_component_to_use_per_channel[11] = [2]\n",
    "    ind_component_to_use_per_channel[12] = [2]\n",
    "    ind_component_to_use_per_channel[13] = [2]\n",
    "if rawname_ == 'S09_off_rest':\n",
    "    baselines = [[300,550]] * len(ica_res)\n",
    "    ind_component_to_use_per_channel[0] = [2]\n",
    "    ind_component_to_use_per_channel[1] = [1]\n",
    "    ind_component_to_use_per_channel[2] = [2]\n",
    "    ind_component_to_use_per_channel[4] = [1]\n",
    "    ind_component_to_use_per_channel[5] = [1]\n",
    "    ind_component_to_use_per_channel[10] = [1]\n",
    "    ind_component_to_use_per_channel[11] = [1]\n",
    "    ind_component_to_use_per_channel[12] = [1]\n",
    "    ind_component_to_use_per_channel[13] = [1]\n",
    "if rawname_ == 'S10_off_rest':\n",
    "    baselines = [[60,150]] * len(ica_res)\n",
    "    ind_component_to_use_per_channel[4] = [2]\n",
    "    ind_component_to_use_per_channel[5] = [1]\n",
    "if rawname_ == 'S10_off_move':\n",
    "    baselines = [[80,200]] * len(ica_res)\n",
    "    ind_component_to_use_per_channel[0] = [2]\n",
    "    ind_component_to_use_per_channel[2] = [1]\n",
    "    mults[2] = 2.2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert len(raw.annotations) == 0\n",
    "#thr = 0.01\n",
    "import utils_tSNE as utsne\n",
    "cvls = {}\n",
    "ivals_check_artifs = {}\n",
    "anns_check_artifs = {}\n",
    "dat_absed = {}\n",
    "artifacts_found = False\n",
    "plot_only_channels_with_artifacts = 0 \n",
    "fig,axs = plt.subplots(2*len(ica_res),1,figsize=(24,len(ica_res)*4), sharex='col')\n",
    "plt.subplots_adjust(right=0.99,left=0.05,top=0.96,bottom=0.03)\n",
    "\n",
    "for chi in range(len(ica_res)):\n",
    "    chn = raw_lfponly.ch_names[chi]\n",
    "    anns_check_artifs[chn] = mne.Annotations([],[],[])\n",
    "for chi in range(len(ica_res)):\n",
    "    chn = raw_lfponly.ch_names[chi]\n",
    "    S_ = ica_res[chi]\n",
    "    #N_components_to_use = 1\n",
    "    ival_baseline = baselines[chi]\n",
    "    b0,b1 = ival_baseline\n",
    "    inds_baseline = np.where(np.logical_and( (Xtimes >= b0) , (Xtimes <= b1)) )[0]\n",
    "    for ind_component_to_use in ind_component_to_use_per_channel[chi]:\n",
    "        dat_cur = S_[:,ind_component_to_use ]\n",
    "        dat_cur = np.abs( dat_cur - np.mean(dat_cur[inds_baseline]) )\n",
    "        dat_absed[chn] = dat_cur\n",
    "\n",
    "        # pctshift = 25\n",
    "        # pcts = [pctshift, 100-pctshift]\n",
    "        # qs = np.percentile(megdat, pcts, axis=1)\n",
    "        #me, mn,mx = utsne.robustMean(checkdat, axis=1, per_dim =1, ret_aux=1, q = .25)\n",
    "        #checkdat_scaled = ( checkdat - me[:,None] ) / (mx-mn)[:,None]\n",
    "        #checkdat_sum = np.sum(np.abs(checkdat_scaled),axis=0)\n",
    "        #dat_cur = S_[:,0]\n",
    "        me_s, mn_s,mx_s = utsne.robustMean(dat_cur[inds_baseline], \n",
    "                                           axis=None, per_dim =1, ret_aux=1, pos = 1)\n",
    "        mult = mults[chi]\n",
    "        mask= dat_cur > mx_s * mult\n",
    "        summask = np.sum(mask)\n",
    "        if summask != 0:\n",
    "            #np.where(mask)[0]\n",
    "            cvl,ivals_check_artif = utils.getIntervals(mask ,include_short_spikes=1,\\\n",
    "                minlen=2, thr=thr, inc=1, extFactorL=extFactorLs[chi], \n",
    "                                                       extFactorR=extFactorRs[chi],\n",
    "                percentthr=percentthr, width=width_conv_bins, min_dist_between=5)\n",
    "\n",
    "            print('artifact intervals found ' ,ivals_check_artif)\n",
    "            if chn in cvls:\n",
    "                cvls[chn] = np.maximum(cvl,cvls[chn] )\n",
    "            else:\n",
    "                cvls[chn] = cvl\n",
    "            ivals_check_artifs[chn] = ivals_check_artif\n",
    "            if len(ivals_check_artif) > 0:\n",
    "                artifacts_found = True\n",
    "        else:\n",
    "            print('{}, comp {}: no artifacts found'.format(chn,ind_component_to_use))\n",
    "            ivals_check_artif = []\n",
    "            if plot_only_channels_with_artifacts:\n",
    "                continue\n",
    "\n",
    "        ax = axs[chi * 2]\n",
    "        ax.plot(Xtimes,dat_cur / mx_s, label='comp {}'.format(ind_component_to_use))\n",
    "        ax.axhline( me_s / mx_s, c='r', ls=':')\n",
    "        ax.axhline( mx_s / mx_s, c='purple', ls=':')\n",
    "        ax.axhline( me_s * mult / mx_s, c='r', ls=':')\n",
    "        ax.axhline( mx_s * mult / mx_s, c='purple', ls=':')\n",
    "        ax.set_ylabel(raw_lfponly.ch_names[chi])\n",
    "        ax.legend(loc='lower right')\n",
    "\n",
    "        if summask > 0:\n",
    "            ax = axs[chi * 2 + 1]\n",
    "            ax.plot(Xtimes,cvl, label='comp {}'.format(ind_component_to_use))\n",
    "            ax.axhline(y=thr, ls=':', c='purple')\n",
    "            ax.legend(loc='lower right')\n",
    "            ax.set_xlim(Xtimes[0],Xtimes[-1])\n",
    "\n",
    "        for i in [chi * 2, chi * 2 + 1]:\n",
    "            ax = axs[i]\n",
    "            if i % 2 == 0:\n",
    "                ymin = np.min(dat_cur) /  mx_s; ymax = np.max(dat_cur) / mx_s\n",
    "            else:\n",
    "                if summask > 0:\n",
    "                    ymin = 0; ymax = np.max(cvl)\n",
    "            for ivl in ivals_check_artif:\n",
    "                b0,b1 = ivl\n",
    "                b0t,b1t = Xtimes[b0],Xtimes[b1]\n",
    "                ax.axvline( b0t , c='r', ls=':')\n",
    "                ax.axvline( b1t , c='r', ls=':')\n",
    "\n",
    "                ax.fill_between( [b0t,b1t], ymin,ymax, facecolor='red', alpha=0.2)\n",
    "            ax.set_xlim(Xtimes[0],Xtimes[-1])\n",
    "            #raw.annotations.append([b0],[b1-b0], ['bad_MEG'])\n",
    "\n",
    "        anns_check_artifs[chn] +=\\\n",
    "        utils.intervals2anns(ivals_check_artif,\\\n",
    "                             'BAD_{}'.format(chn),\n",
    "                             Xtimes)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(gv.dir_fig,'{}_LFP_artif_from_ICA.png'.format(rawname_)) )\n",
    "\n",
    "    #plt.close()\n",
    "print('artifacts_found =',artifacts_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#artifacts_found = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving emtpy\n",
    "if not artifacts_found:\n",
    "    mne.Annotations([],[],[]).\\\n",
    "    save(os.path.join(gv.data_dir, '{}_ann_LFPartif.txt'.format(rawname_) ) )\n",
    "    print('Saving empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ymin,ymax = ax.get_ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot sub_bands and components togehter (nothing gets saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#%matplotlib qt\n",
    "plot_detailed = 0\n",
    "if plot_detailed:\n",
    "    for chi in range(len(ica_res)):\n",
    "        chn = raw_lfponly.ch_names[chi]\n",
    "        if chn not in cvls:\n",
    "            continue\n",
    "\n",
    "        #S_ = ica_res[chi]\n",
    "        dat_cur = dat_absed[chn]\n",
    "\n",
    "        #descrs = ['trem']\n",
    "        plt.figure(figsize=(40,8))\n",
    "        ax = plt.gca()\n",
    "\n",
    "        logabsdat = np.log( np.abs(tfrres) )\n",
    "\n",
    "        pctsh = 5\n",
    "        mlt = 1.3\n",
    "        mlt2 = 155\n",
    "        mlt3 = 455\n",
    "\n",
    "        effmn, effmx = np.percentile(logabsdat,[pctsh,100-pctsh]) \n",
    "        effrange = (effmx - effmn)\n",
    "        sh = effrange * mlt\n",
    "\n",
    "        effmn_S, effmx_S = np.percentile(dat_cur,[pctsh,100-pctsh]) \n",
    "        effrange = effmx_S - effmn_S\n",
    "\n",
    "\n",
    "        cvl = cvls[chn]\n",
    "        ivals_check_artif = ivals_check_artifs[chn]\n",
    "        cvlrange = np.max(cvl)\n",
    "        i = 0\n",
    "        #while i < S_.shape[-1]:\n",
    "            #ax.plot(Xtimes, S_[:,i] + (i)*sh)\n",
    "            #for i in ivalis\n",
    "\n",
    "\n",
    "        ax.plot(Xtimes, (dat_cur - effmn_S) / (effmx_S-effmn_S) * effrange * mlt2 + (i)*sh); i+= 1\n",
    "        ax.plot(Xtimes,cvl / cvlrange * effrange *mlt3 + (i)*sh)\n",
    "        ax.set_xlim(raw.times[0],raw.times[-1])\n",
    "\n",
    "        while i < tfrres.shape[1]:\n",
    "            ax.plot(times, logabsdat[chi,i,:] + (- effmn  + (i)*sh ) )\n",
    "            i += 1\n",
    "\n",
    "        ymin,ymax = ax.get_ylim()\n",
    "        for ivl in ivals_check_artif:\n",
    "            b0,b1 = ivl\n",
    "            b0t,b1t = Xtimes[b0],Xtimes[b1]\n",
    "            ax.axvline( b0t , c='r', ls=':')\n",
    "            ax.axvline( b1t , c='r', ls=':')\n",
    "\n",
    "            ax.fill_between( [b0t,b1t], ymin,ymax, facecolor='red', alpha=0.2)\n",
    "\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('{}_LFP_artif_from_ICA_{}.png'.format(rawname_,chn), dpi=300)\n",
    "        plt.close()\n",
    "    import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend ends/beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extend_interval_sec = 2\n",
    "for chn in anns_check_artifs:\n",
    "    anns = anns_check_artifs[chn]\n",
    "    newanns = mne.Annotations([],[],[])\n",
    "    for an in anns:\n",
    "        if an['onset'] < extend_interval_sec:\n",
    "            an['onset'] = 0\n",
    "            print(chn,' extend')\n",
    "        if an['onset'] + an['duration'] > raw.times[-1] - extend_interval_sec:\n",
    "            an['duration'] = raw.times[-1] - an['onset']\n",
    "        newanns.append(an['onset'],an['duration'],an['description'])\n",
    "    anns_check_artifs[chn] = newanns\n",
    "    #utils.mergeIntervalsWithinList(newann_curside, printLog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(anns_check_artifs)#, anns_check_artifs.onset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only select artifacts from some channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_approve_chns = raw_lfponly.ch_names # default\n",
    "artifact_approve_side = ''\n",
    "#artifact_approve_side = 'R' # if '', then both\n",
    "if len(artifact_approve_side) > 0:\n",
    "    print('Filtering')\n",
    "    artifact_approve_chns = [chn for chn in raw_lfponly.ch_names \\\n",
    "                             if chn.find('LFP{}'.format(artifact_approve_side)) >= 0 ]\n",
    "print(artifact_approve_chns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only select artifacts from some time periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%debug\n",
    "#artiact_approve_intervals = [ [0,300] ]\n",
    "artiact_approve_intervals = [ [0,raw.times[-1]] ]  #entire\n",
    "anns_check_artifs_upd = {}\n",
    "for approve_int in artiact_approve_intervals:\n",
    "    ai0,ai1 = approve_int\n",
    "    for chi in range(len(ica_res)):\n",
    "        chn = raw_lfponly.ch_names[chi]\n",
    "        if chn not in artifact_approve_chns:\n",
    "            print('skipping {}'.format(chn))\n",
    "            continue\n",
    "        if chn not in anns_check_artifs:\n",
    "            print('skipping {}'.format(chn))\n",
    "            continue\n",
    "        anns = anns_check_artifs[chn]\n",
    "        newanns = utils.findIntersectingAnns(ai0,ai1,anns, ret_type='anns')\n",
    "        anns_check_artifs_upd[chn] = newanns\n",
    "        \n",
    "#Believe artifacts found in time period\n",
    "print(anns_check_artifs_upd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print( anns_check_artifs['LFPL23'].description )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "anns_dict = anns_check_artifs_upd\n",
    "#anns_dict = anns_check_artifs\n",
    "for chn in anns_dict:\n",
    "    plt.figure(figsize=(13,3))\n",
    "    anns = anns_dict[chn]\n",
    "    ax = plt.gca()\n",
    "    for an in anns:\n",
    "        b0,b1 = an['onset'], an['onset']+an['duration']\n",
    "        ax.axvline( b0 , c='r', ls=':')\n",
    "        ax.axvline( b1 , c='r', ls=':')\n",
    "        ymin = 0; ymax = 1\n",
    "        ax.fill_between( [b0,b1], ymin,ymax, facecolor='red', alpha=0.2)\n",
    "    ax.set_title(chn)\n",
    "    ax.set_xlim(raw.times[0],raw.times[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge artfiacts from all channels on one side (or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%debug\n",
    "#merge_by_side = 1\n",
    "merge_sides = []\n",
    "#merge_sides = ['L', 'R']\n",
    "#merge_sides = ['L']\n",
    "if len(merge_sides):\n",
    "    newann_perside = {}\n",
    "    for side in merge_sides:\n",
    "        newann_curside = mne.Annotations([],[],[])\n",
    "        templ = 'LFP'+side\n",
    "        for chn in anns_check_artifs_upd:\n",
    "            if chn.find(templ) < 0:  # if not this side\n",
    "                continue\n",
    "            anns = anns_check_artifs_upd[chn]\n",
    "            print(chn, np.sum(anns.duration))\n",
    "            descr = len(anns.duration) * ['BAD_'+templ]\n",
    "            newann_curside += mne.Annotations(anns.onset,anns.duration,descr)\n",
    "        newann_curside_merged = utils.mergeIntervalsWithinList(newann_curside, printLog=True)\n",
    "        for ii in range(30):\n",
    "        #newann_curside_merged = utils.mergeIntervalsWithinList(newann_curside_merged, printLog=True)\n",
    "            #print(ii)\n",
    "            newann_curside_merged = utils.mergeIntervalsWithinList(newann_curside_merged, printLog=True)\n",
    "        newann_perside[side ] = newann_curside_merged\n",
    "        \n",
    "        print(side, np.sum(newann_curside.duration), np.sum(newann_curside_merged.duration)  )\n",
    "        \n",
    "        \n",
    "\n",
    "    for side in newann_perside:\n",
    "        print(side, newann_perside[side], newann_perside[side].onset)\n",
    "\n",
    "    #anns_check_artifs_upd['LFPL12' ].description\n",
    "    #utils.intervals2anns( utils.anns2intervals(anns_check_artifs_upd['LFPL12' ], tuple_len=3 ) )\n",
    "\n",
    "    #%matplotlib inline\n",
    "    for side in newann_perside:\n",
    "        plt.figure()\n",
    "        anns = newann_perside[side]\n",
    "        ax = plt.gca()\n",
    "        for an in anns:\n",
    "            b0,b1 = an['onset'], an['onset']+an['duration']\n",
    "            ax.axvline( b0 , c='r', ls=':')\n",
    "            ax.axvline( b1 , c='r', ls=':')\n",
    "            ymin = 0; ymax = 1\n",
    "            ax.fill_between( [b0,b1], ymin,ymax, facecolor='red', alpha=0.2)\n",
    "        ax.set_title(side)\n",
    "        ax.set_xlim(raw.times[0],raw.times[-1])\n",
    "\n",
    "    for side in newann_perside:\n",
    "        print(side,newann_perside[side].onset)\n",
    "        print(side,newann_perside[side].duration, np.sum(newann_perside[side].duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_names = raw_lfponly.ch_names\n",
    "info = mne.create_info(ch_names, sfreq/decim, ch_types='eeg')\n",
    "#print(info)\n",
    "#help(mne.io.RawArray)\n",
    "\n",
    "dat = []\n",
    "for chi in range(len(ica_res)):\n",
    "    chn = raw_lfponly.ch_names[chi]\n",
    "    dat += [dat_absed[chn]]\n",
    "dat = np.vstack(dat)\n",
    "\n",
    "print(chns_perside)\n",
    "\n",
    "artif_raw = mne.io.RawArray(dat,info) #,first_samp=n_edge_bins_TFR)\n",
    "#artif_raw.times += wsz_sec\n",
    "#Tune by hand\n",
    "ta = mne.Annotations([],[],[])\n",
    "for side in merge_sides:\n",
    "    ta  += newann_perside[side] \n",
    "    #print(ta.onset)\n",
    "if len(merge_sides) < 2:\n",
    "    nonmerge_sides = list( set(['L','R']) - set(merge_sides) )\n",
    "    print('nonmerge_sides = ',nonmerge_sides)\n",
    "    for side in nonmerge_sides:\n",
    "        for chn in anns_check_artifs_upd:\n",
    "            if chn in chns_perside[side]:\n",
    "                ta += anns_check_artifs_upd[chn]\n",
    "                #print(chn,'fd')\n",
    "import copy\n",
    "ta_shifted = copy.deepcopy(ta)\n",
    "ta_shifted.onset -= wsz_sec\n",
    "    \n",
    "artif_raw.set_annotations(ta_shifted)\n",
    "print(ta_shifted)\n",
    "\n",
    "#--------------------------\n",
    "\n",
    "artif_raw_upsampled = artif_raw.copy().resample(256)\n",
    "print(artif_raw_upsampled.times)\n",
    "#help(artif_raw_upsampled.get_data)\n",
    "dat = artif_raw_upsampled.get_data(reject_by_annotation=None)\n",
    "print(dat.shape)\n",
    "d1s = np.zeros( (dat.shape[0], wsz_bins) )\n",
    "\n",
    "tremfreq_for_preproc = 10\n",
    "rectconvraw = upre.extractEMGData(raw, rawname_ = rawname_, tremfreq=tremfreq_for_preproc)\n",
    "emgdat = rectconvraw.get_data()\n",
    "\n",
    "dat_ext = np.hstack( [d1s, dat, d1s] )\n",
    "assert  dat_ext.shape == rawdata.shape\n",
    "print(rawdata.shape)\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "dd = []\n",
    "chns = []\n",
    "for chi in range(len(raw_lfponly.ch_names)):\n",
    "    chn = raw_lfponly.ch_names[chi]\n",
    "    dd += [rawdata[chi]]; chns += [chn]\n",
    "    dd += [dat_ext[chi]]; chns += [chn+'_I0']\n",
    "dd += [emgdat]\n",
    "chns += rectconvraw.ch_names\n",
    "    \n",
    "dd = np.vstack(dd)\n",
    "scaler = RobustScaler(quantile_range=(15,85), with_centering=1)\n",
    "scaler.fit(dd.T)\n",
    "dd_scaled = scaler.transform(dd.T).T\n",
    "    \n",
    "info = mne.create_info(chns, sfreq, ch_types='eeg')\n",
    "lfp_aug = mne.io.RawArray(dd_scaled,info)\n",
    "#lfp_aug.set_annotations(raw_lfponly_wann.annotations)\n",
    "lfp_aug.set_annotations(ta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_aug.plot(duration=50,\n",
    "                       scalings={'eeg':'auto'}, highpass=None, lowpass=None  );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lfp_aug.annotations)\n",
    "print(lfp_aug.annotations.onset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I allow to have labels that mark bad segemnets in all channel per side. I want to convert them to per-channel labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newann = mne.Annotations([],[],[])\n",
    "for an in lfp_aug.annotations:\n",
    "    processed = False\n",
    "    for s in ['LFPL', 'LFPR']:\n",
    "        d = an['description']\n",
    "        if not d.endswith( s ):  # not just find, but completely\n",
    "            continue\n",
    "        print('found merged per side')\n",
    "        for chn in raw_lfponly.ch_names:\n",
    "            print(d,chn)\n",
    "            if chn.find(s) < 0:\n",
    "                continue\n",
    "            newann.append(an['onset'],an['duration'],'BAD_' + chn)\n",
    "            processed = True\n",
    "    if not processed:\n",
    "        newann.append(an['onset'],an['duration'],an['description'])\n",
    "            \n",
    "print(newann)\n",
    "print(newann.onset)\n",
    "print(newann.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(artif_raw.plot)\n",
    "\n",
    "# %matplotlib qt\n",
    "\n",
    "# artif_raw.plot(duration=50,scalings={'eeg':'auto'}, highpass=None, lowpass=None);\n",
    "\n",
    "# print(artif_raw.annotations.onset, artif_raw.annotations.duration)\n",
    "\n",
    "# raw_lfponly_wann = raw_lfponly.copy()\n",
    "# taa = artif_raw.annotations\n",
    "# taa.onset += wsz_sec\n",
    "# raw_lfponly_wann.set_annotations(taa)\n",
    "\n",
    "# raw_lfponly_wann.plot(duration=50,scalings='auto', highpass=None, lowpass=None);\n",
    "\n",
    "# raw_lfponly_wann.annotations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(raw_lfponly.plot_psd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that after rejecting artifacts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_lfponly_wann = raw_lfponly.copy()\n",
    "raw_lfponly_wann.set_annotations(newann)\n",
    "for chi in range(len(raw_lfponly.ch_names)):\n",
    "    chn = raw_lfponly.ch_names[chi]\n",
    "    #raw_lfponly.plot_psd(fmin=0,fmax=30, picks=chn);\n",
    "    raw_lfponly_wann.plot_psd(fmin=0, picks=chn, reject_by_annotation=True);\n",
    "    plt.title(chn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lfp_aug.annotations.\\\n",
    "resname = os.path.join(gv.data_dir, '{}_ann_LFPartif.txt'.format(rawname_) ) \n",
    "print(resname)\n",
    "newann.save(resname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just to look how components are related to labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_aug.set_annotations(newann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_aug_all_ann = lfp_aug.copy()\n",
    "lfp_aug_all_ann.set_annotations(raw_lfponly.annotations + lfp_aug.annotations)\n",
    "lfp_aug_perside = utils.getLFPperSide(lfp_aug_all_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_aug_perside['L'].plot(duration=50,\n",
    "                       scalings='auto', highpass=None, lowpass=None  );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_aug_perside['R'].plot(duration=50,\n",
    "                       scalings='auto', highpass=None, lowpass=None  );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# artif_raw_tremann = lfp_aug.copy()\n",
    "# ann_mainside_sh = ann_mainside\n",
    "# #ann_mainside_sh.onset -= wsz_sec\n",
    "# artif_raw_tremann.set_annotations( ann_mainside_sh + raw_lfponly_wann.annotations)\n",
    "\n",
    "# artif_raw_tremann.plot(duration=50,\n",
    "#                        scalings='auto', highpass=None, lowpass=None  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#artif_raw_tremann.crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try PAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorpac\n",
    "\n",
    "sfreq = 256\n",
    "\n",
    "# define an ERPAC object\n",
    "p = tensorpac.EventRelatedPac(f_pha=[3,10], f_amp=(30, 90, 5, 5))\n",
    "\n",
    "# extract phases and amplitudes\n",
    "pha = p.filter(sfreq, chdata[0], ftype='phase',     n_jobs=6)\n",
    "amp = p.filter(sfreq, chdata[1], ftype='amplitude', n_jobs=6)\n",
    "\n",
    "#Compute the ERPAC using the two implemented methods and plot it\n",
    "\n",
    "# implemented ERPAC methods\n",
    "#methods = ['circular', 'gc']\n",
    "methods = [ 'gc']\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "for n_m, m in enumerate(methods):\n",
    "    # compute the erpac\n",
    "    erpac = p.fit(pha, amp, method=m, smooth=50, n_jobs=-1).squeeze()\n",
    "\n",
    "    # plot\n",
    "    plt.subplot(len(methods), 1, n_m + 1)\n",
    "    p.pacplot(erpac, time, p.yvec, xlabel='Time (second)' * n_m,\n",
    "              cmap='Spectral_r', ylabel='Amplitude frequency', title=p.method,\n",
    "              cblabel='ERPAC', vmin=0., rmaxis=True)\n",
    "    plt.axvline(1., linestyle='--', color='w', linewidth=2)\n",
    "\n",
    "p.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
