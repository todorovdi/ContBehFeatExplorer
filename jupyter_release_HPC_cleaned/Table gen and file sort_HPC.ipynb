{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawnames =   ['S01_off_hold', 'S01_off_move'] + ['S01_on_hold', 'S01_on_move']\n",
    "rawnames +=  ['S02_off_hold', 'S02_off_move'] + ['S02_on_hold', 'S02_on_move'] \n",
    "rawnames +=  ['S03_off_hold', 'S03_off_move']\n",
    "rawnames +=  ['S04_off_hold', 'S04_off_move'] + ['S04_on_hold', 'S04_on_move'] \n",
    "rawnames +=  ['S05_off_hold', 'S05_off_move'] + ['S05_on_hold', 'S05_on_move'] \n",
    "rawnames +=  ['S07_off_hold', 'S07_off_move'] + ['S07_on_hold', 'S07_on_move'] \n",
    "\n",
    "rawnames = rawnames[::2] # we have joined them anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawnames =   ['S01_off_hold']\n",
    "rawnames +=  ['S02_off_hold'] \n",
    "rawnames +=  ['S04_off_hold'] \n",
    "rawnames +=  ['S07_off_hold'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawnames =   ['S01_off_hold']\n",
    "rawnames +=  ['S02_off_hold'] \n",
    "rawnames +=  ['S03_off_hold']\n",
    "rawnames +=  ['S04_off_hold'] \n",
    "rawnames +=  ['S05_off_hold'] \n",
    "rawnames +=  ['S07_off_hold'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawnames =   ['S01_off_hold', 'S01_off_move'] + ['S01_on_hold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawnames =  ['S01_off_hold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawnames =   ['S01']\n",
    "rawnames +=  ['S02'] \n",
    "rawnames +=  ['S03']\n",
    "rawnames +=  ['S04'] \n",
    "rawnames +=  ['S05'] \n",
    "rawnames +=  ['S07'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawnames = ['S01_off_hold', 'S02_off_hold', 'S02_on_hold', \n",
    "#             'S03_off_hold', 'S04_off_hold', 'S04_on_hold',\n",
    "#            'S05_off_hold', 'S05_on_hold', 'S07_off_hold'] #,'S01_on_hold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = ['all',\n",
    "'allb_trem',    \n",
    "'allb_beta',    \n",
    "'allb_gamma',   \n",
    "'allb_trembeta',\n",
    "'allnoHFO',\n",
    "'modLFP',\n",
    "'modLFPnoHFO',\n",
    "'modSrc',\n",
    "'onlyTD',\n",
    "'onlyFD',\n",
    "'conH',\n",
    "'onlyH',\n",
    "'onlyBpcorr',\n",
    "'onlyBpcorrNoHFO',\n",
    "'onlyRbcorr',\n",
    "'onlyCon',\n",
    "'onlyConNoHFO',\n",
    "'LFPrel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = ['all',\n",
    "'allb_trem',    \n",
    "'allb_beta',    \n",
    "'allb_gamma',   \n",
    "'modLFP',\n",
    "'modSrc',\n",
    "'modSrc_self',\n",
    "'onlyMotorSrc',\n",
    "'onlyRestSrc', \n",
    "'onlyCBSrc'    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = ['all',\n",
    "'allb_trem',    \n",
    "'allb_beta',    \n",
    "'allb_gamma',  \n",
    "'allb_HFO',\n",
    "'modLFP',\n",
    "'modSrc_self',\n",
    "'modSrc',\n",
    "'LFPrel_noself',\n",
    "'LFPrel_noself_onlyCon',            \n",
    "'LFPrel_noself_onlyRbcorr',            \n",
    "'LFPrel_noself_onlyBpcorr',                        \n",
    "'onlyTD', 'onlyFD', 'allb_trembeta',\n",
    "'onlyMotorSrc','onlyRestSrc','onlyCBSrc' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source ~/.bashrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting to sens,spec table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import globvars as gv\n",
    "import utils\n",
    "import utils_tSNE as utsne\n",
    "import utils_preproc as upre\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import mne\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import multiprocessing as mpr\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "import gc;\n",
    "import scipy.signal as sig\n",
    "import pandas as pd \n",
    "\n",
    "import numpy as np\n",
    "import utils_postprocess_HPC as postp\n",
    "import pymatreader\n",
    "\n",
    "data_dir = gv.data_dir\n",
    "from os.path import join as pjoin\n",
    "\n",
    "\n",
    "print(mne.__version__)\n",
    "\n",
    "# from datetime import datetime\n",
    "# dt = datetime.now()\n",
    "# dt.date()\n",
    "\n",
    "import pathlib\n",
    "gen_subj_info = gv.gen_subj_info\n",
    "#!pip help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect subject names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "light_only = True\n",
    "ndaysBefore = None\n",
    "\n",
    "#subdir = 'nointerp'\n",
    "subdir = 'nofeatsel'\n",
    "subdir = 'per_subj_best_LFP'\n",
    "start_time = parser.parse(\"20 Sept 2021 01:00:15\")\n",
    "end_time = parser.parse(\"21 Sept 2021 21:21:45\")\n",
    "\n",
    "\n",
    "lookup_dir = pjoin(gv.data_dir,subdir)\n",
    "recent = postp.listRecent(days=None, lookup_dir= lookup_dir,\n",
    "                          start_time=start_time,\n",
    "                                   end_time=end_time)\n",
    "rawnames = []\n",
    "rawnames_uncut = []\n",
    "for lf in recent:\n",
    "    st = 0\n",
    "    if light_only:\n",
    "        if not lf.startswith('_!'):\n",
    "            continue\n",
    "        st = 2\n",
    "    rawnames += [lf[st+1:st+4]]\n",
    "    rawnames_uncut += [lf]\n",
    "rawnames = list(sorted(set(rawnames)))\n",
    "rawnames_uncut = list(sorted(set(rawnames_uncut)))\n",
    "print(rawnames)\n",
    "\n",
    "import utils_postprocess_HPC as postp\n",
    "prefixes = postp.listRecentPrefixes(days = None, light_only=light_only, start_time=start_time,\n",
    "                                   end_time=end_time,\n",
    "                                    lookup_dir= lookup_dir)\n",
    "display(prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#awnames_uncut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# #%debug\n",
    "# #label_types = ['allsep', 'trem_vs_all', 'trem_vs_quiet']\n",
    "# #label_types = ['allsep']\n",
    "\n",
    "# nraws_used_PCA = 2\n",
    "\n",
    "# set_explicit_nraws_used_PCA = 1\n",
    "# set_explicit_n_feats_PCA = 0\n",
    "# set_explicit_dim_PCA = 0\n",
    "\n",
    "# try:\n",
    "#     print(output_per_raw.keys() )\n",
    "# except (NameError,AttributeError) as e:\n",
    "#     output_per_raw = None\n",
    "    \n",
    "#subdir='SSS'\n",
    "mainLFP = 1\n",
    "sources_type = 'parcel_aal'  # or ''\n",
    "#subdir =''\n",
    "r = postp.collectPerformanceInfo2(rawnames,prefixes, nraws_used=[2,4],                                                                                                    \n",
    "                                          sources_type = sources_type, \n",
    "                                           printFilenames=1,ndays_before=ndaysBefore,\n",
    "                                          use_main_LFP_chan=mainLFP,\n",
    "                                             subdir=subdir, remove_large_items = 1,\n",
    "                                 list_only=0, allow_multi_fn_same_prefix=0,\n",
    "                                 use_light_files = light_only)\n",
    "\n",
    "# r = postp.collectPerformanceInfo3(rawnames,prefixes, nraws_used='[2,4]',                                                                                                    \n",
    "#                                           sources_type = sources_type, \n",
    "#                                            printFilenames=1,                                 \n",
    "#                                             ndays_before=ndaysBefore,\n",
    "#                                             use_main_LFP_chan=mainLFP,\n",
    "#                                              subdir=subdir, remove_large_items = 1,\n",
    "#                                  list_only=0, allow_multi_fn_same_prefix=1,\n",
    "#                                  use_light_files = light_only, rawname_regex_full=0,\n",
    "#                                  start_time=start_time,\n",
    "#                                    end_time=end_time)\n",
    "#output_per_raw,Ximp_per_raw,gis_per_raw = r\n",
    "output_per_raw,_,_ = r\n",
    "\n",
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save result (to save time from loading next time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_per_raw \n",
    "load = 0; save = 0\n",
    "fname_full_summary = pjoin(gv.data_dir,subdir,'output_per_raw.npz')\n",
    "if save:\n",
    "    np.savez(fname_full_summary,output_per_raw=output_per_raw)\n",
    "    print( os.path.getsize(fname_full_summary) / 1024 **3 )\n",
    "if load:\n",
    "    f = np.load(fname_full_summary,allow_pickle=1)\n",
    "    output_per_raw = f['output_per_raw'][()]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_per_raw.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_postprocess as pp\n",
    "pp.printDict(output_per_raw,max_depth=2,print_leaves=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many XGB infos we have. 9 means we have all what we need\n",
    "for subj,it0 in output_per_raw.items():\n",
    "    for pref,it1 in it0.items():\n",
    "        for grp, it2 in it1.items():\n",
    "            if isinstance(it2,np.ndarray):\n",
    "                continue\n",
    "            for itype, it3 in it2.items():\n",
    "                anvers = it3['XGB_analysis_versions']            \n",
    "                anvers = it3['LDA_analysis_versions']            \n",
    "                #print(subj,pref,grp,'after_VF_threshold present','after_VF_threshold' in anvers.keys(), len(anvers ))\n",
    "                print(anvers.keys())\n",
    "            #['S01']['LFPrel_noself_onlyBpcorr']['merge_movements']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_postprocess as pp\n",
    "#pp.printDict(output_per_raw['S01']['LFPrel_noself_onlyBpcorr']['merge_movements'],max_depth=1,print_leaves=0)\n",
    "pp.printDict(output_per_raw['S01'],max_depth=1,print_leaves=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check if featsel present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rn in output_per_raw:\n",
    "    #feat_nums_perprefix = {}\n",
    "    feat_nums0 = {}\n",
    "    feat_nums_per_prefix = {}\n",
    "    feat_nums_red_per_prefix = {}\n",
    "    for prefix,pg in output_per_raw[rn].items():        \n",
    "        feat_nums_red_pgs = {}\n",
    "        feat_nums_pgs = {}\n",
    "        for g,pitset in pg.items():\n",
    "            if g == 'feature_names_filtered':\n",
    "                continue            \n",
    "            for it_set,lda_output in pitset.items():   \n",
    "                if 'featsel_per_method' in lda_output:\n",
    "                    print(rn,prefix,'featsel_per_method present')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import utils_postprocess as pp\n",
    "# pp.printDict(feat_numdict_perraw,max_depth=5)\n",
    "\n",
    "# so = output_per_raw['S01']['all']['merge_nothing']['basic']\\\n",
    "#     ['lda_analysis_versions']['strongest_features_XGB_fs_opinion']\n",
    "# so\n",
    "\n",
    "# # import json\n",
    "# # print( json.dumps(output_per_raw['S01']) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of sens,spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check organization by levels\n",
    "for subj,clvl0 in output_per_raw.items():\n",
    "    for prefix,clvl1 in clvl0.items():\n",
    "        for grp,clvl2 in clvl1.items():\n",
    "            if grp == 'feature_names_filtered':\n",
    "                continue\n",
    "            for it,clvl3 in clvl2.items():\n",
    "                print(clvl3.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = output_per_raw['S01']['all']['merge_movements']['basic']['XGB_analysis_versions']\n",
    "pp.printDict(d['all_present_features'], max_depth=2)\n",
    "len( d['all_present_features']['featinds_present'] )\n",
    "#d['all_present_features']['perf_aver']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_postprocess as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgv = output_per_raw['S01']['all']['merge_movements']['basic']['XGB_analysis_versions']\n",
    "ll = list( xgv.keys() )\n",
    "print(ll)\n",
    "pp.printDict(xgv['strongest_features_XGB_opinion'],print_leaves=0)\n",
    "xgv['strongest_features_XGB_opinion']['perf_aver']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = output_per_raw['S01']['all']['merge_movements']['basic']\n",
    "pp.printDict(d['perfs_XGB'][0] )\n",
    "print( len (d['perfs_XGB'][0]['sortinds']) )\n",
    "d['perfs_XGB'][-1]['perf_aver']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    merge_all_not_trem\n",
    "#     feature_names_filtered\n",
    "#     merge_nothing\n",
    "#     merge_movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_show = [('allsep','merge_nothing','basic'), ('trem_vs_all','merge_all_not_trem','basic'),\n",
    "        ('trem_vs_quiet','merge_all_not_trem','trem_vs_quiet')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_show = [('allsep','merge_nothing','basic'),\n",
    "#            ('trem_vs_quiet','merge_nothing','trem_vs_quiet'),\n",
    "#            ('trem_vs_all','merge_all_not_trem','basic'),\n",
    "#            ('medcond','merge_within_medcond','subj_medcond'),\n",
    "#           ('dataset','merge_within_task','subj_medcond_task') ]\n",
    "\n",
    "# use_CV_perf = True\n",
    "\n",
    "# perf_to_use_list = ['perfs_XGB', 'perfs_XGB_red', 'all_present_features',\n",
    "#                     'strongest_features_LDA_selMinFeatSet', \n",
    "#                     'strongest_features_XGB_opinion', \n",
    "#                     'best_PCA-derived_features_0.6']\n",
    "\n",
    "# perf_to_use_list = ['perfs_XGB','perfs_XGB_red', \n",
    "#                     'all_present_features', \n",
    "#                     'strongest_features_LDA_selMinFeatSet']\n",
    "\n",
    "# table_info_per_perf_type, table_per_perf_type = \\\n",
    "#     postp.prepTableInfo(output_per_raw, prefixes=prefixes, \n",
    "#     perf_to_use_list=perf_to_use_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB ['all_present_features', 'strongest_features_XGB_opinion', \n",
    "#  'after_VF_threshold', 'strongest_features_XGB_opinion_nosyn', \n",
    "#  'best_PCA-derived_features_0.87', 'best_PCA-derived_features_0.92',\n",
    "#  'best_PCA-derived_features_0.99', 'strongest_features_XGB_fs_opinion',\n",
    "#  'strongest_features_XGB_fs_opinion_nosyn']\n",
    "# LDA ['all_present_features', 'all_present_features_but_LFPR01',\n",
    "#           'all_present_features_but_LFPR12', 'all_present_features_but_LFPR23', \n",
    "#           'best_PCA-derived_features_0.87', 'best_PCA-derived_features_0.92', \n",
    "#           'best_PCA-derived_features_0.99', 'strongest_features_LDA_opinion',\n",
    "#           'after_VF_threshold', 'strongest_features_LDA_selMinFeatSet', \n",
    "#           'strongest_features_XGB_opinion', 'boruta_selected', 'strongest_features_XGB_fs_opinion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_to_use_list = []\n",
    "perf_to_use_list += [('XGB','perfs_XGB','perfs_XGB_red') ]\n",
    "perf_to_use_list += [('XGB','perfs_XGB','perfs_XGB_fs_red') ]\n",
    "perf_to_use_list += [('LDA','all_present_features','strongest_features_LDA_opinion') ]\n",
    "perf_to_use_list += [('LDA','all_present_features','strongest_features_LDA_selMinFeatSet') ]\n",
    "# these are actually XGB_selMeanFeatSet\n",
    "perf_to_use_list += [('LDA','all_present_features','strongest_features_XGB_opinion') ]\n",
    "perf_to_use_list += [('LDA','all_present_features','strongest_features_XGB_fs_opinion') ]\n",
    "\n",
    "#thr0,thr1,thr2='0.6','0.75','0.9'\n",
    "thr0,thr1,thr2='0.87','0.92','0.99'\n",
    "all_LDA =  ['all_present_features',\n",
    "      f'best_PCA-derived_features_{thr0}',\n",
    "      f'best_PCA-derived_features_{thr1}',\n",
    "      f'best_PCA-derived_features_{thr2}',\n",
    "      'after_VF_threshold',\n",
    "      'boruta_selected',\n",
    "      'strongest_features_LDA_opinion',\n",
    "      'strongest_features_LDA_selMinFeatSet',\n",
    "      'strongest_features_XGB_opinion',\n",
    "      'strongest_features_XGB_fs_opinion' ]\n",
    "\n",
    "all_XGB = ['all_present_features',\n",
    "      'strongest_features_XGB_opinion',\n",
    "      'strongest_features_XGB_opinion_nosyn',\n",
    "      f'best_PCA-derived_features_{thr0}',\n",
    "      f'best_PCA-derived_features_{thr1}',\n",
    "      f'best_PCA-derived_features_{thr2}',\n",
    "           'after_VF_threshold',\n",
    "      'strongest_features_XGB_fs_opinion',\n",
    "      'strongest_features_XGB_fs_opinion_nosyn']\n",
    "\n",
    "\n",
    "all_LDA =  ['all_present_features',\n",
    "      f'best_PCA-derived_features_{thr2}',\n",
    "      'best_LFP']\n",
    "\n",
    "all_XGB = ['all_present_features',     \n",
    "      f'best_PCA-derived_features_{thr2}',\n",
    "     'best_LFP']\n",
    "\n",
    "import utils_postprocess as pp\n",
    "tpll = pp.multiLevelDict2TupleList(output_per_raw,4,3)\n",
    "#tpll [0][:4]  \n",
    "\n",
    "mult_clf_output = tpll[0][-1]\n",
    "all_thrs = mult_clf_output['feat_variance_q_thr'][-3:]\n",
    "all_thrs = np.array(mult_clf_output['feat_variance_q_thr'])[[1,-3,-1]]\n",
    "#thr0,thr1,thr2='0.6','0.75','0.9'\n",
    "thr0,thr1,thr2='0.87','0.92','0.99'\n",
    "\n",
    "all_LDA =  []\n",
    "all_XGB = ['all_present_features','after_VF_threshold']\n",
    "\n",
    "for thr_cur in all_thrs:\n",
    "    all_XGB += [ f'best_PCA-derived_features_{thr_cur}']\n",
    "\n",
    "perf_to_use_list = []\n",
    "if len(all_LDA):\n",
    "    for v in all_LDA[1:]:\n",
    "        perf_to_use_list += [('LDA',all_LDA[0],v)]\n",
    "for v in all_XGB[1:]:\n",
    "    perf_to_use_list += [('XGB',all_XGB[0],v,'across_subj')]\n",
    "\n",
    "across_type = 'across_subj'\n",
    "across_type = 'across_medcond'\n",
    "    \n",
    "perf_to_use_list = []\n",
    "for v in all_LDA[1:]:\n",
    "    perf_to_use_list += [('LDA',all_LDA[0],v,across_type)]\n",
    "for v in all_XGB[1:]:\n",
    "    perf_to_use_list += [('XGB',all_XGB[0],v,across_type)]\n",
    "\n",
    "display(perf_to_use_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.printDict(output_per_raw['S01']['onlyMotorSrc'],max_depth=1,print_leaves=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_show = [('allsep','merge_nothing','basic'), ('trem_vs_all','merge_all_not_trem','basic'),\n",
    "        ('trem_vs_2class','merge_movements','basic')]\n",
    "to_show = [('trem_vs_2class','merge_movements','basic')]\n",
    "to_show = [('trem_vs_2class','merge_movements','basic'),('trem_vs_mvts','merge_movements','trem_vs_hold&move'),\n",
    "           ('trem_vs_quiet','merge_nothing','trem_vs_quiet')]\n",
    "\n",
    "\n",
    "# warnings.simplefilter('error')\n",
    "# table_info_per_perf_type, table_per_perf_type = \\\n",
    "#     postp.prepTableInfo2(output_per_raw, prefixes=prefixes, \n",
    "#     perf_to_use_list=perf_to_use_list)\n",
    "\n",
    "#%debug\n",
    "# import warnings\n",
    "# with warnings.catch_warnings():\n",
    "#warnings.simplefilter('error')\n",
    "table_info_per_perf_type, table_per_perf_type = \\\n",
    "    postp.prepTableInfo3(output_per_raw, prefixes=prefixes, \n",
    "    perf_to_use_list=perf_to_use_list, to_show=to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import utils_postprocess as pp\n",
    "# pp.printDict(table_info_per_perf_type[('LDA', 'all_present_features', 'strongest_features_XGB_opinion')], \n",
    "#              max_depth=1,print_leaves=1)\n",
    "\n",
    "# pp.printDict(table_info_per_perf_type[('LDA', 'all_present_features', 'strongest_features_XGB_opinion')], \n",
    "#              max_depth=0,print_leaves=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plotting summary of results per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perf_tuple = perf_to_use_list[0]\n",
    "#%debug\n",
    "#for perf_tuple in perf_to_use_list[:1]:\n",
    "for perf_tuple in perf_to_use_list:\n",
    "    print(perf_tuple)\n",
    "    postp.plotTableInfos2(table_info_per_perf_type, perf_tuple=perf_tuple, \n",
    "                          output_subdir=subdir) \n",
    "    plt.close()\n",
    "    import gc;gc.collect()\n",
    "    #break\n",
    "#postp.plotTableInfos2(table_info_per_perf_type, perf_kind='LDA', keys = None, output_subdir=''): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.printDict(table_info_per_perf_type,print_leaves=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot locations on brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (sub)select selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_output['cmd'][0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pp.printDict(lda_output, max_depth=0)\n",
    "\n",
    "#prefixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot depenence of performance on feature number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.printDict(output_per_raw['S01']['all']['merge_nothing']['basic']['perfs_XGB'], max_depth=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_postprocess as pp\n",
    "pp.printDict(feat_names_per_prefix, max_depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib as il; il.reload(postp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'all'\n",
    "prefix = 'LFPrel_noself'\n",
    "prefix = 'LFPrel_noself_onlyBpcorr'\n",
    "# prefix = 'LFPrel_noself_onlyBpcorr_onlyMotorSrc'\n",
    "# prefix = 'cross_freqmod_beta,gamma:HFO'\n",
    "# prefix = 'onlyH'\n",
    "# prefix = 'modSrc'\n",
    "# prefix = 'LFPrel_noself_onlyBpcorr_onlyRestSrc'\n",
    "#for prefix in prefixes:\n",
    "#feat_inds_per_prefix = postp.plotFeatNum2Perf(output_per_raw, prefixes)\n",
    "\n",
    "perflists = ['perfs_XGB','perfs_XGB_fs', 'perfs_LDA_featsearch']\n",
    "\n",
    "prefix_list =  ['all', 'LFPrel_noself', 'LFPrel_noself_onlyBpcorr', 'onlyH']\n",
    "prefix_list = prefixes\n",
    "\n",
    "#perflists = []\n",
    "#prefix_list = ['LFPrel_noself_onlyRbcorr']\n",
    "#prefix_list =  [ 'LFPrel_noself', 'LFPrel_noself_onlyBpcorr', 'onlyH']\n",
    "feat_names_per_prefix = postp.plotFeatNum2Perf(output_per_raw, \n",
    "                                               perflists, prefix_list,\n",
    "                                              skip_plot=1, xlim=(0,300))\n",
    "import gc;gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot feature-realed source locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "\n",
    "#%debug\n",
    "perflists = ['perfs_XGB','perfs_XGB_fs', 'perfs_LDA_featsearch']# [:1]\n",
    "for pt in perflists: \n",
    "    for prefix in feat_names_per_prefix.keys():\n",
    "        #pt = 'perfs_XGB'\n",
    "        featlist_per_rn={}\n",
    "        rns = list(sorted(output_per_raw.keys()))\n",
    "        rowind = 0\n",
    "        for rn in rns:\n",
    "\n",
    "            feat_names_per_pg_piset = {}\n",
    "            #for prefix,pg in output_per_raw[rn].items():\n",
    "            pg = output_per_raw[rn][prefix]\n",
    "            for g,pitset in pg.items():\n",
    "                if g == 'feature_names_filtered':\n",
    "                    continue\n",
    "                for it_set,multi_clf_output in pitset.items():\n",
    "                    \n",
    "                    featnames = feat_names_per_prefix[prefix][rn][(g,it_set)][pt]\n",
    "                    if featnames is None:\n",
    "                        continue\n",
    "                    print(rn,prefix,g,it_set,pt, len(featnames))\n",
    "#                     postp.plotImportantFeatLocations(rn,multi_clf_output,featnames)\n",
    "#                     figname = f'important_feat_headloc__{prefix}_{rn}_{g,it_set}__{pt}.pdf'\n",
    "#                     plt.suptitle(f'Number of (balanced) features = {len(featnames)}')\n",
    "#                     plt.savefig(pjoin(gv.dir_fig, figname ) )\n",
    "#                     plt.close()\n",
    "#                     import gc;gc.collect()\n",
    "\n",
    "#                     break\n",
    "#                 break\n",
    "#             break\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names_per_prefix.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.load( lda_output['filename_full'], allow_pickle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = f['results_light']  [()]['corr_matrix']\n",
    "\n",
    "len(fip_fs)\n",
    "\n",
    "## Throw away correlated features\n",
    "\n",
    "indlist = fip_fs\n",
    "#indlist = np.arange(C.shape[0])\n",
    "C_subset = C[indlist,:][:,indlist]\n",
    "strong_correl_level = 0.85\n",
    "\n",
    "nonsyn_feat_inds = pp.getNotSyn(C_subset,strong_correl_level)\n",
    "#orig_inds = indlist[nonsyn_feat_inds]\n",
    "\n",
    "print(f'Without synonyms for corr. level = {strong_correl_level:.3f}: {len(nonsyn_feat_inds)} of {len(indlist)}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i1,i2 in pairs:\n",
    "    print(featnames_nice[i1],'<-->',featnames_nice[i2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(C_subset.flatten());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolor(C_subset)\n",
    "#plt.hist(C_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_output['pca_xgafeats'].__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rncur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_per_raw.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.printDict(lda_output['info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_output['info']['src_grouping'], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reacall that sense was shifted by 1 comapred to numbering in there\n",
    "ind_balanced = np.where( np.array(sens) > balance_level )[0][0] + 1\n",
    "cur = lda_output[pt][ind_balanced]   \n",
    "featinds = cur['featinds_present']#[ind]\n",
    "featnames = lda_output['feature_names_filtered']\n",
    "featnames[featinds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featlist_per_rn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feat signif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_show = [('allsep','merge_nothing','basic'), ('trem_vs_all','merge_all_not_trem','basic'),\n",
    "        ('trem_vs_quiet','merge_all_not_trem','trem_vs_quiet')]\n",
    "\n",
    "to_show = [('trem_vs_2class', 'merge_movements', 'basic')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot feat signif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load sources labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rncur = 'S01_off_hold'\n",
    "sind_str,mc,tk  = utils.getParamsFromRawname(rncur)\n",
    "sources_type='parcel_aal'\n",
    "src_file_grouping_ind = 10\n",
    "src_rec_info_fn = '{}_{}_grp{}_src_rec_info'.format(rncur,\n",
    "                                                    sources_type,src_file_grouping_ind)\n",
    "src_rec_info_fn_full = os.path.join(gv.data_dir, src_rec_info_fn + '.npz')\n",
    "rec_info = np.load(src_rec_info_fn_full, allow_pickle=True)\n",
    "\n",
    "\n",
    "print( list(rec_info.keys()) )\n",
    "\n",
    "labels_dict = rec_info['label_groups_dict'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = ['all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_postprocess_HPC as postp\n",
    "ndaysBefore = 5\n",
    "subdir = 'nointerp'\n",
    "lookup_dir = pjoin(gv.data_dir,subdir)\n",
    "\n",
    "recent = postp.listRecent(days=ndaysBefore, lookup_dir=lookup_dir)\n",
    "rawnames = []\n",
    "for lf in recent:\n",
    "    rawnames += [lf[1:4]]\n",
    "rawnames = list(sorted(set(rawnames)))\n",
    "print('rawnames = ',rawnames)\n",
    "\n",
    "prefixes = postp.listRecentPrefixes(days = ndaysBefore, lookup_dir=lookup_dir)\n",
    "print('prefixes = ',prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_postprocess_HPC as postp\n",
    "from os.path import join as pjoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_postprocess as pp\n",
    "pp.printDict(mult_clf_output['XGB_analysis_versions']['all_present_features']['perf_dict'],max_depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_per_raw.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#featnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_postprocess_HPC as postp\n",
    "import importlib as il\n",
    "postp = il.reload(postp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "#mpl.use('Agg')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(featnames) : 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_light_file = 1\n",
    "perf_thr = 0.7\n",
    "#%debug\n",
    "rname_crop = slice(0,3)\n",
    "for rn in output_per_raw:\n",
    "    for lt, it_grp, it_set in to_show:\n",
    "        if it_grp == 'merge_all_not_trem':\n",
    "            print('skip')\n",
    "            continue            \n",
    "        for prefix in prefixes:           \n",
    "#             if rn != 'S03' or prefix != 'onlyH':\n",
    "#                 continue\n",
    "#             if prefix != 'allb_beta':\n",
    "#                 continue\n",
    "            \n",
    "            print(f'Starting {rn} {prefix} {(lt,it_set)}')\n",
    "            info_cur = {}\n",
    "            #sens,spec = res[rn].get(pref, (np.nan, np.nan))\n",
    "            r = output_per_raw[rn].get(prefix, None)\n",
    "            if (r is not None) and (it_grp not in r or it_set not in r[it_grp]):\n",
    "                r = None\n",
    "\n",
    "            if r is None:\n",
    "                print('Warning : no output for ',rn,prefix,it_grp,it_set)\n",
    "                continue\n",
    "            else:\n",
    "                mult_clf_output = r[it_grp][it_set]\n",
    "\n",
    "            use_light_file = 1\n",
    "            if use_light_file:\n",
    "                featsel_per_method = mult_clf_output['featsel_per_method'] \n",
    "                featnames = mult_clf_output['feature_names_filtered']\n",
    "                class_labels_good = mult_clf_output['class_labels_good']\n",
    "            else:                \n",
    "                f = np.load( mult_clf_output['filename_full'], allow_pickle=True )\n",
    "                featnames =  f['feature_names_filtered_pri'][()][0]\n",
    "                print(prefix, f['Xconcat_good_cur'].shape, len(featnames) )\n",
    "                class_labels_good = f['class_labels_good']\n",
    "                \n",
    "            revdict = mult_clf_output['revdict']\n",
    "            from sklearn import preprocessing\n",
    "            lab_enc = preprocessing.LabelEncoder()\n",
    "            # just skipped class_labels_good\n",
    "            lab_enc.fit(class_labels_good)\n",
    "            class_labels_good_for_classif = lab_enc.transform(class_labels_good)\n",
    "            class_label_ids = lab_enc.inverse_transform( np.arange( len(set(class_labels_good_for_classif)) ) )\n",
    "            class_label_names = [revdict[cli] for cli in class_label_ids]\n",
    "            \n",
    "            output_subdir = ''\n",
    "            out_name_plot = f'{rn}_{it_grp},{it_set}_{prefix}_feat_signif'        \n",
    "            \n",
    "            chnames_LFP = ['LFPR01', 'LFPR12', 'LFPR23']\n",
    "            \n",
    "            pvec = mult_clf_output['XGB_analysis_versions']['all_present_features']['perf_dict']['perf_aver']\n",
    "            sens,spec,F1 = pvec\n",
    "            str_to_put_ =  '{:.0f}%,{:.0f}%,{:.0f}%'.format(100*pvec[0],100*pvec[1],100*pvec[2])\n",
    "            if min(sens,spec) < perf_thr:\n",
    "                print('  Skipping due to low perf ',str_to_put_)\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                pdf= PdfPages(pjoin(gv.dir_fig, output_subdir, out_name_plot + '.pdf' ))    \n",
    "                postp.plotFeatSignifSHAP(pdf=pdf,\n",
    "                                         featsel_per_method=featsel_per_method, fshs='XGB_Shapley', \n",
    "                                         featnames_list=featnames, \n",
    "                                         class_labels_good_for_classif=class_labels_good_for_classif,\n",
    "                                         class_label_names=class_label_names,\n",
    "                                         figname_prefix=prefix, roi_labels=labels_dict['all_raw'],\n",
    "                                        body_side='left', chnames_LFP=chnames_LFP, \n",
    "                                         hh = int( 20 * len(featnames) / 270  ), \n",
    "                                         tickfontsize = 15,\n",
    "                                         suptitle = str_to_put_, \n",
    "                                         suptitle_fontsize=20);                  \n",
    "                \n",
    "                pdf.close()\n",
    "            except (ValueError) as e:\n",
    "                print('__EERRRRROOORRR ', e,out_name_plot)\n",
    "                raise e\n",
    "            plt.close('all')\n",
    "            #print('aaa')\n",
    "            \n",
    "            #return  #for debug only\n",
    "            \n",
    "#             break\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = {'0a': \n",
    "         {'1a': \n",
    "          {\n",
    "              '2a':[3,4,1] \n",
    "          } , \n",
    "          '1b':\n",
    "          {\n",
    "              '2b':[4,6]\n",
    "          },\n",
    "          '1c':['1c1','1c2'],\n",
    "         },\n",
    "         '0b':{'1c':[14,16]},\n",
    "         '0c':[33,444]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi subject ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(sorted( set(prefixes) - set(['all']) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_postprocess as pp\n",
    "\n",
    "prefixes_to_use = ['cross_freqmod_beta,gamma:HFO']\n",
    "prefixes_to_use = ['LFPrel_noself']\n",
    "for prefix_cur in list(sorted( set(prefixes) - set(['all']) )):\n",
    "#for prefix_cur in ['cross_freqmod_beta,gamma:HFO']:\n",
    "    prefixes_to_use = [prefix_cur]\n",
    "\n",
    "    outputs_grouped = pp.groupOutputs(output_per_raw, prefixes_to_use,['merge_movements'],['basic'])\n",
    "    #pp.printDict(outputs_grouped,1,print_leaves=1)\n",
    "\n",
    "\n",
    "    use_light_file = 1\n",
    "    perf_thr = 0.7\n",
    "\n",
    "    rname_crop = slice(0,3)\n",
    "\n",
    "    #(prefix,grp,int_type), output = u\n",
    "    print(f'Starting plotting for {len(outputs_grouped)} grouped outputs')\n",
    "    info_cur = {}\n",
    "    #sens,spec = res[rn].get(pref, (np.nan, np.nan))\n",
    "    (prefix,grp,int_type), mult_clf_output = list(outputs_grouped.values())[0]\n",
    "\n",
    "    output_subdir = ''\n",
    "    out_name_plot = f'{\",\".join((prefix,grp,int_type) ) }_feat_signif'        \n",
    "    chnames_LFP = ['LFPR01', 'LFPR12', 'LFPR23']\n",
    "\n",
    "    str_to_put_ = ''\n",
    "    #     pvec = mult_clf_output['XGB_analysis_versions']['all_present_features']['perf_dict']['perf_aver']\n",
    "    #     sens,spec,F1 = pvec\n",
    "    #     str_to_put_ =  '{:.0f}%,{:.0f}%,{:.0f}%'.format(100*pvec[0],100*pvec[1],100*pvec[2])\n",
    "    #     if min(sens,spec) < perf_thr:\n",
    "    #         print('  Skipping due to low perf ',str_to_put_)\n",
    "    #         continue\n",
    "    #hh = int( 20 * len(featnames) / 270  ), \n",
    "    #%debug\n",
    "\n",
    "    #outputs_grouped   # \n",
    "    #(prefix,grp,int_type), mult_clf_output = output_list[0]\n",
    "    #%debug\n",
    "    from matplotlib.backends.backend_pdf import PdfPages\n",
    "    pdf= PdfPages(pjoin(gv.dir_fig, subdir, out_name_plot + '.pdf' ))    \n",
    "    postp.plotFeatSignifSHAP_list(pdf=pdf,\n",
    "                             outputs_grouped=outputs_grouped, fshs='XGB_Shapley',                                  \n",
    "                             figname_prefix=prefix, roi_labels=labels_dict['all_raw'],\n",
    "                             body_side='left', chnames_LFP=chnames_LFP, \n",
    "                             hh = 8, \n",
    "                             tickfontsize = 10, markersize=8,\n",
    "                             suptitle = str_to_put_, use_best_LFP=True,\n",
    "                             suptitle_fontsize=20, show_bias=0);                  \n",
    "\n",
    "    pdf.close()\n",
    "\n",
    "    plt.close('all')\n",
    "    \n",
    "    cax,clrb = postp.plotConfmats(outputs_grouped, best_LFP=1)\n",
    "    kind = ';'.join( list( outputs_grouped.values() )[0][0] )\n",
    "    figname = ','.join( [k[0] for k in outputs_grouped.keys()] ) + f'_confmats_{kind}.pdf'\n",
    "    kind = ';  '.join( list( outputs_grouped.values() )[0][0] )\n",
    "    plt.suptitle(kind)\n",
    "    plt.savefig( pjoin(gv.dir_fig,subdir,figname) )\n",
    "    \n",
    "    plt.close('all')\n",
    "            #print('aaa')\n",
    "            \n",
    "            #return  #for debug only\n",
    "            \n",
    "#             break\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   #     pvec = mult_clf_output['XGB_analysis_versions']['all_present_features']['perf_dict']['perf_aver']\n",
    "    #     sens,spec,F1 = pvec\n",
    "    #     str_to_put_ =  '{:.0f}%,{:.0f}%,{:.0f}%'.format(100*pvec[0],100*pvec[1],100*pvec[2])\n",
    "    #     if min(sens,spec) < perf_thr:\n",
    "    #         print('  Skipping due to low perf ',str_to_put_)\n",
    "    #         continue\n",
    "    #hh = int( 20 * len(featnames) / 270  ), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_grouped.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers_mean = [r'$' +f'{int(subj[0][1:])}' + r'$' for subj in outputs_grouped.keys()]\n",
    "markers_max = [r'$\\tilde{' + f'{int(subj[0][1:])  }' + r'}$' for subj in outputs_grouped.keys()]\n",
    "\n",
    "#%debug\n",
    "hh_ = None\n",
    "#for prefix_cur in list(sorted( set(prefixes) - set(['all']) )):\n",
    "#for prefix_cur in ['cross_freqmod_beta,gamma:HFO']:\n",
    "#for prefix_cur in [ 'LFPrel_noself']:\n",
    "#for prefix_cur in [ 'onlyH']:\n",
    "#for prefix_cur in [ 'LFPrel_noself_onlyCon']:\n",
    "#for prefix_cur in [ 'allb_beta', 'onlyH']:\n",
    "#for prefix_cur in [  'allb_beta', 'allb_tremor', 'allb_gamma', 'onlyH']:\n",
    "#for prefix_cur in [ 'LFPrel_noself_onlyRbcorr', 'LFPrel_noself_onlyCon', 'modSrc_self',  'onlyCBSrc', 'onlyMotorSrc']:\n",
    "#for prefix_cur in [ 'LFPrel_noself_onlyBpcorr', 'LFPrel_noself']:\n",
    "#for prefix_cur in [ 'all']:\n",
    "#for tpl_ in [('onlyH',10), ('LFPrel_noself',25)]:\n",
    "#for tpl_ in [('LFPrel_noself_onlyRbcorr',15)]:\n",
    "#for tpl_ in [ ('allb_beta',15),  ('allb_gamma',15), ('allb_tremor',15) ]:\n",
    "#for tpl_ in [ ('LFPrel_noself_onlyBpcorr',25)]:    \n",
    "#for prefix_cur in [ 'onlyH', 'LFPrel_noself', 'allb_beta']:\n",
    "#for prefix_cur in prefixes:\n",
    "\n",
    "pref_hh_tuples = [ ('all',40)]\n",
    "pref_hh_tuples = [ ('onlyH',10)]\n",
    "subdir_short = 'per_subj_best_LFP'\n",
    "\n",
    "pref_hh_tuples = [ ('modSrc',12),\n",
    " ('modSrc_self',10),\n",
    " ('onlyCBSrc',10),\n",
    " ('onlyMotorSrc',10),\n",
    " ('onlyRestSrc',10)]\n",
    "\n",
    "subdir_short = 'joint_noskip'\n",
    "grpit_tpl = 'merge_movements','basic'\n",
    "#grpit_tpl = 'merge_movements','trem_vs_hold&move'\n",
    "\n",
    "\n",
    "from IPython import get_ipython; ipython = get_ipython()\n",
    "runstr_ = '%run -i ../run/_subrun_plot_imp_HPC.py'\n",
    "ipython.magic(runstr_)\n",
    "#             break+\n",
    "#         break\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subdir = 'per_subj_best_LFP'\n",
    "\n",
    "pref_hh_tuples = [ ('all',40)]\n",
    "\n",
    "pref_hh_tuples = [ ('onlyH',10)]\n",
    "EBM_feat_subsets = ['all','VIFsel']\n",
    "#EBM_feat_subsets = ['all']\n",
    "\n",
    "\n",
    "#subdir_short = 'joint_noskip'\n",
    "#grpit_tpl = 'merge_movements','basic'\n",
    "#grpit_tpl = 'merge_movements','basic'\n",
    "grpit_tpl = 'merge_movements','trem_vs_hold&move'\n",
    "\n",
    "\n",
    "#%debug\n",
    "from IPython import get_ipython; ipython = get_ipython()\n",
    "runstr_ = '%run -i ../run/_subrun_plot_imp_EBM_HPC.py'\n",
    "ipython.magic(runstr_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib as il\n",
    "\n",
    "il.reload(postp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.printDict(output_per_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_grouped = pp.groupOutputs(output_per_raw, prefixes_to_use,\n",
    "                                  ['merge_movements'],['tremor_vs_hold&move'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(outputs_grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir_short = 'per_subj_best_LFP'\n",
    "\n",
    "pref_hh_tuples = [ ('all',40)]\n",
    "\n",
    "#subdir_short = 'joint_noskip'\n",
    "grpit_tpl = 'merge_movements','basic'\n",
    "\n",
    "\n",
    "from IPython import get_ipython; ipython = get_ipython()\n",
    "runstr_ = '%run -i ../run/_subrun_plot_imp_EBM_HPC.py'\n",
    "ipython.magic(runstr_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for rn,prefix,grp,it,mult_clf_output in tpll:\n",
    "    VIFtr = mult_clf_output['VIF_truncation']\n",
    "    dd = dict( VIFtr.items() )\n",
    "    #del dd['VIFsel_linreg_objs']\n",
    "    #dd[]\n",
    "    #VIFtr['VIFsel_linreg_objs'][0]\n",
    "    d[(rn,prefix,grp,it)] = dd\n",
    "#('S01,S02,S04,S05,S07_off', 'allb_beta', 'merge_movements', 'basic')\n",
    "VIF_info_fname = pjoin(gv.data_dir,subdir_short,'VIF_info.npz')\n",
    "print(VIF_info_fname)\n",
    "np.savez(VIF_info_fname,VIF_info = d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common = set(VIFtr['colinds_bad_VIFsel'])\n",
    "for i,og in enumerate(outputs_grouped.items() ):\n",
    "    rn = og[0][0]\n",
    "    (prefix,grp,int_type), mult_clf_output = og[1]\n",
    "    VIFtr = mult_clf_output['VIF_truncation']\n",
    "    badinds = VIFtr['colinds_bad_VIFsel']\n",
    "    print(len(badinds), badinds)\n",
    "    common = common & set(badinds)\n",
    "print(len(common),sorted(common,reverse=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = mult_clf_output['corr_matrix']\n",
    "nonsyn_feat_inds = mult_clf_output['nonsyn_feat_inds']\n",
    "C_nonsyn = C[:,nonsyn_feat_inds][nonsyn_feat_inds,:]\n",
    "maxnonsyn = np.max( C_nonsyn - np.diag(np.diag(C_nonsyn))  )\n",
    "maxorig = np.max( C - np.diag(np.diag(C))  )\n",
    "print(maxnonsyn,maxorig, len(C),len(nonsyn_feat_inds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonsyn_feat_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_clf_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lro in VIFtr['VIFsel_linreg_objs']:\n",
    "    c = lro.coef_\n",
    "    print( f'{len(c)}  {np.abs(c).min():.3f}, {c.mean():.3f}, {np.abs(c).max():.3f},  {np.abs(c).sum():.3f}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fromjoint = [92, 91, 90, 89, 88, 87, 86, 85, 84, 83, 82, 81, 80, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 65, 64, 63, 62, 57, 56, 54, 53, 50, 48, 46, 45, 43, 41, 33, 32, 24, 21, 13, 12, 10, 6, 3]\n",
    "print(fromjoint)\n",
    "common - set(fromjoint), set(fromjoint) - common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for prefix_cur in prefixes:\n",
    "#for prefix_cur in prefixes[:3]:\n",
    "#for prefix_cur in prefixes:\n",
    "for prefix in ['onlyH']:\n",
    "    prefixes_to_use = [prefix_cur]\n",
    "\n",
    "    outputs_grouped = pp.groupOutputs(output_per_raw, prefixes_to_use,\n",
    "                                      ['merge_movements'],['basic'])\n",
    "    print('      ',prefix_cur)\n",
    "    for og in outputs_grouped.items():\n",
    "        rn = og[0]\n",
    "        (prefix,grp,int_type), mult_clf_output = og[1]\n",
    "        assert prefix == prefix_cur\n",
    "    \n",
    "        filename_fullsize = mult_clf_output['filename_full']\n",
    "        from pathlib import Path\n",
    "        pfsz = Path(filename_fullsize)\n",
    "        filename_fullsize = pjoin(pfsz.parents[0], pfsz.name[2:])\n",
    "        #    finfo = os.stat( filename_fullsize )\n",
    "        #    print(finfo.st_size / (1024**2))\n",
    "        f = np.load(filename_fullsize,allow_pickle=True)\n",
    "\n",
    "        results_cur =  f['results_cur'][()]\n",
    "\n",
    "        #results_cur.keys()\n",
    "\n",
    "        EBM = results_cur['featsel_per_method']['interpret_EBM']        \n",
    "        #scores\n",
    "\n",
    "        #clf_dict = EBM['info_per_cp'][('trem_L', 'hold_L&move_L')]\n",
    "        fs = 'all'\n",
    "        clf_dict = EBM[fs]\n",
    "        scores = clf_dict['scores']; \n",
    "        #print(len(results_cur['feature_names_filtered']), len(EBM['feature_indices_used']) )\n",
    "        #print('len(scores) = ',len(scores) )\n",
    "        explainer = clf_dict['explainer']\n",
    "        mult_clf_output['featsel_per_method']['interpret_EBM'] [fs]['explainer'] = explainer\n",
    "        \n",
    "        print((rn,grp,int_type), utsne.sprintfPerfs(clf_dict['perf'] ) )\n",
    "\n",
    "        del f\n",
    "        del results_cur\n",
    "        gc.collect()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_clf_output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fse = mult_clf_output['featsel_per_method']['interpret_EBM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fse[fs].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fse[fs]['perf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fse['all']['feature_names']), len(fse['VIFsel']['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featnames_nice = list(mult_clf_output['feature_names_nice'])\n",
    "fns = sorted( zip( fse[fs]['scores'], fse[fs]['feature_names'] ) , key = lambda x: featnames_nice.index(x[1] ) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so = sorted( zip( fse[fs]['scores'], fse[fs]['feature_names'] ) , key = lambda x: x[0] ) \n",
    "scores_sorted,_ = zip(*so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores_sorted,lw=0,marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explainer.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len( explainer.feature_names ) == len(scores)\n",
    "best_feat_name = explainer.feature_names [ np.argmax(scores)]\n",
    "print(best_feat_name)\n",
    "sortinds = np.argsort(scores)\n",
    "last_ind = np.where([ explainer.feature_names[ind].find(' x ') < 0 \\\n",
    "                     for ind in  sortinds])[0][-1]\n",
    "last_ind = sortinds[last_ind]\n",
    "best_feat_name_no_int = explainer.feature_names[last_ind]\n",
    "print(best_feat_name_no_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret import preserve\n",
    "preserve(explainer, best_feat_name_no_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "markers_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_inds_except_curLFP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.printDict(outputs_grouped[('S01',)][1]['XGB_analysis_versions'],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_clf_output = outputs_grouped[('S01',)][1]\n",
    "mult_clf_output['XGB_analysis_versions']['all_present_features']['perf_dict']['confmat_aver']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_clf_output['best_LFP']['XGB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cax,clrb = postp.plotConfmats(outputs_grouped, best_LFP=1)\n",
    "kind = ';'.join( list( outputs_grouped.values() )[0][0] )\n",
    "figname = ','.join( [k[0] for k in outputs_grouped.keys()] ) + f'_confmats_{kind}.pdf'\n",
    "kind = ';  '.join( list( outputs_grouped.values() )[0][0] )\n",
    "plt.suptitle(kind)\n",
    "plt.savefig( pjoin(gv.dir_fig,subdir,figname) )\n",
    "\n",
    "#clrb.set_ticks([23,43])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting \"balanced\" features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "#%debug\n",
    "rname_crop = slice(0,3)\n",
    "#perflists = ['perfs_XGB','perfs_XGB_fs', 'perfs_LDA_featsearch']\n",
    "for rn in output_per_raw:\n",
    "    for lt, it_grp, it_set in to_show:\n",
    "        for prefix in prefixes:\n",
    "            r = output_per_raw[rn].get(prefix, None)\n",
    "            if (r is not None) and (it_grp not in r or it_set not in r[it_grp]):\n",
    "                r = None\n",
    "\n",
    "            if r is None:\n",
    "                print('Warning : no output for ',rn,prefix,it_grp,it_set)\n",
    "                continue\n",
    "            else:\n",
    "                mult_clf_output = r[it_grp][it_set]\n",
    "                \n",
    "                \n",
    "            print(f'Starting {rn} {prefix} {(it_grp,it_set)}')\n",
    "            \n",
    "            featsel_per_method = mult_clf_output['featsel_per_method'] \n",
    "            \n",
    "            info_cur = {}\n",
    "            #sens,spec = res[rn].get(pref, (np.nan, np.nan))\n",
    "            r = output_per_raw[rn].get(prefix, None)\n",
    "            if (r is not None) and (it_grp not in r or it_set not in r[it_grp]):\n",
    "                r = None\n",
    "            \n",
    "            class_labels_good = mult_clf_output['class_labels_good']\n",
    "            class_labels_good_for_classif = mult_clf_output.get('class_labels_good_for_classif',None)\n",
    "            featsel_per_method = mult_clf_output.get('featsel_per_method',None)\n",
    "            featnames = mult_clf_output.get('feature_names_filtered',None)\n",
    "            \n",
    "            lab_enc = mult_clf_output.get('label_encoder',None)\n",
    "            if lab_enc is None:\n",
    "                from sklearn import preprocessing\n",
    "                lab_enc = preprocessing.LabelEncoder()\n",
    "                # just skipped class_labels_good\n",
    "                lab_enc.fit(class_labels_good)\n",
    "\n",
    "            \n",
    "            class_label_ids = lab_enc.inverse_transform( np.arange( len(set(class_labels_good_for_classif)) ) )\n",
    "            \n",
    "            revdict = mult_clf_output['revdict']\n",
    "            class_label_names = [revdict[cli] for cli in class_label_ids]\n",
    "            \n",
    "            featnames2 = np.array(featnames)[ mult_clf_output['best_inds_XGB_fs'] ]\n",
    "            \n",
    "            pt = 'perfs_XGB_fs'\n",
    "            featnames_subset = feat_names_per_prefix[prefix][rn][(it_grp,it_set)][pt]\n",
    "            if featnames_subset is None:\n",
    "                print('  no balanced ind, skipping')\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            figname_prefix=f'{rn}_{prefix}_{(it_grp,it_set)} n={len(featnames_subset)}: ',            \n",
    "#             if (rn,prefix,it_grp,it_set) != ('S01','LFPrel_noself',\n",
    "#                                              'merge_all_not_trem','basic'):\n",
    "#                 continue\n",
    "        \n",
    "            print(rn,prefix,it_grp,it_set,pt, len(featnames))\n",
    "\n",
    "            fshs = ['XGB_Shapley', 'XGB_Shapley2']            \n",
    "            pdf = None\n",
    "            postp.plotFeatSignifSHAP(pdf,featsel_per_method, fshs, \n",
    "                    [featnames,featnames2], class_labels_good_for_classif,class_label_names,\n",
    "                                     featnames_subset, \n",
    "                                     figname_prefix=figname_prefix,\n",
    "                                    n_individ_feats_show = 40);\n",
    "            plt.savefig(pjoin(gv.dir_fig,\n",
    "                              f'FeatImp_stab_{rn}_{prefix}_{(it_grp,it_set)}.pdf') )\n",
    "#             break\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Starting S02 cross_freqmod_beta,gamma:HFO ('merge_nothing', 'basic')\n",
    "S02 cross_freqmod_beta,gamma:HFO merge_nothing basic perfs_XGB_fs 180\n",
    "# /p/project/icei-hbp-2020-0012/OSCBAGDIS/data_proc_code/utils_postprocess_HPC.py in mergeScores(scores, feature_names, collect_groups, scores_type, feature_names_subset)\n",
    "#     918 \n",
    "#     919     if feature_names_subset is not None:\n",
    "# --> 920         assert set( feature_names ) >= set(feature_names_subset)\n",
    "#     921         #indices of subset features in the larger things\n",
    "#     922         #subinds = [ feature_names.index(f) for f in feature_names_subset  ]\n",
    "\n",
    "# AssertionError: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([13, 5]) > set([13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featnames[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featnames_nice[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(featnames), len(featnames_nice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featnames_nice2 = utils.nicenFeatNames(featnames,\n",
    "                                    roi_labels,srcgrouping_names_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revdict = lda_output['revdict']\n",
    "classid_enconded = 0\n",
    "revdict [ lab_enc.inverse_transform([classid_enconded])[0] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fsh,fspm in featsel_per_method.items():\n",
    "    print(fsh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "featnames_nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(featnames_nice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%debug\n",
    "fsh = 'XGB_total_gain'\n",
    "fspm = featsel_per_method[fsh]\n",
    "print( fspm.keys() )\n",
    "scores = fspm['scores']\n",
    "print( scores.shape )\n",
    "\n",
    "numfeats = 20\n",
    "plt.figure(figsize = (20,5))\n",
    "ax = plt.gca()\n",
    "utsne.plotFeatureImportance(ax, featnames, scores, 'XGB_gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(scores[:,0,:-1], axis=0 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'multi:softprob'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fspm['explainer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fspm['explainer'].__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "What are standard methods for evaluation of performance of multiclass classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featnames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotFeatImpStats(feat_types_all, feat_imp_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lblind in range(scores.shape[1] ):\n",
    "    # select points where true class is like the current one\n",
    "    ptinds = np.where(class_labels_good_for_classif == lblind)[0]\n",
    "    classid_enconded = lblind\n",
    "    label_str = revdict [ lab_enc.inverse_transform([classid_enconded])[0] ]\n",
    "    plt.figure(figsize = (20,5))\n",
    "    ax = plt.gca()\n",
    "    utsne.plotFeatureImportance(ax, featnames, scores[ptinds,lblind,:], 'XGB_Shapley')\n",
    "    ax.set_title( f'{prefix}: ' + ax.get_title() + f'_lblind = {label_str} (lblind={lblind})' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsh = 'interpret_EBM'\n",
    "fspm = featsel_per_method[fsh]\n",
    "print( fspm.keys() )\n",
    "info_per_cp = fspm['info_per_cp']\n",
    "for class_pair in info_per_cp:\n",
    "    info_cur = info_per_cp[class_pair]\n",
    "    explainer = info_cur['explainer']\n",
    "    scores = info_cur['scores']\n",
    "\n",
    "    # select points where true class is like the current one                \n",
    "    plt.figure(figsize = (20,5))\n",
    "    ax = plt.gca()\n",
    "    utsne.plotFeatureImportance(ax, featnames, scores, 'EBM', nshow=20)\n",
    "    ax.set_title( f'{prefix}: ' + ax.get_title() + f'{class_pair}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featnames_nice = explainer.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(explainer.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsh = 'SHAP_XGB'\n",
    "fspm = featsel_per_method[fsh]\n",
    "print( fspm.keys() )\n",
    "explainer = fspm['explainer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = fspm['scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featsel_per_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(featsel_per_method.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfs_XGB[ind]['perf_aver']     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfs_XGB[ind].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfs_noCV[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfs_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len( perfs_CV[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(perfs_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len( lda_output['perfs_XGB'][0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gv.dir_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of strongest feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_per_raw['S99_off_hold']['test'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for perf_to_use in perf_to_use_list:\n",
    "    table =  [ [''] +  prefix_labels_perraw[rawnames[0]]]\n",
    "    was_valid = False\n",
    "    for rn in output_per_raw:\n",
    "        for lt, it_grp, it_set in to_show:\n",
    "        #for lt in label_types:\n",
    "            # raw and label type (grouping+int_types) name goes here\n",
    "            # this will be a row name\n",
    "            row_name = '{}_{}'.format(rn[rname_crop], lt)\n",
    "            table_row = [row_name ]\n",
    "            for prefix in prefixes:\n",
    "                #sens,spec = res[rn].get(pref, (np.nan, np.nan))\n",
    "                r = output_per_raw[rn].get(prefix, None)     \n",
    "                if (r is not None) and (it_grp not in r or it_set not in r[it_grp]):\n",
    "                    r = None\n",
    "                \n",
    "                perfs = None\n",
    "                if r is None:\n",
    "                    print('Warning :',rn,prefix)\n",
    "                else:\n",
    "                    lda_output = r[it_grp][it_set]  \n",
    "                    if lda_output is not None:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kord = list(res.keys())\n",
    "#[k[:-5] for k in kord ]\n",
    "table =  [ [''] +  prefixes]\n",
    "for rn in kord:\n",
    "    for lt in label_types:\n",
    "        table_row = ['{}_{}'.format(rn[:-5], lt) ]\n",
    "        for pref in prefixes:\n",
    "            #sens,spec = res[rn].get(pref, (np.nan, np.nan))\n",
    "            r = res[rn].get(pref, None)\n",
    "            if r is None:\n",
    "                print('Warning :',rn,pref)\n",
    "                sfn = ''\n",
    "            else:\n",
    "                sfn = res_strongfeat[rn][pref][lt]\n",
    "            print('{} {} {}\\n  {}'.format(rn,lt,pref,sfn) )\n",
    "            table_row += [ sfn  ]\n",
    "        table += [table_row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = np.array(table)\n",
    "\n",
    "table_fname = \"strongest_feat_table.csv\"\n",
    "\n",
    "\n",
    "pd.DataFrame(table).to_csv(table_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_strongfeat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from featlist import  parseFeatNames\n",
    "r = parseFeatNames(featnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chnames_LFP = [chn for chn in r['ch1'] if chn.find('LFP') >= 0] + [chn for chn in r['ch2'] if (chn is not None and chn.find('LFP') >= 0) ]\n",
    "chnames_LFP = list(sorted(set(chnames_LFP)))\n",
    "chnames_LFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd['A'] = {'1':{'11':3333}}\n",
    "dd.update({'A': {'2':{'22':1666}} })\n",
    "dd.update({'A': {'3':{'22':2666}} })\n",
    "dd.update({'B': {'2':{'22':6666}} })\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at most important LFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chnames_LFP = ['LFPR01', 'LFPR12', 'LFPR23']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_drops = {}\n",
    "groupings_to_use = ['merge_nothing']\n",
    "#rawnames_to_use = ['S99_off_move']\n",
    "rawnames_to_use = rawnames\n",
    "prefixes_to_use = ['modLFP', 'LFPrel']\n",
    "prefixes_to_use = ['modLFP', 'LFPrel_noself']\n",
    "\n",
    "# if all raws were processed together, they'll have same performances saved, no need to repeat\n",
    "\n",
    "#for k in output_per_raw:\n",
    "for ki,k in enumerate(rawnames_to_use):\n",
    "    output_per_prefix = output_per_raw[k]\n",
    "    #for prefix in output_per_prefix:\n",
    "    for prefix in prefixes_to_use:\n",
    "        output_per_grouping = output_per_prefix.get(prefix,None)\n",
    "        if output_per_grouping is None:\n",
    "            continue\n",
    "        #for grouping in output_per_grouping:\n",
    "        for grouping in groupings_to_use:\n",
    "            output_per_int_types = output_per_grouping[grouping]\n",
    "            for int_type in output_per_int_types:\n",
    "                output_cur = output_per_int_types[int_type]\n",
    "                #s = '{}:{}:{}:{}'.format(k,prefix,grouping,int_type)\n",
    "                s = '{}:{}:{}:{}'.format(ki,prefix,grouping,int_type)\n",
    "                if output_cur is None:\n",
    "                    #print(k,prefix,grouping,int_type,'=None')\n",
    "                    continue\n",
    "                lda_anver = output_cur['lda_analysis_versions']\n",
    "                anver_full = lda_anver['all_present_features']\n",
    "                perfs_full = anver_full['CV_aver']['perfs']\n",
    "                perfs_full = np.array(perfs_full)\n",
    "                perfs_str_full = utsne.sprintfPerfs(perfs_full)\n",
    "                print('{}:: Full avCV-LDA perfs {}'.format(s,perfs_str_full))\n",
    "                perf_drops[s] = {}\n",
    "                for chn in chnames_LFP:\n",
    "                    key = 'all_present_features_but_{}'.format(chn)\n",
    "                    anver = lda_anver.get(key,None)\n",
    "                    if anver is None:\n",
    "                        #print(s,' fail')\n",
    "                        break\n",
    "                    perfs = np.mean(anver['CV']['CV_perfs'], axis=0)\n",
    "                    perfs = np.array(perfs)\n",
    "                    \n",
    "                    #print(perfs_full, perfs)\n",
    "                    perfs_str = utsne.sprintfPerfs(perfs)\n",
    "                    \n",
    "                    print('{}:: No {} avCV-LDA perfs {}'.format(s,chn,perfs_str))\n",
    "                    perf_drop = perfs_full - perfs\n",
    "                    \n",
    "                    perf_drops[s][chn] = perf_drop\n",
    "                    print('  Perf drop: ', utsne.sprintfPerfs(perf_drop) )\n",
    "                if len(perf_drops[s]) == 0:\n",
    "                    del perf_drops[s]\n",
    "                #print(lda_anver.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winnder_chans = {}\n",
    "for s,pdcurd in perf_drops.items():\n",
    "    pds = []\n",
    "    # I want ordered access across \n",
    "    for chn in chnames_LFP:\n",
    "        pds += [pdcurd[chn]]\n",
    "    pds = np.vstack(pds)\n",
    "    # axis 0 -- index of channel\n",
    "    maxdrop_perchan = np.max(pds,axis=1)\n",
    "    maxdrop_perchan = np.maximum(maxdrop_perchan,0)\n",
    "    \n",
    "    mindrop_perchan = np.min(pds,axis=1)\n",
    "    mindrop_perchan = np.minimum(mindrop_perchan,0)\n",
    "    # dropping channel should maximum worsen and minimum improve (mindrop is neg)\n",
    "    inds = np.argsort(maxdrop_perchan + mindrop_perchan)\n",
    "    win_ind = inds[-1]\n",
    "    winnder_chans[s] = chnames_LFP[win_ind]\n",
    "    #print(pds*100)\n",
    "    print('{:50} {} {}'.format( s, chnames_LFP[ win_ind ], utsne.sprintfPerfs( pds[win_ind] ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best features plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_output_pg_cur.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_output_pg_cur.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_per_raw.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rncur = rawnames[0]\n",
    "rncur = 'S01_off_hold'\n",
    "#prefix = 'all'\n",
    "#prefix = 'LFPrel_noself'\n",
    "#prefix = 'allb_beta'\n",
    "#prefix = 'modSrc'\n",
    "prefix = 'LFPrel_noself'\n",
    "it_grouping = 'merge_nothing'\n",
    "it_set = 'basic'\n",
    "nbest = 10\n",
    "#nbest_MI = nbest\n",
    "slice_best_feats = slice(-nbest,None)\n",
    "\n",
    "sind_str,mc,tk = utils.getParamsFromRawname(rncur)\n",
    "\n",
    "lda_output_pg_cur = output_per_raw[sind_str][prefix]\n",
    "lda_output = lda_output_pg_cur[it_grouping][it_set]\n",
    "featnames_filtered = lda_output_pg_cur['feature_names_filtered']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfts = ['LDA', 'MI', 'XGB']\n",
    "bft = bfts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sind_str,mc,tk  = utils.getParamsFromRawname(rncur)\n",
    "sources_type='parcel_aal'\n",
    "src_file_grouping_ind = 10\n",
    "src_rec_info_fn = '{}_{}_grp{}_src_rec_info'.format(rncur,\n",
    "                                                    sources_type,src_file_grouping_ind)\n",
    "src_rec_info_fn_full = os.path.join(gv.data_dir, src_rec_info_fn + '.npz')\n",
    "rec_info = np.load(src_rec_info_fn_full, allow_pickle=True)\n",
    "\n",
    "\n",
    "print( list(rec_info.keys()) )\n",
    "\n",
    "labels_dict = rec_info['label_groups_dict'][()]\n",
    "srcgroups_dict = rec_info['srcgroups_dict'][()]\n",
    "coords = rec_info['coords_Jan_actual'][()]\n",
    "srcgrouping_names_sorted = rec_info['srcgroups_key_order'][()]\n",
    "sgdn = 'all_raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feats_dict = {}\n",
    "#feat_info_pri\n",
    "featnames_nice = utils.nicenFeatNames(featnames_filtered,\n",
    "                                    labels_dict,srcgrouping_names_sorted)\n",
    "featnames_nice = np.array(featnames_nice)\n",
    "\n",
    "\n",
    "if 'MI_per_feati' in lda_output:\n",
    "    MI = lda_output['MI_per_feati']\n",
    "\n",
    "    strong_inds = np.argsort(MI)\n",
    "    # increasing oder\n",
    "    best_feats_dict['MI'] = strong_inds\n",
    "\n",
    "if 'strong_inds_LDA' in lda_output:\n",
    "    # increasing oder\n",
    "    strong_inds = lda_output['strong_inds_LDA']\n",
    "    best_feats_dict['LDA'] = strong_inds\n",
    "    \n",
    "# increasing oder\n",
    "strong_inds = lda_output['strong_inds_XGB']\n",
    "best_feats_dict['XGB'] = strong_inds\n",
    "\n",
    "# increasing oder\n",
    "strong_inds = lda_output['inds_important']\n",
    "best_feats_dict['LDA_naive'] = strong_inds\n",
    "\n",
    "# pca_derived_featinds_perthr = lda_output['pca_derived_featinds_perthr']\n",
    "# feat_variance_q_thr = lda_output['feat_variance_q_thr']\n",
    "\n",
    "# for thri,thr in feat_variance_q_thr:\n",
    "#     best_feats_dict['PCA_{:.2f}'.format(thr)] = pca_derived_featinds_perthr[thri] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bft = 'XGB'\n",
    "strong_inds = best_feats_dict[bft][slice_best_feats]\n",
    "#feat_names_cur = featnames_nice[strong_inds]\n",
    "feat_names_cur = featnames_filtered[strong_inds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{}_{}:_{}_{}_{}__{}best descending order\\n'.format(sind_str,prefix,\n",
    "                                              it_grouping,it_set,bft,nbest))\n",
    "feat_names_cur_nice = featnames_nice[strong_inds]\n",
    "for fn in feat_names_cur_nice[::-1]:\n",
    "    print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{}_{}:_{}_{}_{}__{}best descending order\\n'.format(sind_str,prefix,\n",
    "                                              it_grouping,it_set,bft,nbest))\n",
    "feat_names_cur_nice = featnames_nice[strong_inds]\n",
    "for fn in feat_names_cur_nice[::-1]:\n",
    "    print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "src_chns_per_feat_nice = []\n",
    "src_chns_all_nice = []\n",
    "parcel_indices = []\n",
    "parcel_indices_all = []\n",
    "for fni,fn in enumerate(feat_names_cur):\n",
    "    p = 'msrc._[0-9]+_[0-9]+_c[0-9]+'\n",
    "    source_chns_cur_featname = re.findall(p, fn)\n",
    "    if len(source_chns_cur_featname) == 0:\n",
    "        continue\n",
    "    \n",
    "    sides,groupis,parcelis,compis = utils.parseMEGsrcChnamesShortList(source_chns_cur_featname)\n",
    "    parcel_indices_all += parcelis\n",
    "    parcel_indices += [parcelis]\n",
    "    \n",
    "    tmp = list(srcgrouping_names_sorted) * 10  # because we have 9 there\n",
    "    nice_chns_cur_featname = utils.nicenMEGsrc_chnames(source_chns_cur_featname,labels_dict,tmp,\n",
    "                            prefix='msrc_')\n",
    "    nice_chns_cur_featname = list(set(nice_chns_cur_featname))\n",
    "    src_chns_per_feat_nice += [nice_chns_cur_featname]\n",
    "    src_chns_all_nice += nice_chns_cur_featname\n",
    "    print(fn,nice_chns_cur_featname)\n",
    "\n",
    "sgdn='all_raw'\n",
    "parcel_indices_all = list(set(parcel_indices_all))\n",
    "#parcel_indices_all\n",
    "\n",
    "roi_labels = np.array(  labels_dict[sgdn] )\n",
    "rls = ['unlabeled'] + list( roi_labels[parcel_indices_all] )\n",
    "\n",
    "srcgrp = np.zeros( srcgroups_dict[sgdn].shape, dtype=srcgroups_dict[sgdn].dtype)\n",
    "\n",
    "for pii,pi in enumerate(parcel_indices_all):\n",
    "    srcgrp[srcgroups_dict[sgdn] == pi] = pii + 1 #list(roi_labels).index( rls[pii])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featnames_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_labels_MATLAB_mod = [['Precentral','Postcentral','Rolandic_Oper','Supp_Motor_Area','Paracentral_Lobule'],\n",
    " ['Frontal_Sup','Frontal_Sup_Medial', 'Frontal_Sup_Orb'],['Frontal_Mid','Frontal_Mid_Orb','Frontal_Med_Orb'],\n",
    "                         ['Frontal_Inf_Oper','Frontal_Inf_Orb','Frontal_Inf_Tri'],['Parietal_Sup','Precuneus'],\n",
    " ['Parietal_Inf'],['Temporal_Sup'],['Temporal_Mid','Temporal_Pole_Mid'],\n",
    " ['Temporal_Inf'],['Occipital_Sup','Cuneus'],['Occipital_Mid'],\n",
    " ['Occipital_Inf','Calcarine','Lingual'],['Angular'],['SupraMarginal'],['Cerebellum']];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        new_labels = ['Senorimotor', 'FrontalSup', 'FrontalMed', 'FrontalInf', 'ParietalSup',\n",
    "                      'ParietalInf', 'TemporalSup', 'TemporalMid', 'TemporalInf', 'OccipitalSup', 'OccipitalMid',\n",
    "                      'OccipitalInf', 'Angular', 'SupraMarginal', 'Cerebellum']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict( zip(new_labels,old_labels_MATLAB_mod) )\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcgroups_dict[sgdn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict[sgdn].index(rls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rls[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from globvars import gp\n",
    "cand_areas = [a + '_R' for a in gp.areas_list_aal_my_guess]\n",
    "cand_areas_op = [a + '_L' for a in gp.areas_list_aal_my_guess]\n",
    "print(cand_areas)\n",
    "\n",
    "cand_areas_ = list( set(roi_labels) - set( cand_areas) - set( cand_areas_op) )\n",
    "cand_areas = []\n",
    "for ca in cand_areas_:\n",
    "    if ca.startswith('Cerebellum') or ca.endswith('_R'):\n",
    "        cand_areas += [ca]\n",
    "cand_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcel_groupings_post = {}\n",
    "parcel_groupings_post['M1-ish'] = ['Precentral','Supp_Motor_Area', 'Rolandic_Oper',\n",
    "                                  'Postcentral', 'Paracentral_Lobule']\n",
    "parcel_groupings_post['Parietal'] = ['Parietal_Sup', 'Parietal_Inf']\n",
    "parcel_groupings_post['Cerebellum'] = ['Cerebellum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcand = ['Angular_R', 'Occipital_Mid_R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=0\n",
    "num_to_show=40\n",
    "sl = slice(s,s+num_to_show,1)\n",
    "areas_cur = cand_areas[sl]\n",
    "areas_cur = newcand\n",
    "print(areas_cur)\n",
    "clrs =  utils.vizGroup2(sind_str,coords,areas_cur,srcgroups_dict[sgdn], show=False, \n",
    "                       figsize_mult=1.5,msz=30, printLog=0, \n",
    "                        roi_labels_all = labels_dict[sgdn], show_legend=1,\n",
    "                        alpha_surf=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gn,areas_cur_ in d.items():\n",
    "    areas_cur = [a + '_R' for a in areas_cur_]\n",
    "    axs,clrs =  utils.vizGroup2(sind_str,coords,areas_cur,srcgroups_dict[sgdn], show=False, \n",
    "                       figsize_mult=1.5,msz=30, printLog=0, \n",
    "                        roi_labels_all = labels_dict[sgdn], show_legend=1,\n",
    "                        alpha_surf=0.05)\n",
    "    axs[0].set_title(gn)\n",
    "    #plt.suptitle(gn)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrs =  utils.vizGroup2(sind_str,coords,rls,srcgrp, show=False, alpha=.1,\n",
    "                       figsize_mult=1.5,msz=30, printLog=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "figname = '{}_{}:_{}_{}_{}_srcmap_{}best'.format(sind_str,prefix,\n",
    "                                              it_grouping,it_set,bft,nbest)\n",
    "plt.gcf().axes[0].set_title(figname)\n",
    "#plt.savefig(figname+'.png')\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_per_raw['S01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rncur = rawnames[0]\n",
    "#prefix = 'all'\n",
    "#prefix = 'LFPrel_noself'\n",
    "#prefix = 'allb_beta'\n",
    "#prefix = 'modSrc'\n",
    "#prefix = 'LFPrel_noself'\n",
    "prefix = 'modLFP'\n",
    "it_grouping = 'merge_nothing'\n",
    "it_set = 'basic'\n",
    "nbest = 10\n",
    "#nbest_MI = nbest\n",
    "slice_best_feats = slice(-nbest,None)\n",
    "\n",
    "lda_output_pg_cur = output_per_raw[rncur][prefix]\n",
    "lda_output = lda_output_pg_cur[it_grouping][it_set]\n",
    "featnames_filtered = lda_output_pg_cur['feature_names_filtered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_anver = lda_output['lda_analysis_versions']\n",
    "print(lda_anver.keys())\n",
    "featset_name = 'all_present_features'\n",
    "model = lda_anver[featset_name]['CV_aver']['ldaobj']\n",
    "perfs = lda_anver[featset_name]['CV_aver']['perfs']\n",
    "utsne.sprintfPerfs(perfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Ximp_per_raw[rncur][prefix]\n",
    "gi = gis_per_raw[rncur][prefix]\n",
    "X_to_fit = X[gi]\n",
    "print(X_to_fit.shape)\n",
    "nsamples = 30\n",
    "Xsubset = shap.utils.sample(X_to_fit, nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "21 * 20 * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute SHAP values\n",
    "explainer= shap.Explainer(model.predict, Xsubset,feature_names=featnames_filtered)\n",
    "shap_values = explainer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values, max_display=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.scatter(shap_values[:,1], color=shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ind = 3\n",
    "shap.plots.waterfall(shap_values[sample_ind]) #, max_display=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pyenv",
   "language": "python",
   "name": ".pyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
