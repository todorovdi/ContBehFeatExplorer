{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb6396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, mne, json, h5py, pymatreader, re, time, gc;\n",
    "import globvars as gv\n",
    "import utils\n",
    "import utils_tSNE as utsne\n",
    "import utils_preproc as upre\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import multiprocessing as mpr\n",
    "import matplotlib as mpl\n",
    "import scipy.signal as sig\n",
    "import pandas as pd \n",
    "import utils_postprocess_HPC as postp\n",
    "\n",
    "data_dir = gv.data_dir\n",
    "from os.path import join as pjoin\n",
    "\n",
    "light_only = 1\n",
    "#light_only = 0\n",
    "ndaysBefore = None\n",
    "\n",
    "from dateutil import parser\n",
    "# start_time = parser.parse(\"6 Sept 2021 19:05:15\")\n",
    "# end_time = parser.parse(\"8 Sept 2021 21:21:45\")\n",
    "#start_time = parser.parse(\"26 Sept 2021 01:00:15\")\n",
    "#start_time = parser.parse(\"27 April 2022 16:30:15\")\n",
    "start_time = parser.parse(\"2 Sept 2022 09:00:00\")\n",
    "#end_time = parser.parse(\"30 Oct 2021 21:21:45\")\n",
    "end_time = parser.parse(\"30 Oct 2029 21:21:45\")\n",
    "\n",
    "ndaysBefore = None\n",
    "#subdir = 'nointerp'\n",
    "#subdir = 'nofeatsel'\n",
    "subdir = 'joint_best_LFP_wholectx'\n",
    "lookup_dir = pjoin(gv.data_dir,subdir)\n",
    "recent = postp.listRecent(days=ndaysBefore, lookup_dir= lookup_dir,\n",
    "                          start_time=start_time,\n",
    "                                   end_time=end_time)\n",
    "print(len(recent))\n",
    "rawnames = []\n",
    "rawname_regex = '([S0-9,]+)'\n",
    "re1 = re.compile('_\\!_'+rawname_regex+'_.*')\n",
    "re2 = re.compile('_'+rawname_regex+'_.*')\n",
    "for lf in recent:\n",
    "    st = 0\n",
    "    if light_only:\n",
    "        if not lf.startswith('_!'):\n",
    "            continue    \n",
    "    if light_only:\n",
    "        r = re.match(re1,lf)\n",
    "    else:\n",
    "        r = re.match(re2,lf)\n",
    "    if r is None:\n",
    "        print('None ',lf)\n",
    "        continue\n",
    "    cr = r.groups()[0]\n",
    "    if cr not in rawnames:\n",
    "        rawnames += [ cr ]\n",
    "rawnames = list(sorted(set(rawnames)))\n",
    "\n",
    "#a0 = re.findall('_\\!_'+rawname_regex+'_.*',lf)\n",
    "#a1 = re.match('_\\!_'+rawname_regex+'_.*',lf)\n",
    "#print(a0,a1.groups())#\n",
    "\n",
    "import utils_postprocess_HPC as postp\n",
    "prefixes = postp.listRecentPrefixes(days = ndaysBefore, light_only=light_only, \n",
    "                                    lookup_dir= lookup_dir, \n",
    "                                    custom_rawname_regex = rawname_regex, \n",
    "                                    start_time=start_time,\n",
    "                                   end_time=end_time)\n",
    "\n",
    "print(rawnames)\n",
    "display(prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12989458",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_remove = ['onlyH_act_only50', 'onlyH_act_only49']\n",
    "# to_remove = ['onlyH_act_only50']\n",
    "# for pref in to_remove:\n",
    "#     prefixes.remove(pref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3955e2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_postprocess import printSizeInfo\n",
    "#for i,tpl in enumerate(tpll):\n",
    "    #print(i); printSizeInfo(tpl[-1])\n",
    "printSizeInfo(tpll[4][-1],depthcur=0,depthleft=5 , minsize=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7008cf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#('S01_off', 'modLFP') {'trem_L': '19.2%=64.3s', 'notrem_L': '32.3%=108.0s', 'hold_L': '24.8%=83.0s', 'move_L': '23.6%=79.0s'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efd151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_postprocess_HPC import checkPrefixCollectionConsistencty\n",
    "#for grouping_to_check in ['merge_nothing']: #, 'merge_movements']:\n",
    "for grouping_to_check,it_to_check in [ ('merge_all_not_trem','basic'), ('merge_movements','basic'),\n",
    "                                      ('merge_nothing','basic'), ('merge_nothing','trem_vs_quiet') ]:\n",
    "    print('   ',grouping_to_check,it_to_check)\n",
    "    r = checkPrefixCollectionConsistencty(subdir,prefixes,start_time, end_time,  \n",
    "                                          grouping_to_check, it_to_check,\n",
    "                                          use_main_LFP_chan=1, light_only=1, \n",
    "                                         prefixes_ignore  = [], preloaded=None)\n",
    "    missing, preloaded = r\n",
    "    print('missing=', missing)\n",
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a84dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ff = preloaded['S02_on']['onlyH_act_only15']['merge_nothing']['basic']['_fname_full']\n",
    "# ff,os.path.exists(ff)\n",
    "\n",
    "# f = np.load(ff,allow_pickle=1)\n",
    "# rt = f['results_light'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68367e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del f,rt,ff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8155da1a",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b51b524",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_type = 'parcel_aal'  # or ''\n",
    "load = False # whether I want to do actual load or just collect filenames (for deferred loading)\n",
    "r = postp.collectPerformanceInfo3(None,prefixes, nraws_used='[0-9]+',                                                                                                    \n",
    "          sources_type = sources_type, \n",
    "           printFilenames=1,                                 \n",
    "            ndays_before=ndaysBefore,\n",
    "            use_main_LFP_chan=1,\n",
    "             subdir=subdir, remove_large_items = 1,\n",
    "             list_only=0, allow_multi_fn_same_prefix=0,\n",
    "             use_light_files = light_only, rawname_regex_full=1,\n",
    "             start_time=start_time,\n",
    "               end_time=end_time, load=load)\n",
    "\n",
    "#nraws_used='(10,12,20,24)'\n",
    "#output_per_raw,Ximp_per_raw,gis_per_raw = r\n",
    "output_per_raw,_,_ = r\n",
    "print('len(output_per_raw) =', len(output_per_raw))\n",
    "import gc; gc.collect()\n",
    "\n",
    "if load:\n",
    "    np.savez(pjoin(gv.data_dir,subdir,'gathered.npz'), output_per_raw=output_per_raw )\n",
    "import gc; gc.collect()\n",
    "\n",
    "#Audio(filename=sound_file, autoplay=True)\n",
    "import utils_postprocess as pp\n",
    "tpll = pp.multiLevelDict2TupleList(output_per_raw,4,3)\n",
    "\n",
    "z0 = [tpl[:-1] for tpl in tpll]\n",
    "#rns_ord, prefs_ord, grp_ord, it_ord = list (zip(*z0  ) )\n",
    "tpll_reshaped = np.array( list (zip(*z0  ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73775ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "for tpl in tpll:\n",
    "    moc = tpl[-1]\n",
    "    fn = Path(moc['filename_full'] ).name\n",
    "    if fn.startswith('_!'):\n",
    "        continue\n",
    "    else:\n",
    "        print(fn , datetime.fromtimestamp(moc['mod_time'] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6a0952",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rn = 'S01,S04,S05'\n",
    "test_rn_comb = 'S01,S04,S05_off,on'\n",
    "if test_rn in rawnames:\n",
    "    del rawnames[rawnames.index(test_rn)]\n",
    "if test_rn_comb in output_per_raw:\n",
    "    del output_per_raw[test_rn_comb]\n",
    "    \n",
    "# rns_inc_S05 = ['S01,S02,S04,S05,S07_on', 'S01,S02,S03,S04,S05,S07_off']\n",
    "# for rn in rns_inc_S05:\n",
    "#     if rn in rawnames:\n",
    "#         del rawnames[rawnames.index(rn)]\n",
    "#     if rn in output_per_raw:\n",
    "#         del output_per_raw[rn]\n",
    "rawnames, output_per_raw.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543d4bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_postprocess_HPC import getOutputSetInfo\n",
    "getOutputSetInfo(output_per_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cb62c4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Check runstrings gens ids present and times distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ca0e18",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import utils_postprocess as pp\n",
    "from datetime import datetime\n",
    "from utils_postprocess_HPC import loadRunCorresp\n",
    "CIDs,cretimes = [],[]\n",
    "mod_times = []\n",
    "nloaded = 0\n",
    "for tpl in tpll:\n",
    "    moc = tpl[-1]\n",
    "    corresp,all_info = loadRunCorresp(moc)\n",
    "    if moc['loaded']:\n",
    "        if 'cmd' not in moc:\n",
    "            print(f'Cmd is not in {tpl[:-1]}')\n",
    "            break\n",
    "        runCID = dict( moc['cmd'][0] ).get('--runCID', None) \n",
    "        moc['runstrings_creation_time'] = all_info['date_created']\n",
    "        moc['runCID'] = runCID\n",
    "        CIDs += [runCID]\n",
    "        cretimes += [all_info['date_created']]\n",
    "\n",
    "        #mod_time = os.stat( moc['filename_full'] ).st_mtime\n",
    "        mod_time = moc['mod_time']\n",
    "        dt = datetime.fromtimestamp(mod_time)\n",
    "        moc['mod_time_dt'] = dt\n",
    "        nloaded += 1\n",
    "    \n",
    "    mod_times += [moc['mod_time']] # timestamps only\n",
    "\n",
    "bv,bcoord,_ = plt.hist(mod_times)\n",
    "mn = datetime.fromtimestamp ( np.min(bcoord) )\n",
    "mx = datetime.fromtimestamp ( np.max(bcoord) )\n",
    "delta = mx-mn\n",
    "print(f'Time spread = {delta}, time min = {mn}, time max = {mx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6806b1df",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if not nloaded:\n",
    "    print('Nothing is loaded :(')\n",
    "CIDs = list( map(int,CIDs) ) \n",
    "CIDs_sorted = list( sorted( set( map(int,CIDs) ) ) )\n",
    "for CID in CIDs_sorted:\n",
    "    inds = np.where( np.array(CIDs) == CID )[0]\n",
    "    times = [tpll[i][-1]['fname_mod_time'] for i in inds]\n",
    "    times = list( sorted(times) )\n",
    "    print('CID =  ',CID, 'len(inds)=',len(inds), times[0], times[-1] )\n",
    "CID_most_recent = list( sorted( map(int,CIDs) ) )[-1]\n",
    "print('most recent CID=', CID_most_recent )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8bfdd7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if not nloaded:\n",
    "    print('Nothing is loaded :(')\n",
    "# load large file with gathered\n",
    "import utils_postprocess as pp\n",
    "load_precollected = 0\n",
    "if load_precollected:\n",
    "    output_per_raw = np.load(pjoin(gv.data_dir,subdir,'gathered.npz'),allow_pickle=1)\n",
    "    output_per_raw = output_per_raw['output_per_raw'][()]\n",
    "    print('len(output_per_raw) =', len(output_per_raw))\n",
    "    tpll = pp.multiLevelDict2TupleList(output_per_raw,4,3)\n",
    "\n",
    "    z0 = [tpl[:-1] for tpl in tpll]\n",
    "    #rns_ord, prefs_ord, grp_ord, it_ord = list (zip(*z0  ) )\n",
    "    tpll_reshaped = np.array( list (zip(*z0  ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7111d14",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Check completness of loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e574687e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from utils_postprocess_HPC import checkTupleListTableCompleteness\n",
    "b,missing = checkTupleListTableCompleteness(tpll_reshaped)\n",
    "\n",
    "outputs_filtered = postp.filterOutputs(output_per_raw, rns=rawnames, \n",
    "                    prefs=prefixes, grps = ['merge_nothing'] )\n",
    "b,missing =  checkTupleListTableCompleteness(outputs_filtered)\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f82685",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Tremor and other beh states durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc5cc23",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TODO NEXT -- try to compare merge nothing with other groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf87f25",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if not nloaded:\n",
    "    print('Nothing is loaded :(')\n",
    "grp = 'merge_nothing'\n",
    "#pref_print = 'modLFP'\n",
    "#ref_print = 'onlyH_act_LFPand_only13'\n",
    "pref_print = 'onlyH_actLL'\n",
    "print('pref_print', pref_print)\n",
    "r = {}\n",
    "for tpl in sorted(tpll, key= lambda x: rawnames.index(x[0]) * 1000 + prefixes.index(x[1]) ):\n",
    "    if tpl[2] != grp or tpl[1] != pref_print:\n",
    "        continue\n",
    "    cts = tpl[-1]['counts']\n",
    "    tot = np.sum( list(cts.values()) )\n",
    "    cts2 = cts.copy()\n",
    "    s = ''\n",
    "    for k,v in cts.items():\n",
    "        k2 = k[:-2]\n",
    "        #k2 = k\n",
    "        stmp = f'{v / tot * 100:4.1f}%={v/32:5.1f}s'\n",
    "        cts2[k2] = stmp\n",
    "        s += f', {k2}: {stmp}'\n",
    "    #print(tpl[:2],  cts2)\n",
    "    print(f'{tpl[0]:7} {s[1:]}')\n",
    "    #print(tpl[:2],  cts2['trem_L'])\n",
    "    #k = ','.join( tpl[:-1] )\n",
    "    k = tpl[:-1]\n",
    "    r[k] = {}\n",
    "    r[k]['counts'] = cts\n",
    "    r[k]['infostr'] = s\n",
    "    r[k]['total'] = tot / 32\n",
    "    r[k]['bacc'] = tpl[-1]['XGB_analysis_versions']['all_present_features']['perf_dict']['perf_aver']['balanced_accuracy']\n",
    "    \n",
    "if len(r):\n",
    "    # import json\n",
    "    # fn_full  = pjoin(gv.data_dir,subdir,'beh_states_durations.json')\n",
    "    # with open(fn_full,'w') as f:\n",
    "    #     json.dump(r,f)\n",
    "    fn_full  = pjoin(gv.data_dir,subdir,\n",
    "        f'beh_states_durations_CID{CID_most_recent}.npz')\n",
    "    np.savez(fn_full, r)\n",
    "    print('beh state duration saved to ',fn_full)\n",
    "else:\n",
    "    print('zero len!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33f79a3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8251e801",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1c726b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# REGEX =  '_!_([,0123456789S_defhlmnorstv]+)_parcel_aal_grp10-0_([a-zA-Z0-9_,:]+)_ML_nr[0-9]{2,4}_.*'#'[0-9]+' +\\\n",
    "# #'chs_nfeats[0-9]+_pcadim[0-9]+_skip[0-9]+_wsz[0-9]+_mainLFP__\\(([a-zA-Z0-9_&]+),([a-zA-Z0-9_&]+)\\).npz'\n",
    "# #rawname_regex = '([S0-9]+_[a-z]+)'\n",
    "# a1 = re.match(REGEX,lf)\n",
    "# a1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2195257d",
   "metadata": {},
   "source": [
    "# Starting plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fb7b72",
   "metadata": {},
   "source": [
    "### prepare table info (long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b634567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%debug\n",
    "# mult_clf_output = tpll[0][-1]\n",
    "# all_thrs = mult_clf_output['feat_variance_q_thr'][-1:]\n",
    "# #thr0,thr1,thr2='0.87','0.92','0.99'\n",
    "# all_LDA =  []\n",
    "# all_XGB = ['all_present_features'] #,'after_VF_threshold']\n",
    "# for thr_cur in all_thrs:\n",
    "#     all_XGB += [ f'best_PCA-derived_features_{thr_cur}']\n",
    "\n",
    "# perf_to_use_list = []\n",
    "# for v in all_XGB[1:]:\n",
    "#     perf_to_use_list += [('XGB',all_XGB[0],v,'across_medcond')]\n",
    "    #perf_to_use_list += [('XGB',all_XGB[0],v,'across_subj')]\n",
    "    \n",
    "#perf_to_use_list = [('XGB',all_XGB[0], f'best_PCA-derived_features_{all_thrs[-1]}','across_subj')]\n",
    "\n",
    "perf_to_use_list = [('XGB','all_present_features', f'best_PCA-derived_features_0.99','across_subj')]\n",
    "\n",
    "###########################################\n",
    "display(perf_to_use_list)\n",
    "\n",
    "# to_show = [('allsep','merge_nothing','basic'), ('trem_vs_all','merge_all_not_trem','basic'),\n",
    "#         ('trem_vs_2class','merge_movements','basic')]\n",
    "#to_show = [('trem_vs_mvt','merge_movements','trem_vs_hold&move'),\n",
    "#           ('trem_vs_all','merge_all_not_trem','basic') ]\n",
    "#             ('trem_vs_2class','merge_movements','basic'),\n",
    "#to_show = [('trem_vs_all','merge_all_not_trem','basic') ]\n",
    "to_show = []\n",
    "to_show += [('allsep','merge_nothing','basic') ]\n",
    "#to_show += [('trem_vs_2class','merge_movements','basic')]\n",
    "#to_show += [('trem_vs_all','merge_all_not_trem','basic')]\n",
    "to_show += [('trem_vs_quiet','merge_nothing','trem_vs_quiet') ]\n",
    "# to_show += [('trem_vs_quiet','merge_all_not_trem','trem_vs_quiet') ]\n",
    "#             ('trem_vs_2class','merge_movements','basic'),\n",
    "\n",
    "#%debug\n",
    "# warnings.simplefilter('error')\n",
    "df, table_info_per_perf_type, table_per_perf_type = \\\n",
    "    postp.prepTableInfo3(output_per_raw, prefixes=prefixes, \n",
    "    perf_to_use_list=perf_to_use_list, to_show=to_show, return_df = True)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "df_all = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1731bc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpll[0][-1]['perfs_XGB'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0343fa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d53f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sens_add']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e758951",
   "metadata": {},
   "source": [
    "### Compare main stats with other feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50437671",
   "metadata": {},
   "outputs": [],
   "source": [
    "grps,its = set(df['grouping']), set(df['interval_set'])\n",
    "grps,its"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b9a973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52bc80f3",
   "metadata": {},
   "source": [
    "#### Change df a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58758a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_postprocess_HPC import getTremorDetPerf,getMocFromRow\n",
    "def addTremorPerf(row):\n",
    "    grp,it = row['grouping'],row['interval_set']\n",
    "    moc = getMocFromRow(row, output_per_raw)\n",
    "    r = getTremorDetPerf(moc,grp,it) \n",
    "    return r\n",
    "def addTremorPerfAcross(row):\n",
    "    grp,it = row['grouping'],row['interval_set']\n",
    "    moc = getMocFromRow(row, output_per_raw)\n",
    "    r = getTremorDetPerf(moc,grp,it,across='subj') \n",
    "    return r\n",
    "\n",
    "df['tremor_det_perf'] = df.apply(addTremorPerf,axis=1)\n",
    "df['tremor_det_perf_across'] = df.apply(addTremorPerfAcross,axis=1)\n",
    "df.reset_index()\n",
    "\n",
    "df['num'] = pd.to_numeric(df['num'])\n",
    "df['num'] = df['num'].map(lambda x: int(x) if ( not (np.isnan(x) or (x is None) ) ) else 0    )\n",
    "df['numpts'] = pd.to_numeric(df['numpts'])\n",
    "df['sens'] = pd.to_numeric(df['sens'])\n",
    "df['spec'] = pd.to_numeric(df['spec'])\n",
    "\n",
    "####################\n",
    "import globvars as gv\n",
    "fname = pjoin(gv.data_dir,subdir,'df_collected.pkl')\n",
    "df.to_pickle(fname)\n",
    "################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd9798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_cur['runCID'] = runCID\n",
    "# results_cur['runstring_ind'] =  runstring_ind\n",
    "# results_cur['SLURM_job_id'] =  SLURM_job_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e0665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa13cb8d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Create sub df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95f5bb1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf766c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a1345f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "use_prefix = False\n",
    "#dfsub = df[['rawname','prefix','prefix_templ', 'num','numpts','bacc','bacc_shuffled']]\n",
    "dfsub = df[['rawname','grouping','interval_set',\n",
    "            'prefix','prefix_templ', 'num','numpts','bacc','bacc_shuffled','bacc_add','sens','spec',\n",
    "           'tremor_det_perf','tremor_det_perf_across']]\n",
    "\n",
    "# prefs_to_compare = ['onlyH_subskip8','onlyH_act_subskip8','onlyH_mob_subskip8','onlyH_compl_subskip8','allb_beta_noH_subskip8','allb_gamma_noH_subskip8','allb_tremor_noH_subskip8',\n",
    "#         'LFPrel_noself_subskip8','modSrc_self_subskip8','modSrc_subskip8','modLFP_subskip8']\n",
    "\n",
    "if use_prefix:\n",
    "    prefs_to_compare = ['onlyH_subskip8','onlyH_act_subskip8',\n",
    "                        'onlyH_mob_subskip8','onlyH_compl_subskip8','onlyH_modLFP_subskip8']\n",
    "    prefix_role = 'prefix'\n",
    "else:\n",
    "    pref_templs_to_compare = ['onlyH_subskip8%%','onlyH_act_subskip8%%',\n",
    "#                        'onlyH_mob_subskip8%%','onlyH_compl_subskip8%%',\n",
    "                             'onlyH_modLFP_subskip8%%']\n",
    "    prefix_role = 'prefix_templ'\n",
    "\n",
    "dfsub2 = dfsub[ dfsub[prefix_role].isin(pref_templs_to_compare) ]\n",
    "\n",
    "#dfsub2 = dfsub2[ (dfsub2['grouping'] == grp) & (dfsub2['interval_set'] == it) ]\n",
    "grp =  dfsub2.groupby( by=[prefix_role,'grouping','interval_set'] )\n",
    "\n",
    "assert tuple( set( list( grp.count()['rawname'] ) ) )  == tuple([2])\n",
    "#grp.count()\n",
    "\n",
    "#print ( len( dfsub2.groupby('prefix') ) )\n",
    "dfmn = grp.mean().reset_index()\n",
    "dfstd = grp.std().reset_index()\n",
    "\n",
    "rename_dict = dict( zip( list( dfstd.columns), [col + '_std' for col in  dfstd.columns  ] ) )\n",
    "del rename_dict[prefix_role]\n",
    "del rename_dict['grouping']\n",
    "del rename_dict['interval_set']\n",
    "dfstd = dfstd.rename(columns=rename_dict)\n",
    "\n",
    "rename_dict = dict( zip( list( dfmn.columns), [col + '_mean' for col in  dfmn.columns  ] ) )\n",
    "del rename_dict[prefix_role]\n",
    "del rename_dict['grouping']\n",
    "del rename_dict['interval_set']\n",
    "dfmn = dfmn.rename(columns=rename_dict)\n",
    "\n",
    "dfstat = dfmn\n",
    "for col in dfstd.columns:\n",
    "    if col in ['prefix_templ','prefix','num_std','grouping','interval_set']:\n",
    "        continue\n",
    "    dfstat[col] = dfstd[col]\n",
    "cols_desired = [prefix_role, 'grouping','interval_set','bacc_mean','bacc_std',\n",
    "                      'bacc_add_mean','bacc_add_std',                      \n",
    "                'tremor_det_perf_mean','tremor_det_perf_std', \n",
    "                'tremor_det_perf_across_mean','tremor_det_perf_across_std',\n",
    "                'num_mean']\n",
    "dfstat_short = dfstat[cols_desired]\n",
    "\n",
    "display( dfstat_short )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06367ee7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### print nice all info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b0d647",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "show_only_act = 0\n",
    "if show_only_act:\n",
    "    if prefix_role == 'prefix':\n",
    "        good = 'onlyH_act_subskip8'\n",
    "    else:\n",
    "        good = 'onlyH_act_subskip8%%'\n",
    "    dfstat_short_nice = dfstat_short[dfstat_short[prefix_role] == good].copy()    \n",
    "else: # all Hjorth\n",
    "    dfstat_short_nice = dfstat_short.copy()\n",
    "dfstat_short_nice = dfstat_short_nice.drop(['num_mean'], axis=1) # here (unlike in medcondsep) I want to drop num_mean anyway\n",
    "\n",
    "rename_dict = {}\n",
    "for s in dfstat_short_nice[prefix_role]:\n",
    "    if prefix_role == 'prefix':\n",
    "        s2 = s[:-(len('subskip8')+1)]\n",
    "    else:\n",
    "        s2 = s[:-(len('subskip8')+3)]\n",
    "    rename_dict[s] = s2\n",
    "display(rename_dict)\n",
    "#dfstat_short_nice.rename(lambda x: x.replace(rename_dict[x] ) , axis='columns')\n",
    "dfstat_short_nice[prefix_role].replace(rename_dict, inplace=True )\n",
    "\n",
    "assert( len( set(dfstat_short_nice['grouping'])  )  ) == 1\n",
    "print(dfstat_short_nice['grouping'])\n",
    "dfstat_short_nice = dfstat_short_nice.drop(['grouping'], axis=1)\n",
    "\n",
    "\n",
    "rename_dict = {'onlyH':'all Hjorth parameters' , 'onlyH_act':'Hjorth activity', \n",
    "               'onlyH_mob':'Hjorth mobility', 'onlyH_compl':'Hjorth complexity', 'onlyH_modLFP':'all Hjorth parameters of LFP'}\n",
    "dfstat_short_nice[prefix_role].replace(rename_dict, inplace=True )\n",
    "\n",
    "# rename_dict = { 'merge_all_not_trem':'all non-tremor states', \n",
    "#             'merge_movements':'voluntary movements',\n",
    "#             'merge_nothing':'none'          }\n",
    "# dfstat_short_nice['grouping'].replace(rename_dict, inplace=True )\n",
    "\n",
    "rename_dict = { 'basic':'tremor,quiet,hold,grasp', \n",
    "            'trem_vs_quiet':'tremor,quiet'  }\n",
    "dfstat_short_nice['interval_set'].replace(rename_dict, inplace=True )\n",
    "\n",
    "pctf = lambda x: f'{x * 100:.0f}%'\n",
    "# if not show_only_act:\n",
    "#     dfstat_short_nice['num_mean'] = dfstat_short_nice['num_mean'].map(int)\n",
    "    \n",
    "pctize = ['bacc_mean','bacc_std','tremor_det_perf_mean','tremor_det_perf_std','bacc_add_mean','bacc_add_std',\n",
    "          'tremor_det_perf_across_mean','tremor_det_perf_across_std']\n",
    "for coln in pctize:\n",
    "    dfstat_short_nice[coln] = dfstat_short_nice[coln].apply(pctf)\n",
    "# dfstat_short_nice['performance / feature number'] = \\\n",
    "#     dfmn.apply(lambda row: f'{row.bacc_mean / row.num_mean:.4f}', axis=1 )\n",
    "\n",
    "# rename column names\n",
    "rename_dict = {}\n",
    "rename_dict[prefix_role] = 'Feature set'\n",
    "#rename_dict['grouping'] = 'behav. states merged'\n",
    "rename_dict['interval_set'] = 'behav. states used'\n",
    "rename_dict['bacc_mean'] = 'performance mean'\n",
    "rename_dict['bacc_std'] = 'performance std'\n",
    "rename_dict['bacc_add_mean'] = 'performance across subj. mean'\n",
    "rename_dict['bacc_add_std'] = 'performance across subj. std'\n",
    "\n",
    "rename_dict['tremor_det_perf_mean'] = 'tremor detection mean'\n",
    "rename_dict['tremor_det_perf_std'] = 'tremor detection std'\n",
    "\n",
    "rename_dict['tremor_det_perf_across_mean'] = 'tremor detection across subj. mean'\n",
    "rename_dict['tremor_det_perf_across_std'] = 'tremor detection across subj. std'\n",
    "# if not show_only_act:\n",
    "#     rename_dict['num_mean'] = 'feature number'\n",
    "dfstat_short_nice.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "columns = np.array(list(dfstat_short_nice.columns) )[[0,1,2,5,6,3,4]]\n",
    "columns\n",
    "\n",
    "#dfstat_short_nice[columns]\n",
    "dfstat_short_nice.style.set_properties(**{'text-align': 'left'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b14cdc",
   "metadata": {},
   "source": [
    "#### create sub df (without grouping of raws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76c17bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_prefix = False\n",
    "#dfsub = df[['rawname','prefix','prefix_templ', 'num','numpts','bacc','bacc_shuffled']]\n",
    "dfsub = df[['rawname','grouping','interval_set',\n",
    "            'prefix','prefix_templ', 'num','numpts','bacc','bacc_shuffled','bacc_add','sens','spec',\n",
    "           'tremor_det_perf','tremor_det_perf_across']]\n",
    "\n",
    "# prefs_to_compare = ['onlyH_subskip8','onlyH_act_subskip8','onlyH_mob_subskip8','onlyH_compl_subskip8','allb_beta_noH_subskip8','allb_gamma_noH_subskip8','allb_tremor_noH_subskip8',\n",
    "#         'LFPrel_noself_subskip8','modSrc_self_subskip8','modSrc_subskip8','modLFP_subskip8']\n",
    "\n",
    "if use_prefix:\n",
    "    pref_templs_to_compare = ['onlyH_subskip8','onlyH_act_subskip8',\n",
    "                        'onlyH_mob_subskip8','onlyH_compl_subskip8','onlyH_modLFP_subskip8']\n",
    "    prefix_role = 'prefix'\n",
    "else:\n",
    "    pref_templs_to_compare = ['onlyH_subskip8%%','onlyH_act_subskip8%%',\n",
    "#                        'onlyH_mob_subskip8%%','onlyH_compl_subskip8%%',\n",
    "                             'onlyH_modLFP_subskip8%%']\n",
    "    prefix_role = 'prefix_templ'\n",
    "\n",
    "dfstat = dfsub[ dfsub[prefix_role].isin(pref_templs_to_compare) ]\n",
    "\n",
    "for col in dfstd.columns:\n",
    "    if col in ['prefix_templ','prefix','num_std','grouping','interval_set']:\n",
    "        continue\n",
    "    dfstat[col] = dfstd[col]\n",
    "cols_desired = ['rawname', prefix_role, 'grouping','interval_set','bacc',\n",
    "                      'bacc_add',                      \n",
    "                'tremor_det_perf',\n",
    "                'tremor_det_perf_across',\n",
    "                'num']\n",
    "dfstat_short = dfstat[cols_desired]\n",
    "\n",
    "display( dfstat_short )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0311c5e",
   "metadata": {},
   "source": [
    "#### print nice all info (w/o gropuing across rawnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262e9b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb228265",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_only_act = 0\n",
    "if show_only_act:\n",
    "    if prefix_role == 'prefix':\n",
    "        good = 'onlyH_act_subskip8'\n",
    "    else:\n",
    "        good = 'onlyH_act_subskip8%%'\n",
    "    dfstat_short_nice = dfstat_short[dfstat_short[prefix_role] == good].copy()    \n",
    "else: # all Hjorth\n",
    "    dfstat_short_nice = dfstat_short.copy()\n",
    "dfstat_short_nice = dfstat_short_nice.drop(['num'], axis=1) # here (unlike in medcondsep) I want to drop num_mean anyway\n",
    "\n",
    "rename_dict = {}\n",
    "for s in dfstat_short_nice[prefix_role]:\n",
    "    if prefix_role == 'prefix':\n",
    "        s2 = s[:-(len('subskip8')+1)]\n",
    "    else:\n",
    "        s2 = s[:-(len('subskip8')+3)]\n",
    "    rename_dict[s] = s2\n",
    "display(rename_dict)\n",
    "#dfstat_short_nice.rename(lambda x: x.replace(rename_dict[x] ) , axis='columns')\n",
    "dfstat_short_nice[prefix_role] = dfstat_short_nice[prefix_role].replace(rename_dict )\n",
    "#dfstat_short_nice\n",
    "\n",
    "# ########### rawnames rename\n",
    "# rename_dict = {}\n",
    "# for s in dfstat_short_nice[prefix_role]:\n",
    "#     if prefix_role == 'prefix':\n",
    "#         s2 = s[:-(len('subskip8')+1)]\n",
    "#     else:\n",
    "#         s2 = s[:-(len('subskip8')+3)]\n",
    "#     rename_dict[s] = s2\n",
    "# display(rename_dict)\n",
    "#dfstat_short_nice.rename(lambda x: x.replace(rename_dict[x] ) , axis='columns')\n",
    "\n",
    "assert( len( set(dfstat_short_nice['grouping'])  )  ) == 1\n",
    "print(list(dfstat_short_nice['grouping'] ) [0] )\n",
    "dfstat_short_nice = dfstat_short_nice.drop(['grouping'], axis=1)\n",
    "\n",
    "rename_dict = {'onlyH':'all Hjorth parameters' , 'onlyH_act':'Hjorth activity', \n",
    "               'onlyH_mob':'Hjorth mobility', 'onlyH_compl':'Hjorth complexity', 'onlyH_modLFP':'all Hjorth parameters of LFP'}\n",
    "dfstat_short_nice[prefix_role] = dfstat_short_nice[prefix_role].replace(rename_dict)\n",
    "\n",
    "dfstat_short_nice['rawname'] = dfstat_short_nice['rawname'].apply(lambda x: x.upper())\n",
    "\n",
    "# rename_dict = { 'merge_all_not_trem':'all non-tremor states', \n",
    "#             'merge_movements':'voluntary movements',\n",
    "#             'merge_nothing':'none'          }\n",
    "# dfstat_short_nice['grouping'].replace(rename_dict, inplace=True )\n",
    "\n",
    "rename_dict = { 'basic':'tremor,quiet,hold,grasp', \n",
    "            'trem_vs_quiet':'tremor,quiet'  }\n",
    "dfstat_short_nice['interval_set'] = dfstat_short_nice['interval_set'].replace(rename_dict )\n",
    "\n",
    "# if not show_only_act:\n",
    "#     dfstat_short_nice['num_mean'] = dfstat_short_nice['num_mean'].map(int)\n",
    "    \n",
    "pctf = lambda x: f'{x * 100:.0f}%' if isinstance(x,float) else x\n",
    "pctize = ['bacc','tremor_det_perf','bacc_add',\n",
    "          'tremor_det_perf_across']\n",
    "for coln in pctize:\n",
    "    dfstat_short_nice[coln] = dfstat_short_nice[coln].apply(pctf)\n",
    "# dfstat_short_nice['performance / feature number'] = \\\n",
    "#     dfmn.apply(lambda row: f'{row.bacc_mean / row.num_mean:.4f}', axis=1 )\n",
    "\n",
    "# rename column names\n",
    "rename_dict = {}\n",
    "rename_dict[prefix_role] = 'Feature set'\n",
    "#rename_dict['grouping'] = 'behav. states merged'\n",
    "rename_dict['interval_set'] = 'behav. states used'\n",
    "rename_dict['bacc'] = 'performance'\n",
    "rename_dict['bacc_add'] = 'performance across subj.'\n",
    "rename_dict['tremor_det_perf'] = 'tremor detection'\n",
    "rename_dict['tremor_det_perf_across'] = 'tremor detection across subj.'\n",
    "# if not show_only_act:\n",
    "#     rename_dict['num_mean'] = 'feature number'\n",
    "dfstat_short_nice = dfstat_short_nice.rename(columns=rename_dict)\n",
    "\n",
    "columns = np.array(list(dfstat_short_nice.columns) )[[0,1,2,5,6,3,4]]\n",
    "columns\n",
    "\n",
    "#dfstat_short_nice[columns]\n",
    "#dfstat_short_nice = dfstat_short_nice.reset_index()\n",
    "#dfstat_short_nice.style.set_properties(**{'text-align': 'left'})\n",
    "dfstat_short_nice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be053369",
   "metadata": {},
   "source": [
    "#### Hjorth activity optimality (within other Hjorth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f402e7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimality\n",
    "dfopt = dfmn[(dfmn['grouping']=='merge_nothing') & (dfmn['interval_set']=='basic')].copy()\n",
    "\n",
    "cols_desired = [prefix_role, 'tremor_det_perf_mean','tremor_det_perf_std',\n",
    "               'bacc_mean','bacc_std','num_mean']\n",
    "dfopt = dfopt[cols_desired]\n",
    "\n",
    "dfopt['bacc_over_num'] = dfopt.apply(lambda row: \\\n",
    "                        f'{row.bacc_mean / row.num_mean:.3f}', axis=1)\n",
    "dfopt.sort_values('bacc_over_num')\n",
    "\n",
    "pctf = lambda x: f'{x * 100:.0f}%'\n",
    "dfopt['num_mean'] = dfopt['num_mean'].map(int)\n",
    "dfopt['bacc_mean'] = dfopt['bacc_mean'].apply(pctf )\n",
    "dfopt['bacc_std'] = dfopt['bacc_std'].apply(pctf )\n",
    "dfopt['tremor_det_perf_mean'] = dfopt['tremor_det_perf_mean'].apply(pctf )\n",
    "dfopt['tremor_det_perf_std'] = dfopt['tremor_det_perf_std'].apply(pctf )\n",
    "\n",
    "###############\n",
    "for s in dfopt[prefix_role]:\n",
    "    if prefix_role == 'prefix':\n",
    "        s2 = s[:-(len('subskip8')+1)]\n",
    "    else:\n",
    "        s2 = s[:-(len('subskip8')+3)]\n",
    "    rename_dict[s] = s2\n",
    "display(rename_dict)\n",
    "#dfstat_short_nice.rename(lambda x: x.replace(rename_dict[x] ) , axis='columns')\n",
    "dfopt[prefix_role].replace(rename_dict, inplace=True )\n",
    "\n",
    "rename_dict = {'onlyH':'all Hjorth parameters' , 'onlyH_act':'Hjorth activity', \n",
    "               'onlyH_mob':'Hjorth mobility', 'onlyH_compl':'Hjorth complexity'}\n",
    "dfopt[prefix_role].replace(rename_dict, inplace=True )\n",
    "\n",
    "rename_dict = {}\n",
    "rename_dict[prefix_role] = 'Feature set'\n",
    "rename_dict['grouping'] = 'behav. states merged'\n",
    "rename_dict['interval_set'] = 'behav. states used'\n",
    "rename_dict['bacc_mean'] = 'performance mean'\n",
    "rename_dict['bacc_std'] = 'performance std'\n",
    "rename_dict['tremor_det_perf_mean'] = 'tremor detection mean'\n",
    "rename_dict['tremor_det_perf_std'] = 'tremor detection std'\n",
    "rename_dict['num_mean'] = 'feature number'        \n",
    "#\n",
    "rename_dict['bacc_over_num'] = 'mean pef. / num. features'        \n",
    "dfopt.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "dfopt.style.set_properties(**{'text-align': 'left'})\n",
    "\n",
    "#display( dfopt )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c325a9",
   "metadata": {},
   "source": [
    "#### Compare groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5020ef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_only_act = 1\n",
    "if show_only_act:\n",
    "    if prefix_role == 'prefix':\n",
    "        good = 'onlyH_act_subskip8'\n",
    "    else:\n",
    "        good = 'onlyH_act_subskip8%%'\n",
    "    dfstat_short_nice = dfstat_short[dfstat_short[prefix_role] == good].copy()\n",
    "    dfstat_short_nice = dfstat_short_nice.drop(['num_mean'], axis=1)\n",
    "else: # all Hjorth\n",
    "    dfstat_short_nice = dfstat_short.copy()\n",
    "\n",
    "rename_dict = {}\n",
    "for s in dfstat_short_nice[prefix_role]:\n",
    "    if prefix_role == 'prefix':\n",
    "        s2 = s[:-(len('subskip8')+1)]\n",
    "    else:\n",
    "        s2 = s[:-(len('subskip8')+3)]\n",
    "    rename_dict[s] = s2\n",
    "display(rename_dict)\n",
    "#dfstat_short_nice.rename(lambda x: x.replace(rename_dict[x] ) , axis='columns')\n",
    "dfstat_short_nice[prefix_role].replace(rename_dict, inplace=True )\n",
    "\n",
    "\n",
    "rename_dict = {'onlyH':'all Hjorth parameters' , 'onlyH_act':'Hjorth activity', \n",
    "               'onlyH_mob':'Hjorth mobility', 'onlyH_compl':'Hjorth complexity'}\n",
    "dfstat_short_nice[prefix_role].replace(rename_dict, inplace=True )\n",
    "\n",
    "rename_dict = { 'merge_all_not_trem':'all non-tremor states', \n",
    "            'merge_movements':'voluntary movements',\n",
    "            'merge_nothing':'none'          }\n",
    "dfstat_short_nice['grouping'].replace(rename_dict, inplace=True )\n",
    "\n",
    "rename_dict = { 'basic':'tremor,quiet,hold,grasp', \n",
    "            'trem_vs_quiet':'tremor,quiet'  }\n",
    "dfstat_short_nice['interval_set'].replace(rename_dict, inplace=True )\n",
    "\n",
    "pctf = lambda x: f'{x * 100:.0f}%'\n",
    "if not show_only_act:\n",
    "    dfstat_short_nice['num_mean'] = dfstat_short_nice['num_mean'].map(int)\n",
    "dfstat_short_nice['bacc_mean'] = dfstat_short_nice['bacc_mean'].apply(pctf )\n",
    "dfstat_short_nice['bacc_std'] = dfstat_short_nice['bacc_std'].apply(pctf )\n",
    "dfstat_short_nice['tremor_det_perf_mean'] = dfstat_short_nice['tremor_det_perf_mean'].apply(pctf )\n",
    "dfstat_short_nice['tremor_det_perf_std'] = dfstat_short_nice['tremor_det_perf_std'].apply(pctf )\n",
    "\n",
    "# dfstat_short_nice['performance / feature number'] = \\\n",
    "#     dfmn.apply(lambda row: f'{row.bacc_mean / row.num_mean:.4f}', axis=1 )\n",
    "\n",
    "# rename column names\n",
    "rename_dict = {}\n",
    "rename_dict[prefix_role] = 'Feature set'\n",
    "rename_dict['grouping'] = 'behav. states merged'\n",
    "rename_dict['interval_set'] = 'behav. states used'\n",
    "rename_dict['bacc_mean'] = 'performance mean'\n",
    "rename_dict['bacc_std'] = 'performance std'\n",
    "rename_dict['tremor_det_perf_mean'] = 'tremor detection mean'\n",
    "rename_dict['tremor_det_perf_std'] = 'tremor detection std'\n",
    "if not show_only_act:\n",
    "    rename_dict['num_mean'] = 'feature number'\n",
    "dfstat_short_nice.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "columns = np.array(list(dfstat_short_nice.columns) )[[0,1,2,5,6,3,4]]\n",
    "columns\n",
    "\n",
    "dfstat_short_nice[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd47ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "suff = '_subskip8'\n",
    "d['onlyH'] =  'Hjorth'\n",
    "for freq in ['tremor','beta','gamma']:\n",
    "    d[f'allb_{freq}'] = f'{freq} interactions and band power w/o Hjorth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc599bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfstat_short[dfstat_short['prefix'] == 'onlyH_act_subskip8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739d3731",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfstat_short_nice.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd30963",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dfstat_short_nice.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd955d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef1fea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "We have compared 11 different feature sets: all Hjorth parameters together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ece1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfstat_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9373f328",
   "metadata": {},
   "outputs": [],
   "source": [
    "% -- contra\n",
    "^ -- ipsi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e556d04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Save perftable\n",
    "ss = []\n",
    "for tpl in to_show:\n",
    "    ss += [','.join(tpl)]\n",
    "s = ':'.join(ss)\n",
    "print(s)\n",
    "\n",
    "fn_table = pjoin(gv.data_dir,subdir, f'perftable_{s}_{len(prefixes)}prefs.npz')\n",
    "print(fn_table)\n",
    "svd = dict(table_info_per_perf_type=table_info_per_perf_type, table_per_perf_type=table_per_perf_type)\n",
    "np.savez(fn_table, **svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf57836",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_to_use_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3807fb",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### plot table info (many bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5fd1be",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#perf_tuple = perf_to_use_list[0]\n",
    "#%debug\n",
    "#for perf_tuple in perf_to_use_list[:1]:\n",
    "for perf_tuple in perf_to_use_list:\n",
    "    print(perf_tuple)\n",
    "    postp.plotTableInfos2(table_info_per_perf_type, perf_tuple=perf_tuple, \n",
    "                          output_subdir=subdir,use_recalc_perf=False, \n",
    "                          prefixes_sorted=prefixes, crop_rawname=slice(None,None)) \n",
    "    plt.close()\n",
    "    import gc;gc.collect()\n",
    "    #break\n",
    "#postp.plotTableInfos2(table_info_per_perf_type, perf_kind='LDA', keys = None, output_subdir=''): \n",
    "\n",
    "## load labels (not important where from exactly)\n",
    "from utils import loadLabelsDict\n",
    "labels_dict = loadLabelsDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae392ec",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subdir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68db8099",
   "metadata": {},
   "source": [
    "# Perf only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172e8ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_tuple = perf_to_use_list[-1]\n",
    "defsp = 'special:min(sens,spec)'\n",
    "score = 'bacc'\n",
    "\n",
    "#TODO:  add part of plotCalcOutput\n",
    "    #plt.title(plt.title())\n",
    "scstr = ''\n",
    "if score != defsp:\n",
    "    scstr = score\n",
    "fn_full = pjoin(gv.dir_fig,subdir,\n",
    "                f'bars_perf_dif_subsets_{plotname_pref}_{scstr}.pdf')\n",
    "plt.savefig(fn_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b305c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5169896",
   "metadata": {},
   "source": [
    "### H_act only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c444c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_postprocess_HPC import plotOnePrefQuick\n",
    "pref_quick_plots = ['onlyH_act_subskip8BB']\n",
    "for pref in pref_quick_plots:\n",
    "    plotOnePrefQuick(rawnames, table_info_per_perf_type,perf_to_use_list[0], pref)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig( pjoin(gv.dir_fig, subdir,f'{pref}_summary.pdf') )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31aa26f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_postprocess_HPC import plotOnePrefQuick\n",
    "pref_quick_plots = ['onlyH_act_modLFP_subskip8%%', 'onlyH_act_modLFP_subskip8^^', \n",
    "                      'onlyH_modLFP_subskip8%%', 'onlyH_modLFP_subskip8^^', 'onlyH_subskip8%%', 'onlyH_subskip8^^', 'onlyH_subskip8BB']\n",
    "for pref in pref_quick_plots:\n",
    "    plotOnePrefQuick(rawnames, table_info_per_perf_type,perf_to_use_list[0], pref)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig( pjoin(gv.dir_fig, subdir,f'{pref}_summary.pdf') )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5605fb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.sort( np.unique( ords[1][ (ords[0]  == 'S07_on') & (ords[2]  == 'merge_nothing') ] ) )\n",
    "#[aa for aa in a if aa.startswith()]\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7367a85",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Confmats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6af85f7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'onlyH_subskip8' in prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77192476",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 'onlyH_subskip8',\n",
    "#  'onlyH_subskip8BB',\n",
    "#  'onlyH_subskip8BL',\n",
    "#  'onlyH_subskip8BR',\n",
    "#  'onlyH_subskip8LL',\n",
    "#  'onlyH_subskip8RR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2932c4a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fig 1 -- 'onlyH_act_subskip8%%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1428a6fa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#revdict_user = {'trem_L':0, 'notrem_L':1, 'hold_L':2, 'move_L':3}\n",
    "#%debug\n",
    "from utils_postprocess_HPC import filterOutputs\n",
    "pref_confmat_plots = ['onlyH_modLFP_subskip8%%', 'onlyH_subskip8%%', 'onlyH_subskip8^^', 'onlyH_subskip8BB',\n",
    "                      'onlyH_act_modLFP_subskip8%%', 'onlyH_act_modLFP_subskip8^^', \n",
    "                      'onlyH_modLFP_subskip8%%', 'onlyH_modLFP_subskip8^^', \n",
    "                      'onlyH_act_subskip8%%', 'onlyH_act_subskip8^^', 'onlyH_act_subskip8BB',\n",
    "                     'LFPrel_noself_subskip8','LFPrel_noself_subskip8%%']\n",
    "#                      'onlyH_subskip8%%', 'onlyH_subskip8^^', 'onlyH_subskip8BB']\n",
    "#pref_confmat_plot = 'modLFP'\n",
    "#pref_confmat_plot = 'onlyH_act_only15' # CB\n",
    "#pref_confmat_plot = 'onlyH_act_only14' # CB\n",
    "#pref_confmat_plot = 'onlyH_act_only0'  #Senosorimotor\n",
    "#pref_confmat_plot = 'onlyH_act_LFPand_only14' # CB\n",
    "#pref_confmat_plot = 'onlyH_act_LFPand_only0'  #Senosorimotor\n",
    "import pandas as pd\n",
    "from globvars import gp\n",
    "\n",
    "colnames_add = []\n",
    "for it_mvt in ['hold', 'move','trem']:\n",
    "    colnames_add += [it_mvt + '_perf_mean']\n",
    "    colnames_add += [it_mvt + '_perf_std']\n",
    "\n",
    "dfcm = pd.DataFrame(columns = ['prefix_templ', 'grouping','interval_set','confmats','confmats_offdiag',\n",
    "                              'confmats_diag'] + colnames_add)\n",
    "for pref_confmat_plot in pref_confmat_plots:\n",
    "    for grp,it in [('merge_nothing','basic')]: #, 'merge_movements']:\n",
    "        print(pref_confmat_plot)\n",
    "        #grps = ['merge_nothing'] #, 'merge_movements']\n",
    "        #grps = [ 'merge_movements']\n",
    "        outputs_filtered = postp.filterOutputs(output_per_raw,prefs=[pref_confmat_plot], \n",
    "                                               grps=[grp], its=[it])\n",
    "        plt.rcParams.update({'font.size': 15})\n",
    "        plt.rc('ytick',labelsize=22)\n",
    "        plt.rc('xtick',labelsize=22)\n",
    "        plt.rc('axes',labelsize=24)\n",
    "\n",
    "        colorbar_axes_bbox = [0.80, 0.2, 0.025, 0.7]\n",
    "        _,_,confmats_normalized,confmat_normalized_offdiags, confmat_normalized_diags_els = \\\n",
    "            postp.plotConfmats(outputs_filtered, ww = 5, hh =5, keep_beh_state_sides=0,\n",
    "                           keep_subj_list_title=1,\n",
    "                           labelpad_cbar=155, colorbar_axes_bbox= colorbar_axes_bbox,\n",
    "                          rename_class_names = {'notrem':'quiet'})\n",
    "        \n",
    "        d = {'confmats':confmats_normalized, 'confmats_offdiag':confmat_normalized_offdiags,\n",
    "            'confmats_diag': confmat_normalized_diags_els}\n",
    "        d['grouping'] = grp\n",
    "        d['interval_set'] = it\n",
    "        d['prefix_templ'] = pref_confmat_plot\n",
    "        #plt.gcf().axes[-1].set_visible(False)\n",
    "        figname = f'confmats_{pref_confmat_plot}_{grp},{it}.pdf'\n",
    "        figname_full = pjoin(gv.dir_fig,subdir,figname)\n",
    "        plt.savefig(figname_full)\n",
    "        print(figname_full)\n",
    "        plt.close()\n",
    "        \n",
    "        confmats_all = np.array( confmats_normalized )\n",
    "        #confmats_all.shape\n",
    "        cmm = confmats_all.mean(axis=0)\n",
    "        cmstd = confmats_all.std(axis=0)        \n",
    "        # diag el\n",
    "        for it_mvt in ['hold', 'move','trem']:\n",
    "            i = gp.int_types_basic.index(it_mvt)    \n",
    "            me = cmm[i,i]\n",
    "            std = cmstd[i,i]\n",
    "            d[it_mvt + '_perf_mean'] = me\n",
    "            d[it_mvt + '_perf_std'] = std\n",
    "        \n",
    "        # this is averaged over subjects/medcond \n",
    "        dfcm = dfcm.append(d,ignore_index = 1)\n",
    "dfcm.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74183d9a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfcm[['prefix_templ','grouping','interval_set','trem_perf_mean','trem_perf_std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2997d741",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "row = df.loc[0]\n",
    "row['interval_set']\n",
    "row['grouping']\n",
    "row['perf_dict_shuffled']['confmat']\n",
    "#getConfmat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4654957e",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Prpare funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636d56dc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def prefixTempl2Prefix(prefix_templ,rawname):\n",
    "    subj = rawname.split('_')[0]\n",
    "    mainmoveside = gv.gen_subj_info[subj].get('move_side',None)\n",
    "    assert mainmoveside is not None\n",
    "    movesidelet = mainmoveside[0].upper()\n",
    "    moveopsidelet = utils.getOppositeSideStr( movesidelet )\n",
    "    templ_eff = prefix_templ.    replace('%', moveopsidelet)\n",
    "    templ_eff = templ_eff.replace('^', movesidelet)\n",
    "    return templ_eff\n",
    "\n",
    "\n",
    "def getMcf(row):\n",
    "    if 'rawname' not in row:\n",
    "        rawnames_cur = rawnames\n",
    "    else:\n",
    "        rawname = row['rawname']\n",
    "        rawnames_cur = [rawname]\n",
    "    res = []\n",
    "    for rawname in rawnames_cur:\n",
    "        if 'prefix' in row:\n",
    "            prefix = row['prefix']\n",
    "        else:\n",
    "            prefix = prefixTempl2Prefix(row['prefix_templ'],rawname)\n",
    "        r = output_per_raw[rawname][prefix][row['grouping']][row['interval_set']]\n",
    "        res += [r]\n",
    "    return res\n",
    "        \n",
    "def getShuffledConfmatsStats(row):\n",
    "    r = getMcf(row)\n",
    "\n",
    "    cms = []\n",
    "    for mcf in r:\n",
    "        cm,lblord = getConfmat(mcf,row['grouping'],row['interval_set'],shuffled=1)\n",
    "        cms += [cm]\n",
    "    cms = np.array(cms)\n",
    "    cms_mn = cms.mean(axis=0)\n",
    "    cms_std = cms.std(axis=0)\n",
    "    return cms_mn,cms_std\n",
    "    \n",
    "row = dfcm_sub.reset_index().loc[0]\n",
    "cms_mn,cms_std = getShuffledConfmatsStats(row)\n",
    "\n",
    "\n",
    "def getCM(row, data_type, stat):\n",
    "    if data_type == 'normal':\n",
    "        confmats_normalized =  row['confmats']\n",
    "        confmats_all = np.array(confmats_normalized)\n",
    "        cms_mn = confmats_all.mean(axis=0)\n",
    "        cms_std = confmats_all.std(axis=0)\n",
    "    else:\n",
    "        cms_mn,cms_std = getShuffledConfmatsStats(row)\n",
    "            \n",
    "    if stat == 'mean':\n",
    "        cms = cms_mn\n",
    "    elif stat == 'std':\n",
    "        cms = cms_std\n",
    "    return cms\n",
    "\n",
    "def getStat(row, data_type, stat, it_mvt):\n",
    "    cms = getCM(row, data_type, stat)    \n",
    "    i = gp.int_types_basic.index(it_mvt) \n",
    "    return cms[i,i]\n",
    "    \n",
    "def getBest(row, data_type, best_type, stat=None):\n",
    "    cms = getCM(row, data_type, 'mean')\n",
    "    assert cms.ndim == 2\n",
    "    \n",
    "    eye = np.eye(cms.shape[0])\n",
    "    diag = np.diag(np.diag(cms))\n",
    "    cms_offdiag = cms - diag\n",
    "    cms_offdiag_largedval = cms_offdiag + eye * 1e5\n",
    "    \n",
    "    if best_type == 'best':\n",
    "        ip = np.unravel_index( np.argmin( np.mean( cms_offdiag_largedval, 0)  ), cmm.shape )    \n",
    "    elif best_type == 'worst':\n",
    "        ip = np.unravel_index( np.argmax( np.mean( confmat_normalized_offdiags, 0)  ), cmm.shape )\n",
    "    \n",
    "    if stat is None:\n",
    "        s = f'{gp.int_types_basic[ip[0]]} pred as {gp.int_types_basic[ip[1]]}'\n",
    "        return s\n",
    "    if stat == 'mean':\n",
    "        return cms[tuple(ip)]\n",
    "    elif stat == 'std':\n",
    "        cms_std = getCM(row, data_type, 'std')\n",
    "        return cms_std[tuple(ip)]\n",
    "    # f'(mean={cmm[tuple(ip)]:.0f}%, std={cmstd[tuple(ip)]:.0f}%)' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd21678a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### fill confusion matrix data for pub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02531d9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cms = []\n",
    "for mcf in r:\n",
    "    cm,lblord = getConfmat(mcf,row['grouping'],row['interval_set'],shuffled=1)\n",
    "    cms += [cm]\n",
    "cms = np.array(cms)\n",
    "cms_mn = cms.mean(axis=0)\n",
    "cms_std = cms.std(axis=0)\n",
    "cms_mn,cms_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f91031a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getCM(row, data_type, stat):\n",
    "    if data_type == 'normal':\n",
    "        confmats_normalized =  row['confmats']\n",
    "        confmats_all = np.array(confmats_normalized)\n",
    "        cms_mn = confmats_all.mean(axis=0)\n",
    "        cms_std = confmats_all.std(axis=0)\n",
    "    else:\n",
    "        cms_mn,cms_std = getShuffledConfmatsStats(row)\n",
    "            \n",
    "    if stat == 'mean':\n",
    "        cms = cms_mn\n",
    "    elif stat == 'std':\n",
    "        cms = cms_std\n",
    "    return cms\n",
    "\n",
    "def getStat(row, data_type, stat, it_mvt):\n",
    "    cms = getCM(row, data_type, stat)    \n",
    "    i = gp.int_types_basic.index(it_mvt) \n",
    "    return cms[i,i]\n",
    "    \n",
    "def getBest(row, data_type, best_type, stat=None):\n",
    "    cms = getCM(row, data_type, 'mean')\n",
    "    assert cms.ndim == 2\n",
    "    \n",
    "    eye = np.eye(cms.shape[0])\n",
    "    diag = np.diag(np.diag(cms))\n",
    "    cms_offdiag = cms - diag\n",
    "    cms_offdiag_largedval = cms_offdiag + eye * 1e5\n",
    "    \n",
    "    if best_type == 'best':\n",
    "        ip = np.unravel_index( np.argmin( np.mean( cms_offdiag_largedval, 0)  ), cmm.shape )    \n",
    "    elif best_type == 'worst':\n",
    "        ip = np.unravel_index( np.argmax( np.mean( confmat_normalized_offdiags, 0)  ), cmm.shape )\n",
    "    \n",
    "    if stat is None:\n",
    "        s = f'{gp.int_types_basic[ip[0]]} pred as {gp.int_types_basic[ip[1]]}'\n",
    "        return s\n",
    "    if stat == 'mean':\n",
    "        return cms[tuple(ip)]\n",
    "    elif stat == 'std':\n",
    "        cms_std = getCM(row, data_type, 'std')\n",
    "        return cms_std[tuple(ip)]\n",
    "    # f'(mean={cmm[tuple(ip)]:.0f}%, std={cmstd[tuple(ip)]:.0f}%)' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40dde95",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for data_type in ['normal','shuffled']:\n",
    "    for stat in ['mean','std']:\n",
    "        for it_mvt in ['hold', 'move','trem']:\n",
    "            fcur = lambda row : getStat(row, data_type, stat, it_mvt)\n",
    "            res = dfcm.apply(fcur, axis=1)\n",
    "            dfcm[f'detperf_{data_type}_{it_mvt}_{stat}'] = res                        \n",
    "            \n",
    "    if data_type != 'shuffled':            \n",
    "        for best_type in ['best', 'worst']:            \n",
    "            fcur = lambda row : getBest(row, data_type, best_type=best_type, stat=None)\n",
    "            res = dfcm.apply(fcur, axis=1)\n",
    "            dfcm[f'{best_type}_pair'] = res                        \n",
    "\n",
    "            for stat in ['mean','std']:\n",
    "                fcur = lambda row : getBest(row, data_type, best_type=best_type, stat=stat)\n",
    "                res = dfcm.apply(fcur, axis=1)\n",
    "                dfcm[f'{best_type}_pair_{stat}'] = res                                        \n",
    "            \n",
    "dfcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485fca3f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols = ['prefix_templ',\n",
    " 'detperf_normal_hold_mean',\n",
    " 'detperf_normal_move_mean',\n",
    " 'detperf_normal_trem_mean',\n",
    " 'detperf_normal_hold_std',\n",
    " 'detperf_normal_move_std',\n",
    " 'detperf_normal_trem_std',\n",
    " 'detperf_shuffled_hold_mean',\n",
    " 'detperf_shuffled_move_mean',\n",
    " 'detperf_shuffled_trem_mean',\n",
    " 'detperf_shuffled_hold_std',\n",
    " 'detperf_shuffled_move_std',\n",
    " 'detperf_shuffled_trem_std',\n",
    " 'best_pair',\n",
    " 'best_pair_mean',\n",
    " 'best_pair_std',\n",
    " 'worst_pair',\n",
    " 'worst_pair_mean',\n",
    " 'worst_pair_std']\n",
    "\n",
    "cols1 = ['prefix_templ',\n",
    " 'detperf_normal_hold_mean',\n",
    " 'detperf_normal_move_mean',\n",
    " 'detperf_normal_trem_mean',\n",
    " 'detperf_normal_hold_std',\n",
    " 'detperf_normal_move_std',\n",
    " 'detperf_normal_trem_std',\n",
    " 'detperf_shuffled_hold_mean',\n",
    " 'detperf_shuffled_move_mean',\n",
    " 'detperf_shuffled_trem_mean',\n",
    " 'detperf_shuffled_hold_std',\n",
    " 'detperf_shuffled_move_std',\n",
    " 'detperf_shuffled_trem_std']\n",
    "\n",
    "cols2 =  ['prefix_templ','best_pair',\n",
    " 'best_pair_mean',\n",
    " 'best_pair_std',\n",
    " 'worst_pair',\n",
    " 'worst_pair_mean',\n",
    " 'worst_pair_std']\n",
    "\n",
    "cols_nice = []\n",
    "for col in cols:\n",
    "    if col.find('detperf_normal') >= 0:\n",
    "        col_nice = col.replace('detperf_normal_','')\n",
    "    else:\n",
    "        col_nice = col\n",
    "    cols_nice += [col_nice]\n",
    "rename_dict = dict( zip(cols,cols_nice) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f47039d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list( dfcm_sub['hold_mean'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3706488",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "interval_names_pub = {'notrem':'quet','move':'grasp','trem':'tremor','hold':'hold'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbb8494",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show dataframes for best/worst stats AND print human readable\n",
    "for pref_templ_desired in ['onlyH_act_subskip8%%', 'onlyH_act_modLFP_subskip8%%']:\n",
    "    dfcm_sub = dfcm[dfcm['prefix_templ']==pref_templ_desired  ]\n",
    "    assert len(dfcm_sub) == 1\n",
    "    #dfcm_sub = dfcm_sub[cols]\n",
    "    dfcm_sub = dfcm_sub[cols2]\n",
    "    #dfcm_sub = dfcm_sub[cols1]\n",
    "    dfcm_sub = dfcm_sub.rename(rename_dict, axis='columns')\n",
    "    display(dfcm_sub)\n",
    "    \n",
    "    s = ''\n",
    "    \n",
    "    bp  = list( dfcm_sub[f'best_pair'] )[0]\n",
    "    me  = list( dfcm_sub[f'best_pair_mean'] )[0]\n",
    "    std = list( dfcm_sub[f'best_pair_std'] )[0]\n",
    "    \n",
    "    for it in interval_names_pub:\n",
    "        if bp.find(it) >= 0:\n",
    "            bp = bp.replace(it,f'\\'{interval_names_pub[it]}\\'' )\n",
    "    bp = bp.replace('pred as','predicted to be')\n",
    "    s += f'Least often detected confusion: {bp} ('\n",
    "    s += f'mean={me:.0f}%, std={std:.0f}%). '\n",
    "    \n",
    "    bp  = list( dfcm_sub[f'worst_pair'] )[0]\n",
    "    me  = list( dfcm_sub[f'worst_pair_mean'] )[0]\n",
    "    std = list( dfcm_sub[f'worst_pair_std'] )[0]\n",
    "    \n",
    "    for it in interval_names_pub:\n",
    "        if bp.find(it) >= 0:\n",
    "            bp = bp.replace(it,f'\\'{interval_names_pub[it]}\\'' )\n",
    "    \n",
    "    bp = bp.replace('pred as','predicted to be')\n",
    "    s += f'Most often detected confusion: {bp} ('\n",
    "    s += f'mean={me:.0f}%, std={std:.0f}%); '\n",
    "    \n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49774db",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show dataframes for main stats\n",
    "for pref_templ_desired in ['onlyH_act_subskip8%%', 'onlyH_act_modLFP_subskip8%%']:\n",
    "    dfcm_sub = dfcm[dfcm['prefix_templ']==pref_templ_desired  ]\n",
    "    assert len(dfcm_sub) == 1\n",
    "    #dfcm_sub = dfcm_sub[cols]\n",
    "    #dfcm_sub = dfcm_sub[cols2]\n",
    "    dfcm_sub = dfcm_sub[cols1]\n",
    "    dfcm_sub = dfcm_sub.rename(rename_dict, axis='columns')\n",
    "    display(dfcm_sub)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea98a90a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print human readable\n",
    "for pref_templ_desired in ['onlyH_act_subskip8%%', 'onlyH_act_modLFP_subskip8%%']:\n",
    "    dfcm_sub = dfcm[dfcm['prefix_templ']==pref_templ_desired  ]\n",
    "    assert len(dfcm_sub) == 1\n",
    "    #dfcm_sub = dfcm_sub[cols]\n",
    "    #dfcm_sub = dfcm_sub[cols2]\n",
    "    dfcm_sub = dfcm_sub[cols1]\n",
    "    #dfcm_sub = dfcm_sub.rename(rename_dict, axis='columns')\n",
    "    #display(dfcm_sub)\n",
    "    \n",
    "    row = dfcm_sub.reset_index().loc(0)    \n",
    "    #for data_type in ['normal', 'shuffled']:\n",
    "    print(f'  {data_type}')\n",
    "    for it_mvt in ['trem', 'hold', 'move']:\n",
    "        s = ''\n",
    "        #i = gp.int_types_basic.index(it_mvt)    \n",
    "        #me = cmm[i,i]\n",
    "        #std = cmstd[i,i]\n",
    "        data_type = 'normal'\n",
    "        me  = list( dfcm_sub[f'detperf_{data_type}_{it_mvt}_mean'] )[0]\n",
    "        std = list( dfcm_sub[f'detperf_{data_type}_{it_mvt}_std'] )[0]\n",
    "        \n",
    "        data_type = 'shuffled'\n",
    "        me_s  = list( dfcm_sub[f'detperf_{data_type}_{it_mvt}_mean'] )[0]\n",
    "        std_s = list( dfcm_sub[f'detperf_{data_type}_{it_mvt}_std'] )[0]\n",
    "        s += (f'for \\'{interval_names_pub[it_mvt]}\\' movement the '\n",
    "            'statistic of correct detection is ')\n",
    "        s += f'mean={me:.0f}, std={std:.0f}; '\n",
    "        s += ' (for shuffled data '\n",
    "        s += f'mean={me_s:.0f}, std={std_s:.0f}); '\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e37754",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfcm_sub.rename(rename_dict, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f6661a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfcm[dfcm['prefix_templ']==pref_templ_desired  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cfdbef",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# to put in Discussion\n",
    "For all Hjorth parameters together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48777e85",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Worst and best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eddb7a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(dfcm[dfcm['prefix_templ']==pref_templ_desired  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320ff73e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for pref_templ_desired in ['onlyH_act_subskip8%%', 'onlyH_act_modLFP_subskip8%%']:\n",
    "    print('   ' ,pref_templ_desired)\n",
    "    dfcm_sub = dfcm[dfcm['prefix_templ']==pref_templ_desired  ]\n",
    "    assert len(dfcm_sub) == 1\n",
    "    confmats_normalized =  dfcm_sub['confmats']\n",
    "    confmats_normalized = list(confmats_normalized)[0]\n",
    "    assert len(confmats_normalized) == 11\n",
    "    \n",
    "    row = dfcm_sub.reset_index().loc[0]\n",
    "    cms_mn,cms_std = getShuffledConfmatsStats(row)\n",
    "\n",
    "    from globvars import gp\n",
    "    confmats_all = np.array( confmats_normalized )\n",
    "    #confmats_all.shape\n",
    "    cmm = confmats_all.mean(axis=0)\n",
    "    cmstd = confmats_all.std(axis=0)\n",
    "\n",
    "    eyes = np.array( [np.eye(confmats_all.shape[-1] ) for cm in confmats_normalized], dtype=bool)\n",
    "    confmat_normalized_offdiags_largedval = confmat_normalized_offdiags + eyes * 1e5\n",
    "\n",
    "    ip = np.unravel_index( np.argmax( np.mean( confmat_normalized_offdiags, 0)  ), cmm.shape )\n",
    "    print(f'Most often wrong attribution -- {gp.int_types_basic[ip[0]]} is predicted to be {gp.int_types_basic[ip[1]]}, '\n",
    "    f'(mean={cmm[tuple(ip)]:.0f}%, std={cmstd[tuple(ip)]:.0f}%)')\n",
    "\n",
    "    ip = np.unravel_index( np.argmin( np.mean( confmat_normalized_offdiags_largedval, 0)  ), cmm.shape )\n",
    "    print(f'Least often wrong attibution -- {gp.int_types_basic[ip[0]]} is predicted to be {gp.int_types_basic[ip[1]]}, '\n",
    "     f'(mean={cmm[tuple(ip)]:.0f}%, std={cmstd[tuple(ip)]:.0f}%)' )\n",
    "\n",
    "    s = ''\n",
    "    for it_mvt in ['hold', 'move','trem']:\n",
    "        i = gp.int_types_basic.index(it_mvt)    \n",
    "        me = cmm[i,i]\n",
    "        std = cmstd[i,i]\n",
    "        s += f'for \\'{it_mvt}\\' movement the statistic of correct detection is '\n",
    "        s += f'mean={me:.0f}, std={std:.0f}; \\n'\n",
    "        \n",
    "    \n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b2ecd3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#prefixes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b84363",
   "metadata": {},
   "source": [
    "# onlyBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24c18f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_info_per_perf_type, table_per_perf_type = \\\n",
    "    postp.prepTableInfo3(output_per_raw, prefixes=prefixes, \n",
    "    perf_to_use_list=perf_to_use_list, to_show=to_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e073c00",
   "metadata": {},
   "source": [
    "## prepare plotspecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbe1bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotspecs = {}  # plot name 2 stuff\n",
    "prefix2final_name = {'onlyH_act_modLFP_subskip8%%':'LFP contralat',\n",
    "                     'onlyH_act_modLFP_subskip8^^':'LFP ipsilat',\n",
    "                     'onlyH_act_modLFP_subskip8BB':'LFP bilat',\n",
    "                     'onlyH_act_only_best_among_single-sided': 'best area SS',\n",
    "                     'onlyH_act_LFPand_quasibest_among_single-sided': '*LFP + best area SS',\n",
    "                     'onlyH_act_LFPand_best_among_single-sided': 'LFP + best area SS',\n",
    "                     'onlyH_act_only_best_among_clmove': 'best area CLM',\n",
    "                     'onlyH_act_LFPand_quasibest_among_clmove': '*LFP + best area CLM',\n",
    "                     'onlyH_act_LFPand_best_among_clmove': 'LFP + best area CLM',\n",
    "                     'onlyH_act_only_best_among_two-sided': 'best area TS',\n",
    "                     'onlyH_act_LFPand_quasibest_among_two-sided': '*LFP + best area TS',\n",
    "                     'onlyH_act_LFPand_best_among_two-sided': 'LFP + best area TS',\n",
    "                     good_prefs_permod['msrc'][0]:'cortex',\n",
    "                    'onlyH_act_subskip8%%':'LFP+cortex contralat',\n",
    "                     'onlyH_act_subskip8^^':'LFP+cortex ipsilat',\n",
    "                     'onlyH_act_subskip8BB':'LFP+cortex bilat'}\n",
    "plotspecs['all'] = prefix2final_name, 4,8  # numbers are width and height\n",
    "prefix2final_name = {'onlyH_act_modLFP_subskip8%%':'LFP contralat',\n",
    "                     'onlyH_act_modLFP_subskip8^^':'LFP ipsilat',\n",
    "                     'onlyH_act_modLFP_subskip8BB':'LFP bilat'}\n",
    "plotspecs['onlyBestLFP'] = prefix2final_name, 1.8,5\n",
    "prefix2final_name = { 'onlyH_act_only_best_among_two-sided': 'best area TS',\n",
    "                     'onlyH_act_LFPand_quasibest_among_two-sided': '*LFP + best area TS',\n",
    "                     'onlyH_act_LFPand_best_among_two-sided': 'LFP + best area TS' }\n",
    "plotspecs['two-sided'] = prefix2final_name, 1.8,5\n",
    "prefix2final_name = { 'onlyH_act_only_best_among_single-sided': 'best area SS',\n",
    "                     'onlyH_act_LFPand_quasibest_among_single-sided': '*LFP + best area SS',\n",
    "                     'onlyH_act_LFPand_best_among_single-sided': 'LFP + best area SS' }\n",
    "plotspecs['single-sided'] = prefix2final_name, 1.8,5\n",
    "prefix2final_name = {'onlyH_act_only_best_among_clmove': 'best area CLM',\n",
    "                     'onlyH_act_LFPand_quasibest_among_clmove': '*LFP + best area CLM',\n",
    "                     'onlyH_act_LFPand_best_among_clmove': 'LFP + best area CLM' }\n",
    "plotspecs['contralat'] = prefix2final_name, 1.8,5\n",
    "prefix2final_name = {'onlyH_act_only_best_among_clmove': 'best area CLM',\n",
    "                     'onlyH_act_LFPand_best_among_clmove': 'LFP + best area CLM',\n",
    "                     'onlyH_act_only_best_among_ilmove': 'best area ILM',\n",
    "                     'onlyH_act_LFPand_best_among_ilmove': 'LFP + best area ILM' }\n",
    "plotspecs['contr_vs_ipsi'] = prefix2final_name, 1.8,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19130503",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array( list(confmats_normalized)[0] ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191dc346",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotspecs = {}  \n",
    "prefix2final_name = {'onlyH_act_modLFP_subskip8%%':'LFP',\n",
    "                     'onlyH_act_only_best_among_clmove': 'best area',\n",
    "                     'onlyH_act_LFPand_best_among_clmove': 'LFP+best area',\n",
    "                     'onlyH_act_LFPand_best_among_two-sided': 'LFP+best area (two-sided)',                     \n",
    "                     'onlyH_act_subskip8%%':'LFP+cortex',\n",
    "                     'onlyH_act_subskip8BB':'LFP+cortex (two-sided)'}\n",
    "plotspecs['contra_various'] = prefix2final_name, 2.8,6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e006109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig 3\n",
    "plotspecs = {}  \n",
    "prefix2final_name = {'onlyH_act_modLFP_subskip8%%':'LFP',  \n",
    "                     'onlyH_act_only_best_among_two-sided': 'best area (two-sided)',                                         \n",
    "                     'onlyH_act_LFPand_best_among_two-sided': 'LFP+best area (two-sided)',\n",
    "                     'onlyH_act_subskip8BB':'LFP+cortex (two-sided)'}\n",
    "#'onlyH_act_LFPand_best_among_two-sided': 'LFP+best area (two-sided)',\n",
    "#'onlyH_act_LFPand_quasibest_among_two-sided': '*LFP + best area (two-sided)',\n",
    "plotspecs['contra_various_TSonly_wandwoLFP'] = prefix2final_name, 2.2,6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b57fe61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b878220",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(confmats_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c3ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig 3 (not in manuscript) with worse as well\n",
    "plotspecs = {}  \n",
    "prefix2final_name = {'onlyH_act_modLFP_subskip8%%':'LFP',  \n",
    "                     'onlyH_act_only_best_among_two-sided': 'best area (two-sided)',                                         \n",
    "                     'onlyH_act_LFPand_best_among_two-sided': 'LFP+best area (two-sided)',\n",
    "                     'onlyH_act_only_worst_among_two-sided': 'worst area (two-sided)',                                         \n",
    "                     'onlyH_act_LFPand_worst_among_two-sided': 'LFP+worst area (two-sided)',\n",
    "                     'onlyH_act_subskip8BB':'LFP+cortex (two-sided)'}\n",
    "#'onlyH_act_LFPand_best_among_two-sided': 'LFP+best area (two-sided)',\n",
    "#'onlyH_act_LFPand_quasibest_among_two-sided': '*LFP + best area (two-sided)',\n",
    "plotspecs['contra_various_TSonly_wandwoLFP_inc_worst'] = prefix2final_name, 2.2,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cd75af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotspecs = {}  \n",
    "prefix2final_name = {'onlyH_act_modLFP_subskip8%%':'LFP',  \n",
    "                     'onlyH_act_only_best_among_two-sided': 'best area (two-sided)',                                          \n",
    "                     'onlyH_act_subskip8BB':'LFP+cortex (two-sided)'}\n",
    "#'onlyH_act_LFPand_best_among_two-sided': 'LFP+best area (two-sided)',\n",
    "plotspecs['contra_various_TSonly'] = prefix2final_name, 2.2,6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fdb13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotspecs = {}  # plot name 2 stuff\n",
    "prefix2final_name = { 'onlyH_act_subskip8%%':'Hjorth act contralat',\n",
    "                     'onlyH_act_subskip8^^':'Hjorth act ipsilat',\n",
    "                     'onlyH_act_subskip8BB':'Hjorth act bilat',\n",
    "                     'onlyH_subskip8%%':'Hjorth act,mob,compl contralat',\n",
    "                     'onlyH_subskip8^^':'Hjorth act,mob,compl ipsilat',\n",
    "                     'onlyH_subskip8BB':'Hjorth act,mob,compl bilat'}\n",
    "plotspecs['act_vs_all'] = prefix2final_name, 2.1,6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f66fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotspecs = {}  # plot name 2 stuff\n",
    "prefix2final_name = { 'onlyH_act_only_best_among_two-sided': 'best area TS',\n",
    "                     'onlyH_act_LFPand_quasibest_among_two-sided': '*LFP + best area TS',\n",
    "                     'onlyH_act_LFPand_best_among_two-sided': 'LFP + best area TS' }\n",
    "plotspecs['two-sided'] = prefix2final_name, 1.8,5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01136356",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix2final_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03834ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_tuple[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bd0767",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotspecs, len(table_info_per_perf_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b10bbbe",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## run plot gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f663fc13",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from utils_postprocess_HPC import addBestParcelGroups\n",
    "#plotname_pref = 'noLFP'\n",
    "plotname_pref = ''\n",
    "add_pg  = False\n",
    "\n",
    "#%debug\n",
    "\n",
    "for plotspec_name,(prefix2final_name,hh,ww) in plotspecs.items():\n",
    "    score = 'bacc'\n",
    "    prefixes_final = list( prefix2final_name.keys() )\n",
    "    for perf_tuple in table_info_per_perf_type:\n",
    "        print(f'Starting plotTableInfos_onlyBar for {perf_tuple}')\n",
    "        if add_pg:\n",
    "            addBestParcelGroups(output_per_raw, table_info_per_perf_type, perf_tuple, score , do_add=1, \n",
    "                            remove_redundant_quasibest = False)\n",
    "\n",
    "        plt.rc('axes', titlesize=18)\n",
    "        plt.rc('axes', labelsize=20)\n",
    "        plt.rc('ytick', labelsize=16)\n",
    "        plt.rc('xtick', labelsize=16)\n",
    "        \n",
    "        k = list( table_info_per_perf_type.keys() )[0]\n",
    "        axs, df = postp.plotTableInfos_onlyBar(table_info_per_perf_type,\n",
    "                                           perf_tuple=perf_tuple,\n",
    "                              output_subdir=subdir,use_recalc_perf=False,\n",
    "                              prefixes_sorted=prefixes_final, prefix2final_name=prefix2final_name,\n",
    "                                     crop_rawname='no',\n",
    "                                           score= score,\n",
    "                                           rawnames=rawnames, per_medcond =1,\n",
    "                                          expand_best = 1, red='shuffled',\n",
    "                                           allow_missing_prefixes = 1, hh =hh ,ww =ww)\n",
    "        #axs[0,0].set_xlabel('')\n",
    "        axs[2,1].set_visible(False)\n",
    "        #frame1.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "    defsp = 'special:min(sens,spec)'\n",
    "    if score != defsp:\n",
    "        scstr = score\n",
    "    fn_full = pjoin(gv.dir_fig,subdir, f'bars_perf_{plotspec_name}_{plotname_pref}_{scstr}.pdf')\n",
    "    plt.subplots_adjust(hspace=0.2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fn_full)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4718511",
   "metadata": {},
   "source": [
    "## Print collected stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b24b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list ( df['barname_pre_human'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceca7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "barnames = set( df['barname_pre_human'] ) # indep of subject names\n",
    "print(barnames)\n",
    "r = {}\n",
    "rstd = {}\n",
    "s = f'Performance statistics are: '\n",
    "s_shuffled = f'Performance statistics for shuffled data are: '\n",
    "for bn in barnames:\n",
    "    dfsub = df[ df['barname_pre_human'] == bn ]\n",
    "    me  = dfsub['p'].mean()\n",
    "    std = dfsub['p'].std()\n",
    "    r[bn] = me\n",
    "    rstd[bn] = std\n",
    "    s += f'{bn}: mean={me:.2f}%, std={std:.2f}%; '\n",
    "    \n",
    "    me  = dfsub['p_red'].mean()\n",
    "    std = dfsub['p_red'].std()\n",
    "    s_shuffled += f'{bn}: mean={me:.2f}%, std={std:.2f}%; '\n",
    "r\n",
    "s = s[:-2] + '.'\n",
    "print(s)\n",
    "print(s_shuffled)\n",
    "display(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda111e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'shows that best STN LFP channel alone gives poor performance: '\n",
    "bn = 'LFP'; me = r[bn]; std = rstd[bn]\n",
    "s += f'mean={me:.2f}%, std={std:.2f}%. ' \n",
    "##\n",
    "s += 'Best сortical areas show higher performance than the best LFP channel: '\n",
    "bn = 'best area (two-sided)'; me = r[bn]; std = rstd[bn]\n",
    "s += f'mean={me:.2f}%, std={std:.2f}%. ' \n",
    "\n",
    "s += 'Adding LFP features improves performance a bit further: '\n",
    "bn = 'LFP+best area (two-sided)'; me = r[bn]; std = rstd[bn]\n",
    "s += f'mean={me:.2f}%, std={std:.2f}%. ' \n",
    "\n",
    "s += 'Using an entire entire cortex gives even better performance :'\n",
    "bn = 'LFP+cortex (two-sided)'; me = r[bn]; std = rstd[bn]\n",
    "s += f'mean={me:.2f}%, std={std:.2f}%. ' \n",
    "\n",
    "s += ('All feature subsets for every subject show performance '\n",
    "'better than performance of the classifier trained on shuffled labels. ')\n",
    "s += s_shuffled\n",
    "\n",
    "s = s[:-2] + '.'\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864693ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'Worst area performance had '\n",
    "bn = 'worst area (two-sided)'; me = r[bn]; std = rstd[bn]\n",
    "s += f'mean={me:.2f}%, std={std:.2f}%. '\n",
    "\n",
    "s += 'Adding LFP to it gave us performance with '\n",
    "bn = 'LFP+worst area (two-sided)'; me = r[bn]; std = rstd[bn]\n",
    "s += f'mean={me:.2f}%, std={std:.2f}%. '\n",
    "\n",
    "s = s[:-2] + '.'\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e08b406",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Only one area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7943b9f4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e60a698",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "corresp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044cca1f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#tpl[-1]['cmd']\n",
    " #[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acfc390",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cc4c36d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Filtering to leave one-sided and not-pgn-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0557836",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tpll_new = []\n",
    "basepref1 = 'onlyH_act_only'\n",
    "basepref2 = 'onlyH_act_LFPand_only'\n",
    "for tpl in tpll:\n",
    "    prefix = tpl[1]\n",
    "    g = 0\n",
    "    d = dict( tpl[-1]['cmd'][0] )\n",
    "    pgn = d.get('--parcel_group_names' ,None)\n",
    "    if prefix.startswith(basepref1) or prefix.startswith(basepref2):        \n",
    "        assert pgn is not None\n",
    "        if pgn.endswith('_L') or pgn.endswith('_R'):\n",
    "            tpll_new += [tpl]\n",
    "            g = 1\n",
    "    else:\n",
    "        tpll_new += [tpl]\n",
    "        g = 2\n",
    "    #tpl[1]['cmd']\n",
    "#     corresp,all_info = loadRunCorresp(tpl[-1])\n",
    "#     ind,pgn2,nice_name = corresp.get(prefix, (None,None,None) )\n",
    "#     if pgn2 is not None:\n",
    "#         if pgn.endswith('_L') and pgn.endswith('_R'):\n",
    "#             tpll_new += [tpl]\n",
    "#         else:            \n",
    "#             if pgn2 is not None:\n",
    "#                 continue\n",
    "    if g:\n",
    "        print(g,prefix,pgn\n",
    "    \n",
    "#outputs_filtered0 = tupleList2multiLevelDict(tpll_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f91214",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2158cbe4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#tpll[0][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d97dd88",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mco = tpll[0][-1]\n",
    "from utils_postprocess_HPC import computeImprovementsPerParcelGroup2,plotTableInfoBrain\n",
    "from utils_postprocess_HPC import filterOutputs, tupleList2multiLevelDict\n",
    "#%debug\n",
    "prefs =  [pref for pref in prefixes if pref.startswith('onlyH_act_only') ]\n",
    "prefs += [pref for pref in prefixes if pref.startswith('onlyH_act_subskip8BB') ]\n",
    "prefs += [pref for pref in prefixes if pref.startswith('onlyH_act_modLFP_subskip8') ]\n",
    "#prefs += [pref for pref in prefixes if pref.startswith('onlyH_act_exclude') ]\n",
    "#prefs += ['onlyH_act']\n",
    "base_perf_prefix = 'onlyH_act_subskip8BB'\n",
    "#base_perf_low_prefix = 'onlyH_act_modLFP_subskip8%%'\n",
    "base_perf_low_prefix = None\n",
    "\n",
    "#outputs_filtered0 = tupleList2multiLevelDict(tpll_new)\n",
    "outputs_filtered = postp.filterOutputs(outputs_filtered0, rns=rawnames , prefs=prefs, grps = ['merge_nothing'] )\n",
    "checkTupleListTableCompleteness(outputs_filtered)\n",
    "#make_plots = False\n",
    "make_plots = False\n",
    "prefs_after_filter = {}\n",
    "impr_per_rn = {}\n",
    "infos = []\n",
    "for rn in rawnames:\n",
    "#for rn in ['S01_on', 'S02_on']:\n",
    "    outputs_filtered = postp.filterOutputs(outputs_filtered0, rns=[rn] , prefs=prefs, grps = ['merge_nothing'] )\n",
    "    checkTupleListTableCompleteness(outputs_filtered)\n",
    "    medcond = rn.split('_')[1]\n",
    "    prefs_after_filter[rn] = list(outputs_filtered[rn].keys())\n",
    "#    for mode in ['only','exclude']:\n",
    "    for mode in ['only']:\n",
    "        print(f'-------  Starting {rn} {medcond}  {mode}')\n",
    "        impr_wrt_base_per_medcond_per_pgn=computeImprovementsPerParcelGroup2(outputs_filtered, \n",
    "                 base_perf_prefix = base_perf_prefix, base_perf_low_prefix = base_perf_low_prefix,\n",
    "                 mode = mode, inv_exclude = True,\n",
    "                 score = 'balanced_accuracy',\n",
    "                 ignore_base_prefix_missing=1)\n",
    "#         impr_wrt_base_per_medcond_per_pgn, impr_per_medcond_per_pgn,\\\n",
    "#         impr_wrtLFP_per_medcond_per_pgn, perfs_aver_per_medcond =\\\n",
    "#             computeImprovementsPerParcelGroup(outputs_filtered, \n",
    "#                  'onlyH_act', mode = mode, inv_exclude = True,\n",
    "#                  score = 'balanced_accuracy',\n",
    "#                  ignore_base_prefix_missing=1)\n",
    "#         impr_per_rn[rn] = impr_wrt_base_per_medcond_per_pgn, impr_per_medcond_per_pgn,\\\n",
    "#             impr_wrtLFP_per_medcond_per_pgn, perfs_aver_per_medcond\n",
    "        impr_per_rn[rn] = impr_wrt_base_per_medcond_per_pgn\n",
    "    #        return impr_wrt_base_per_medcond_per_pgn, impr_per_medcond_per_pgn, impr_wrtLFP_per_medcond_per_pgn, perfs_aver_per_medcond\n",
    "        #break\n",
    "        for medcond in impr_wrt_base_per_medcond_per_pgn.keys():\n",
    "            if len(impr_wrt_base_per_medcond_per_pgn[medcond] ) <= 4:\n",
    "                print(f'WARNING: {rn} {medcond} has zero len impr_wrt_base_per_medcond_per_pgn[{medcond}]')\n",
    "                continue            \n",
    "            axs,crlb, info = plotTableInfoBrain(impr_wrt_base_per_medcond_per_pgn , medcond, mco, \n",
    "                   head_subj_ind=None, mode=mode, subdir=subdir,\n",
    "                    savefile_prefix=f'EXPORT_brain_map_area_strength_{rn}_',\n",
    "                                               save_only = not make_plots)\n",
    "            infos += [(mode,medcond,info)]\n",
    "            if make_plots:\n",
    "                plt.close()\n",
    "            #break\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a31571",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#impr_wrt_base_per_medcond_per_pgn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dad9fcc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "set(prefs_after_filter['S01_on'] ) ^ set( prefs_after_filter['S02_on'] )\n",
    "\n",
    "rn1 = 'S01_on'\n",
    "outputs_filtered1 = postp.filterOutputs(output_per_raw, rns=[rn1] , prefs=prefs, grps = ['merge_nothing'] )\n",
    "l1 = list(outputs_filtered1[rn1].keys())\n",
    "rn2 = 'S02_on'\n",
    "outputs_filtered2 = postp.filterOutputs(output_per_raw, rns=[rn2] , prefs=prefs, grps = ['merge_nothing'] )\n",
    "l2 = list(outputs_filtered2[rn2].keys())\n",
    "set(l1) ^ set(l2)\n",
    "\n",
    "'2 ' *2\n",
    "\n",
    "list(sorted( output_per_raw['S02_on'].keys() ) )\n",
    "\n",
    "outputs_filtered2['S02_on']['onlyH_act_only15'].keys()\n",
    "\n",
    "oo=0\n",
    "tpll2 = pp.multiLevelDict2TupleList(outputs_filtered2,4,3)\n",
    "tpll_reshaped2 = list( zip(*tpll2) )\n",
    "oo=0\n",
    "tpll1 = pp.multiLevelDict2TupleList(outputs_filtered1,4,3)\n",
    "tpll_reshaped1 = list( zip(*tpll1) )\n",
    "\n",
    "len( outputs_filtered2[rn2] ), len( outputs_filtered1[rn1] )\n",
    "\n",
    "len( tpll_reshaped2[1] ), len( tpll_reshaped1[1] )\n",
    "\n",
    "list ( zip(l1,l2) )\n",
    "\n",
    "prefs_after_filter['S02_on']\n",
    "\n",
    "list( outputs_filtered['S02_on'].keys() )\n",
    "\n",
    "m = (tpll_reshaped[0] == 'S02_on') & (tpll_reshaped[2] == 'merge_nothing')\n",
    "list ( tpll_reshaped[1][m] ) , list( tpll_reshaped[3][m] )\n",
    "\n",
    "rn = 'S07_on'\n",
    "aa = impr_per_rn[rn][rn.split('_')[-1]]\n",
    "\n",
    "impr_per_rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0855c64a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "order = ['LFP', 'Sensorimotor', 'Cerebellum',\n",
    "    'FrontalMed',\n",
    " 'TemporalMid',\n",
    " 'SupraMarginal',\n",
    " 'OccipitalInf',\n",
    " 'Angular',\n",
    " 'FrontalInf',\n",
    " 'ParietalSup',\n",
    " 'TemporalSup',\n",
    " 'FrontalSup',\n",
    " 'TemporalInf',\n",
    " 'OccipitalSup',\n",
    " 'OccipitalMid',\n",
    " 'ParietalInf']\n",
    "keyorder = lambda tpl: order.index( tpl[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87466659",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Make hor barplots one per subj, one bar per area, each medcond dif color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceedf59",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subjs = list(sorted(set( [rn.split('_')[0] for rn in rawnames] ) ))\n",
    "#dict_keys(['sens_recalc', 'spec_recalc', 'descr', 'comment_from_runstrings', 'sens', 'spec', \n",
    "# 'F1', 'acc', 'bacc', 'sens_red', 'spec_red', 'sens_red_recalc', 'spec_red_recalc', 'F1_red', 'num', 'num_red'])\n",
    "aa = table_info_per_perf_type[perf_to_use_list[0]]\n",
    "tpls = sorted( list(aa.keys() ), key=lambda x: x[0] )\n",
    "\n",
    "nr = len(subjs)\n",
    "nc = 1\n",
    "ww = 5; hh = 6\n",
    "fig,axs = plt.subplots(nr,nc,figsize=( nc*ww, nr*hh), sharex='col')\n",
    "plt.subplots_adjust(top=0.97,bottom=0.02,left=0.25,right=0.99,hspace=0.1)\n",
    "\n",
    "color_per_medcond = dict(ON='blue',OFF='red')\n",
    "\n",
    "for rn,imprs in impr_per_rn.items():\n",
    "    #rn,grp,it = tpl\n",
    "    subj,medcond = rn.split('_')\n",
    "    axi = subjs.index(subj)\n",
    "    impr_cur = imprs[medcond]\n",
    "    \n",
    "    medcond = medcond.upper()\n",
    "    srt = sorted(impr_cur.items(), key=keyorder)\n",
    "    srt = list(srt)[::-1]\n",
    "    ks,vs=  zip(*srt)\n",
    "    \n",
    "    ax = axs[axi]\n",
    "    ax.barh(ks,vs, color=color_per_medcond[medcond], alpha=0.7 )\n",
    "    \n",
    "    print(rn,axi)\n",
    "    print(rn,srt)\n",
    "    \n",
    "    #rpint(aa[tpl].keys() )\n",
    "    #print( aa[tpl]['onlyH_act'].keys() )\n",
    "    \n",
    "    #val = aa[tpl]['onlyH_act']['bacc']\n",
    "    #print(rn, axi, val )\n",
    "    \n",
    "    #ax.barh([medcond ],[val] )\n",
    "    ax.set_xlim(0,100)\n",
    "    ax.set_title(subj)\n",
    "    ax.set_xlabel('balanced acc')\n",
    "    #break\n",
    "#.keys()\n",
    "#plt.tight_layout()\n",
    "plt.suptitle('Perf per brain area (red=OFF, blue=ON)', y=0.99)\n",
    "plt.savefig( pjoin(gv.dir_fig, subdir,'H_act_perf_summary_per_area.pdf') )\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab67df1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#impr_wrt_base_per_medcond_per_pgn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e550af",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "axs,crlb, info = plotTableInfoBrain(impr_wrt_base_per_medcond_per_pgn , medcond, mco, \n",
    "                               head_subj_ind=None, mode=mode, subdir=subdir,\n",
    "                                               savefile_prefix=f'EXPORT_brain_map_area_strength_{rn}_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b34feb9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "impr_wrt_base_per_medcond_per_pgn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7313f6b4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Improvement compared to LFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3245a3c8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6b6d97",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mco = tpll[0][-1]\n",
    "from utils_postprocess_HPC import computeImprovementsPerParcelGroup2,computeImprovementsPerParcelGroup,plotTableInfoBrain\n",
    "\n",
    "base_perf_prefix = 'onlyH_act_subskip8BB'\n",
    "base_perf_low_prefix = 'onlyH_act_modLFP_subskip8%%'\n",
    "\n",
    "\n",
    "pref_LFPand = [pref for pref in prefixes if pref.startswith('onlyH_act_LFPand_') ]\n",
    "pref_LFPand += [base_perf_prefix, base_perf_low_prefix]\n",
    "\n",
    "#outputs_filtered0 = tupleList2multiLevelDict(tpll_new)\n",
    "make_plots = False\n",
    "\n",
    "#%debug\n",
    "ress = []\n",
    "for rn in rawnames:\n",
    "    outputs_filtered = postp.filterOutputs(outputs_filtered0, rns=[rn], prefs=pref_LFPand, grps = ['merge_nothing'])\n",
    "    medcond = rn.split('_')[1]\n",
    "    #for mode in ['LFPand_only','LFPand_exclude']:\n",
    "    for mode in ['LFPand_only']:\n",
    "        print(f'-------  Starting {rn} {medcond}  {mode}')\n",
    "#         impr_wrt_base_per_medcond_per_pgn, impr_per_medcond_per_pgn, impr_wrtLFP_per_medcond_per_pgn, perfs_aver_per_medcond =\\\n",
    "#             computeImprovementsPerParcelGroup(outputs_filtered, \n",
    "#                   'onlyH_act', 'modLFP',mode = mode, inv_exclude = True,\n",
    "#                    score='balanced_accuracy')\n",
    "        impr_wrt_base_per_medcond_per_pgn=computeImprovementsPerParcelGroup2(outputs_filtered, \n",
    "                 base_perf_prefix = base_perf_prefix, base_perf_low_prefix = base_perf_low_prefix,\n",
    "                 mode = mode, inv_exclude = True,\n",
    "                 score = 'balanced_accuracy',\n",
    "                 ignore_base_prefix_missing=1)\n",
    "    #        return impr_wrt_base_per_medcond_per_pgn, impr_per_medcond_per_pgn, impr_wrtLFP_per_medcond_per_pgn, perfs_aver_per_medcond\n",
    "\n",
    "        for medcond in impr_wrt_base_per_medcond_per_pgn.keys():\n",
    "            if len(impr_wrt_base_per_medcond_per_pgn[medcond] ) <= 5:\n",
    "                print(f'WARNING: {rn} {medcond} has zero len impr_wrt_base_per_medcond_per_pgn[{medcond}]')\n",
    "                continue\n",
    "            axs,crlb, info = plotTableInfoBrain(impr_wrt_base_per_medcond_per_pgn , medcond, mco, \n",
    "                    head_subj_ind=None, mode=mode, subdir=subdir, \n",
    "                    savefile_prefix=f'EXPORT_brain_map_area_strength_{rn}_',\n",
    "                    save_only = not make_plots)\n",
    "\n",
    "            ress += [info]\n",
    "            plt.close()\n",
    "            #break\n",
    "        #break\n",
    "resgood = [a is not None for a in ress]\n",
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658ca642",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "impr_wrt_base_per_medcond_per_pgn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4664ed",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mode = 'LFPand_only'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25efe73",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# impr_wrt_base_per_medcond_per_pgn, impr_per_medcond_per_pgn, impr_wrtLFP_per_medcond_per_pgn, perfs_aver_per_medcond =\\\n",
    "#     computeImprovementsPerParcelGroup(outputs_filtered, 'onlyH_act', 'modLFP',\n",
    "#                                       mode = mode, inv_exclude = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f12003",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "impr_per_medcond_per_pgn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45a7aa4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pp.printDict(outputs_filtered,depth_cur=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681aa099",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "outputs_filtered.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0318a44a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60be93c7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tpll = pp.multiLevelDict2TupleList(output_per_raw,4,3)\n",
    "[ (ii,tpl[:-1], len(tpll[ii][-1]['feature_names_filtered']) ) for ii,tpl in enumerate(tpll ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b086a297",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ii = 25\n",
    "print(tpll[ii][:-1])\n",
    "len(tpll[ii][-1]['feature_names_filtered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abd08d3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(tpll[ii][-1]['featnames_for_fit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3cfc7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tpll[ii][-1]['cmd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791f4e49",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3da76d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tpll[ii][-1].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba12d575",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Main feature signif plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88012a5d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe897e8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import utils_postprocess as pp\n",
    "from utils_postprocess_HPC import loadFullScores \n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "\n",
    "#%debug\n",
    "hh_ = None\n",
    "#for prefix_cur in list(sorted( set(prefixes) - set(['all']) )):\n",
    "#for prefix_cur in ['cross_freqmod_beta,gamma:HFO']:\n",
    "#for prefix_cur in [ 'LFPrel_noself']:\n",
    "#for prefix_cur in [ 'onlyH']:\n",
    "#for prefix_cur in [ 'LFPrel_noself_onlyCon']:\n",
    "#for prefix_cur in [ 'allb_beta', 'onlyH']:\n",
    "#for prefix_cur in [  'allb_beta', 'allb_tremor', 'allb_gamma', 'onlyH']:\n",
    "#for prefix_cur in [ 'LFPrel_noself_onlyRbcorr', 'LFPrel_noself_onlyCon', 'modSrc_self',  'onlyCBSrc', 'onlyMotorSrc']:\n",
    "#for prefix_cur in [ 'LFPrel_noself_onlyBpcorr', 'LFPrel_noself']:\n",
    "#for prefix_cur in [ 'all']:\n",
    "#for tpl_ in [('onlyH',10), ('LFPrel_noself',25)]:\n",
    "#for tpl_ in [('LFPrel_noself_onlyRbcorr',15)]:\n",
    "#for tpl_ in [ ('allb_beta',15),  ('allb_gamma',15), ('allb_tremor',15) ]:\n",
    "#for tpl_ in [ ('LFPrel_noself_onlyBpcorr',25)]:    \n",
    "#for prefix_cur in [ 'onlyH', 'LFPrel_noself', 'allb_beta']:\n",
    "#for prefix_cur in prefixes:\n",
    "\n",
    "pref_hh_tuples = [ ('all',40)]\n",
    "pref_hh_tuples = [ ('onlyH',10)]\n",
    "pref_hh_tuples = [('LFPrel_noself',35) ]\n",
    "\n",
    "pref_hh_tuples = [ ('onlyH_act',40)]\n",
    "feat_subset_name = 'all'\n",
    "\n",
    "subdir_short = 'per_subj_per_medcond_best_LFP'\n",
    "grpit_tpl = 'merge_movements','trem_vs_hold&move'\n",
    "#grpit_tpl = 'merge_movements','basic'\n",
    "\n",
    "#subdir_short = 'joint2_noskip'\n",
    "\n",
    "from IPython import get_ipython; ipython = get_ipython()\n",
    "runstr_ = '%run -i ../run/_subrun_plot_imp_HPC.py'\n",
    "ipython.magic(runstr_)\n",
    "#             break+\n",
    "#         break\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221d784a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# EBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76b5721",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232dc4f1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aa = [   'onlyH',\n",
    " 'onlyH_act',\n",
    " 'onlyH_act_CB',\n",
    " 'onlyH_act_CByFS',\n",
    " 'onlyH_act_CByFSyPS',\n",
    " 'onlyH_act_CByFSyPSyPI',\n",
    " 'onlyH_act_CByFSyPSyPIyFM',\n",
    " 'onlyH_act_CBySM',\n",
    " 'onlyH_act_noCB',\n",
    " 'onlyH_act_noCBnoFS',\n",
    " 'onlyH_act_noCBnoFSnoPS',\n",
    " 'onlyH_act_noCBnoFSnoPSnoPI',\n",
    " 'onlyH_act_noCBnoFSnoPSnoPInoFM',\n",
    " 'onlyH_act_noCBnoFSnoPSnoPInoFMnoOI',\n",
    " 'onlyH_act_noCBnoFSnoPSnoPInoFMnoOInoOM',\n",
    " 'onlyH_act_noCBnoFSnoPSnoPInoFMnoOInoOMnoA',\n",
    " 'onlyH_act_noCBnoFSnoPSnoPInoFMnoOInoOMnoAnoTI',\n",
    " 'onlyH_act_noCBnoFSnoPSnoPInoFMnoOInoOMnoAnoTInoSM',\n",
    " 'onlyH_act_noCBnoFSnoPSnoPInoFMnoOInoOMnoAnoTInoSMnoTS',\n",
    " 'onlyH_act_noCBnoFSnoPSnoPInoFMnoOInoOMnoAnoTInoSMnoTSnoFI',\n",
    " 'onlyH_act_noFrontalMed',\n",
    " 'onlyH_act_noFrontalSup',\n",
    " 'onlyH_act_noLFP',\n",
    " 'onlyH_act_noOccipitalMid',\n",
    " 'onlyH_act_noParietalSup',\n",
    " 'onlyH_act_noSensorimotor',\n",
    " 'onlyH_act_noTemporalMid',   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67167266",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aa = [ \n",
    " 'allb_beta_noH',\n",
    " 'allb_gamma_noH',\n",
    " 'allb_tremor_noH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587067d5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1734466c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[tpl[2:-1] for tpl in tpll]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d8b27d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subdir = 'per_subj_per_medcond_best_LFP'\n",
    "subdir_short = subdir\n",
    "\n",
    "pref_hh_tuples = [ ('all',40)]\n",
    "EBM_feat_subsets = ['VIFsel']\n",
    "\n",
    "pref_hh_tuples = [ ('onlyH_act_SMyOIyFSyFIyTM', 5), ('onlyH',20), ('onlyH_act',20), ('LFPrel_noself',40)]\n",
    "pref_hh_tuples = [ ('onlyH_act_SMyOIyFSyFIyTM', 5)]\n",
    "pref_hh_tuples = [ ('LFPrel_noself',40) ]\n",
    "# pref_hh_tuples = [ ('onlyH_act_noCB',20)]\n",
    "# pref_hh_tuples = [ ('onlyH_act_noCBnoFS',20)]\n",
    "# pref_hh_tuples =  [(a,10) for a in aa]\n",
    "#pref_hh_tuples =  [(a,40) for a in aa]\n",
    "##pref_hh_tuples = [ ('modSrc',50)]\n",
    "pref_hh_tuples = [ ('onlyH_act',7)]\n",
    "#pref_hh_tuples = [ ('modLFP',3)]\n",
    "#pref_hh_tuples = [ ('onlyH',10)]\n",
    "#onlyH_act_noCBnoFS\n",
    "# pref_hh_tuples = [ ('onlyH_act_noFrontalSup',20)]\n",
    "# pref_hh_tuples = [ ('onlyH_act_noCBnoFSnoPSnoPI',20)]\n",
    "\n",
    "EBM_feat_subsets = ['all']\n",
    "\n",
    "\n",
    "#subdir_short = 'joint_noskip'\n",
    "#grpit_tpl = 'merge_movements','basic'\n",
    "grpit_tpl = 'merge_movements','trem_vs_hold&move'\n",
    "#grpit_tpl = 'merge_all_not_trem','basic'\n",
    "\n",
    "import gc; gc.collect()\n",
    "#%debug\n",
    "from IPython import get_ipython; ipython = get_ipython()\n",
    "runstr_ = '%run -i ../run/_subrun_plot_imp_EBM_HPC.py'\n",
    "ipython.magic(runstr_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6479d275",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "int( keystr[1:3] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ea7ba2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "outputs_grouped.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97140c46",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9567a7a3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "fname = mult_clf_output['filename_full']\n",
    "mtime = os.stat(  fname).st_mtime\n",
    "datetime.fromtimestamp(mtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15607e04",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cceabad",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mult_clf_output['cmd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9987a15f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mult_clf_output_clf_output_clf_output_clf_output     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da90090",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d = ['Cerebellum','ParietalSup','FrontalSup', 'ParietalInf','Angular', 'OccipitalInf', 'FrontalMed']\n",
    "labels_dict['all_raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b30247",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clf_dict = mult_clf_output['featsel_per_method']['interpret_EBM']['all']\n",
    "print(clf_dict.keys())\n",
    "\n",
    "from interpret import preserve\n",
    "explainer = clf_dict['explainer']\n",
    "scores = clf_dict['scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa63696",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sc_noi, fns_noi, _,_ = postp.splitScoresEBM(scores,explainer.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eaead6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sc_noi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b8c355",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fn_to_observe = fns_noi[-1]\n",
    "print(fn_to_observe)\n",
    "preserve(explainer, fn_to_observe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc778e38",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mult_clf_output['feature_names_filtered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee4e0ae",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dd = 'bias/6.1694/2.4873'\n",
    "np.sum( np.array(list(dd)) == '/' ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5092836f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import gc;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7d216c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "common = set(mult_clf_output['VIF_truncation']['colinds_bad_VIFsel'])\n",
    "#print(common)\n",
    "for i,og in enumerate(outputs_grouped.items() ):\n",
    "    rn = og[0][0]\n",
    "    (prefix,grp,int_type), mult_clf_output = og[1]\n",
    "    VIFtr = mult_clf_output['VIF_truncation']\n",
    "    badinds = VIFtr['colinds_bad_VIFsel']\n",
    "    print(len(badinds), badinds)\n",
    "    common = common & set(badinds)\n",
    "    \n",
    "print(len(common),sorted(common,reverse=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0283524b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d[(rn,prefix,grp,it)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c066b9e4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "VIFtr.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffa8120",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "VIFtr['VIFsel_linreg_objs'][0].__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9be401",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "for rn,prefix,grp,it,mult_clf_output in tpll:\n",
    "    VIFtr = mult_clf_output['VIF_truncation']\n",
    "    dd = dict( VIFtr.items() )\n",
    "    #del dd['VIFsel_linreg_objs']\n",
    "    #dd[]\n",
    "    #VIFtr['VIFsel_linreg_objs'][0]\n",
    "    d[(rn,prefix,grp,it)] = dd\n",
    "#('S01,S02,S04,S05,S07_off', 'allb_beta', 'merge_movements', 'basic')\n",
    "VIF_info_fname = pjoin(gv.data_dir,subdir_short,'VIF_info.npz')\n",
    "print(VIF_info_fname)\n",
    "np.savez(VIF_info_fname,VIF_info = d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4c82c5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7dfe68",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# (rn_,prefix,grp,int_type,fsh,featnames_nice,label_str,\\\n",
    "#      scores_pre_class_curlab, feat_imp_stats ) = collect_SHAP_outs[0]\n",
    "\n",
    "\n",
    "runMLvars_pso = []\n",
    "for cso in collect_SHAP_outs:\n",
    "    (rn_,prefix,grp,int_type,fsh,featnames_nice,label_str,\\\n",
    "         scores_pre_class_curlab, feat_imp_stats ) = cso \n",
    "    \n",
    "    mult_clf_output = output_per_raw[rn_][prefix][grp][int_type]\n",
    "    #assert (prefix,grp,int_type) == (prefix_,grp_,int_type_)    \n",
    "    cmd = mult_clf_output['cmd']\n",
    "    print(cmd[0])\n",
    "\n",
    "    ####################\n",
    "\n",
    "    s = '%run -i ../run/run_ML.py '\n",
    "    for a,b in cmd[0]:\n",
    "        s += f'{a} {b} '\n",
    "    print(s)\n",
    "    from IPython import get_ipython; ipython = get_ipython()\n",
    "\n",
    "    #%run -i ../run/run_ML.py -r S01_on_hold,S01_on_move,S02_on_hold,S02_on_move,S04_on_hold,S04_on_move,S05_on_hold,S05_on_move,S07_on_hold,S07_on_move --param_file ML_joint_one_LFP_HPC.ini --groupings_to_use merge_movements --int_types_to_use basic --feat_types H_act,H_mob,H_compl --prefix onlyH --SLURM_job_id 114703_22 --calc_MI 0\n",
    "\n",
    "    ipython.magic(s + ' --exit_after artif_processed --show_plots 0 --do_cleanup 0')\n",
    "    anndict_per_intcat_per_rawn_out = anndict_per_intcat_per_rawn\n",
    "\n",
    "    runMLvars = {}\n",
    "    runMLvars['featnames_nice'] = featnames_nice\n",
    "    runMLvars['featnames'] = featnames\n",
    "    runMLvars['X_pri'] = X_pri\n",
    "    runMLvars['rawnames'] = rawnames\n",
    "    runMLvars['Xtimes_pri'] = Xtimes_pri\n",
    "    runMLvars['wbd_pri'] = wbd_pri\n",
    "    runMLvars['anndict_per_intcat_per_rawn'] = anndict_per_intcat_per_rawn\n",
    "    runMLvars['new_main_side_pri'] = new_main_side_pri\n",
    "    runMLvars['roi_labels'] = roi_labels\n",
    "    runMLvars['srcgrouping_names_sorted'] = srcgrouping_names_sorted\n",
    "    runMLvars['rawtimes_pri'] = rawtimes_pri\n",
    "    \n",
    "    runMLvars_pso += [runMLvars]\n",
    "\n",
    "    rng = slice(0,10)\n",
    "    \n",
    "    # TODO: right now these are not correct scores (perhaps) because of the way they are averaged\n",
    "    featis = np.argsort(np.abs(scores_pre_class_curlab) )\n",
    "    featis = featis[::-1]\n",
    "    featis = featis[rng] #np.random.randint( len(featnames),size=20)\n",
    "\n",
    "    # anns, anns_pri, times_concat, dataset_bounds, wbd_merged = utsne.concatAnns(rawnames,\n",
    "    #                                                           rawtimes_pri, crop=(crop_start,crop_end),\n",
    "    #                                                           side_rev_pri = side_switch_happened_pri,\n",
    "    #                                                          wbd_pri = wbd_pri, sfreq=sfreq, ret_wbd_merged=1)\n",
    "    # print('times_concat end {} wbd end {}'.format(times_concat[-1] * sfreq, wbd_merged[1,-1] ) )\n",
    "\n",
    "    # ivalis = utils.ann2ivalDict(anns)\n",
    "    # ivalis_tb_indarrays_merged = \\\n",
    "    #     utils.getWindowIndicesFromIntervals(wbd_merged,ivalis,\n",
    "    #                                         sfreq,ret_type='bins_contig',\n",
    "    #                                         ret_indices_type = 'window_inds',\n",
    "    #                                         nbins_total=nbins_total )\n",
    "\n",
    "    # anndict_per_intcat = f['anndict_per_intcat'][()]\n",
    "    # anndict_per_intcat_per_rawn[rawn] = anndict_per_intcat\n",
    "    # bindict_per_rawn[rawn] = upre.markedIntervals2Bins(anndict_per_intcat,\n",
    "    #                                                    rawtimes,sfreq,wbd=wbd)\n",
    "    xlim = (-4,8)\n",
    "    #xlim = None\n",
    "    figname = 'hists_'+ f'{(rn_,prefix,grp,int_type,label_str,fsh)}_rng={rng}.pdf'\n",
    "    print('start plotting ',figname)\n",
    "    postp.plotFeatHists(rawnames,featnames_nice,featis,X_pri,Xconcat, bindict_per_rawn,\n",
    "                      ivalis_tb_indarrays_merged, xlim_common = xlim,nbins=25, savefig = 0)\n",
    "    \n",
    "    \n",
    "    plt.savefig(pjoin(gv.dir_fig, subdir_short, figname))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390824a7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be68bf28",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(prefix_,grp_,int_type_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95306301",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## get info from run_genfeats (for a fixed rn_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3040ac8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mainLFPchan_per_rawn = {}\n",
    "for runMLvars in runMLvars_pso:\n",
    "    for rawn in runMLvars['rawnames']:\n",
    "        subj,medcond,task  = utils.getParamsFromRawname(rawn)\n",
    "        mainLFPchan_cur = best_LFP_info[subj][f'{best_LFP_prefix},merge_movements,basic']['best_LFP']\n",
    "        #print(rawn,subj,mainLFPchan_cur)\n",
    "        mainLFPchan_per_rawn[rawn] = mainLFPchan_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d1f826",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "rns = list(output_per_raw.keys() )\n",
    "genfeat_info_per_rn = {}\n",
    "for rn_to_plot in rns:\n",
    "    mult_clf_output = output_per_raw[rn_][prefix_][grp][int_type]\n",
    "    ML_info = mult_clf_output['info']\n",
    "    fn_feat = ML_info['fname_feat_full_pri']\n",
    "\n",
    "    dat_out_pri = []\n",
    "    dat_lfp_hires_out_pri = []\n",
    "    times_hires_out_pri = []\n",
    "    times_out_pri = []\n",
    "    subfeature_order_out_pri = []\n",
    "    subfeature_order_lfp_hires_out_pri = []\n",
    "    extdat_out_pri = []\n",
    "    rawnames_out = []\n",
    "    emgdat_pri = []\n",
    "    \n",
    "    for i,fn_feat_cur in enumerate(fn_feat):\n",
    "        ffeat = np.load(fn_feat_cur, allow_pickle=True )\n",
    "        ss = ' '.join([' '.join(list(tpl)) for tpl in  ffeat['cmd'][0]] )\n",
    "        s = '%run -i ../run/run_genfeats.py ' + ss + ' --exit_after prescale_data'\n",
    "        print(s)\n",
    "        ipython.magic(s)\n",
    "\n",
    "        dat_out_pri              += dat_pri\n",
    "        dat_lfp_hires_out_pri    += dat_lfp_hires_pri\n",
    "        times_hires_out_pri      += times_hires_pri\n",
    "        times_out_pri            += times_pri\n",
    "        subfeature_order_out_pri += subfeature_order_pri\n",
    "        subfeature_order_lfp_hires_out_pri += subfeature_order_lfp_hires_pri\n",
    "        extdat_out_pri           += extdat_pri\n",
    "    \n",
    "    import re\n",
    "    for fn in fn_feat:\n",
    "        r = re.match('.*(S[0-9]+_[a-z]+_[a-z]+)_.*',fn).groups()[0]\n",
    "        #rint(r)\n",
    "        rawnames_out += [r]\n",
    "\n",
    "\n",
    "    emgraw_pri = []\n",
    "    for rawi,rawn in enumerate(ML_info['rawnames']):\n",
    "        emgraw = mne.io.read_raw_fif ( pjoin(gv.data_dir,rawn + '_emg_rectconv.fif') )\n",
    "        chns_cur = gv.EMG_per_hand[main_side_pri[rawi]]\n",
    "        emgraw.pick_channels(chns_cur)\n",
    "        emgraw.resample(256)\n",
    "        #emgraw_pri += [emgraw]\n",
    "        emgdat_pri += [emgraw.get_data()]\n",
    "        assert emgdat_pri[-1].shape[1] == len(times_out_pri[rawi])\n",
    "\n",
    "    from featlist import replaceMEGsrcChnamesParams\n",
    "    subfeature_order_newsrcgrp_pri = ML_info.get('chnames_newsrcgrp_pri')\n",
    "    if subfeature_order_newsrcgrp_pri is None:\n",
    "        subfeature_order_newsrcgrp_pri = [0] * len(rawnames_out)\n",
    "        for rawi in range(len(runMLvars['rawnames'])):\n",
    "            subfeature_order_newsrcgrp_pri[rawi] = \\\n",
    "                replaceMEGsrcChnamesParams(subfeature_order_out_pri[rawi], 0,9, '.*', 0)\n",
    "            \n",
    "            \n",
    "    d = {}\n",
    "    d['dat_out_pri'] = dat_out_pri\n",
    "    d['dat_lfp_hires_out_pri'] = dat_lfp_hires_out_pri\n",
    "    d['times_hires_out_pri'] = times_hires_out_pri\n",
    "    d['times_out_pri'] = times_out_pri\n",
    "    d['subfeature_order_out_pri'] = subfeature_order_out_pri\n",
    "    d['subfeature_order_lfp_hires_out_pri'] = subfeature_order_lfp_hires_out_pri\n",
    "    d['extdat_out_pri'] = extdat_out_pri\n",
    "    d['rawnames_out'] = rawnames_out\n",
    "    d['emgdat_pri'] = emgdat_pri\n",
    "    d['subfeature_order_newsrcgrp_pri'] = subfeature_order_newsrcgrp_pri\n",
    "    genfeat_info_per_rn[rn_to_plot] = d\n",
    "\n",
    "# best_LFP_info_fname = pjoin(gv.data_dir, 'best_LFP_info.json')\n",
    "# with open(best_LFP_info_fname, 'r') as f:\n",
    "#     best_LFP_info = json.load(f)\n",
    "\n",
    "\n",
    "\n",
    "display(mainLFPchan_per_rawn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13abf360",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rn_,prefix,grp,int_type,fsh,featnames_nice_VIF,label_str,\\\n",
    "         scores_pre_class_curlab, feat_imp_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a271bd9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot time traces\n",
    "\n",
    "for collect_SHAP_outs_ind in range(len(collect_SHAP_outs)):\n",
    "    #collect_SHAP_outs_ind = 0\n",
    "    (rn_,prefix,grp,int_type,fsh,featnames_nice_VIF,label_str,\\\n",
    "         scores_pre_class_curlab, feat_imp_stats ) = collect_SHAP_outs[collect_SHAP_outs_ind]\n",
    "    print(rn_)\n",
    "    \n",
    "    runMLvars = runMLvars_pso[collect_SHAP_outs_ind]\n",
    "    d = genfeat_info_per_rn[rn_]\n",
    "    \n",
    "#     ##########################  just for now to avoid recalc of genfeats\n",
    "#     if rn_.endswith('_off'):\n",
    "#         continue\n",
    "#     ###########################    \n",
    "        \n",
    "    featis = np.argsort(np.abs(scores_pre_class_curlab) )\n",
    "    featis = featis[::-1]\n",
    "    \n",
    "    mult_clf_output = output_per_raw[rn_][prefix][grp][int_type]\n",
    "    VIF_truncation = mult_clf_output['VIF_truncation']\n",
    "    colinds_good_VIFsel = VIF_truncation['colinds_good_VIFsel']\n",
    "    featnames_VIFsel = runMLvars['featnames'][colinds_good_VIFsel]\n",
    "    featnames_best_LFP = runMLvars['featnames']\n",
    "\n",
    "    from globvars import gp\n",
    "    beh_states_to_shade = [f'{it}_{main_side_let}' for it in gp.int_types_basic]\n",
    "\n",
    "    # TODO: right now these are not correct scores (perhaps) because of the way they are averaged\n",
    "    #%debug\n",
    "    rng = slice(0,8)\n",
    "    #rng = slice(0,2)\n",
    "    rng_feats = slice(0,2)\n",
    "    #rng_feats = slice(0,1)\n",
    "    from plots import plotFeatsAndRelDat\n",
    "    \n",
    "    axs = plotFeatsAndRelDat(runMLvars['rawnames'][rng], \n",
    "                             featnames_VIFsel[featis[rng_feats]], d['dat_out_pri'],\n",
    "                       d['subfeature_order_out_pri'],\n",
    "                    runMLvars['X_pri'],[featnames_best_LFP]*len(d['rawnames_out']),\n",
    "                    d['times_out_pri'],\n",
    "                    runMLvars['Xtimes_pri'],\n",
    "                    d['subfeature_order_newsrcgrp_pri'], runMLvars['wbd_pri'],\n",
    "                    dat_hires_pri=d['dat_lfp_hires_out_pri'],\n",
    "                    chnames_all_hires_pri = d['subfeature_order_lfp_hires_out_pri'],\n",
    "                    times_hires_pri=d['times_hires_out_pri'],\n",
    "                    anndict_per_intcat_per_rawn=runMLvars['anndict_per_intcat_per_rawn'], \n",
    "                    sfreq=sfreq, mainLFP_per_rawn = mainLFPchan_per_rawn,\n",
    "                    roi_labels=roi_labels, srcgrouping_names_sorted=['all_raw']*10,\n",
    "                            main_side_let = main_side_let, ww=6,hh=3,\n",
    "                            beh_states_to_shade = beh_states_to_shade, \n",
    "                             extdat_pri=d['emgdat_pri'])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(pjoin(gv.dir_fig,'joint',f'good_feats_dyn_{(rn_,prefix,grp,int_type,label_str,fsh)}_{rng}.pdf'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362bb5c4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(collect_SHAP_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08947c38",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3cd7ca",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5692bdd3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# interpretML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754cf802",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#for prefix_cur in prefixes:\n",
    "#for prefix_cur in prefixes[:3]:\n",
    "#for prefix_cur in prefixes:\n",
    "for prefix in ['onlyMotorSrc']:\n",
    "    prefixes_to_use = [prefix_cur]\n",
    "\n",
    "    outputs_grouped = pp.groupOutputs(output_per_raw, prefixes_to_use,\n",
    "                                      ['merge_movements'],['trem_vs_hold&move'])\n",
    "    print('      ',prefix_cur)\n",
    "    for og in outputs_grouped.items():\n",
    "        rn = og[0]\n",
    "        (prefix,grp,int_type), mult_clf_output = og[1]\n",
    "        assert prefix == prefix_cur\n",
    "    \n",
    "        filename_fullsize = mult_clf_output['filename_full']\n",
    "        from pathlib import Path\n",
    "        pfsz = Path(filename_fullsize)\n",
    "        filename_fullsize = pjoin(pfsz.parents[0], pfsz.name[2:])\n",
    "        #    finfo = os.stat( filename_fullsize )\n",
    "        #    print(finfo.st_size / (1024**2))\n",
    "        f = np.load(filename_fullsize,allow_pickle=True)\n",
    "\n",
    "        results_cur =  f['results_cur'][()]\n",
    "\n",
    "        #results_cur.keys()\n",
    "\n",
    "        EBM = results_cur['featsel_per_method']['interpret_EBM']        \n",
    "        #scores\n",
    "\n",
    "        clf_dict = EBM['info_per_cp'][('trem_L', 'hold_L&move_L')]\n",
    "        scores = clf_dict['scores']; \n",
    "        #print(len(results_cur['feature_names_filtered']), len(EBM['feature_indices_used']) )\n",
    "        #print('len(scores) = ',len(scores) )\n",
    "        explainer = clf_dict['explainer']\n",
    "        \n",
    "        print((rn,grp,int_type), utsne.sprintfPerfs(clf_dict['perf'] ) )\n",
    "\n",
    "        del f\n",
    "        del results_cur\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fac607",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#       LFPrel_noself\n",
    "# (('S01,S02,S04,S05,S07_on',), 'merge_movements', 'trem_vs_hold&move') 63.70%,97.30%,73.97%\n",
    "# (('S01,S02,S04,S05,S07_off',), 'merge_movements', 'trem_vs_hold&move') 54.75%,93.76%,65.06%\n",
    "#        LFPrel_noself_onlyBpcorr\n",
    "# (('S01,S02,S04,S05,S07_on',), 'merge_movements', 'trem_vs_hold&move') 53.09%,96.59%,64.78%\n",
    "# (('S01,S02,S04,S05,S07_off',), 'merge_movements', 'trem_vs_hold&move') 49.71%,93.22%,60.30%\n",
    "#        LFPrel_noself_onlyCon\n",
    "# (('S01,S02,S04,S05,S07_on',), 'merge_movements', 'trem_vs_hold&move') 42.19%,94.97%,53.35%\n",
    "# (('S01,S02,S04,S05,S07_off',), 'merge_movements', 'trem_vs_hold&move') 30.51%,92.18%,41.29%\n",
    "#        LFPrel_noself_onlyRbcorr\n",
    "# (('S01,S02,S04,S05,S07_on',), 'merge_movements', 'trem_vs_hold&move') 48.94%,97.15%,62.01%\n",
    "# (('S01,S02,S04,S05,S07_off',), 'merge_movements', 'trem_vs_hold&move') 35.56%,92.61%,46.82%\n",
    "#        allb_beta\n",
    "# (('S01,S02,S04,S05,S07_on',), 'merge_movements', 'trem_vs_hold&move') 64.64%,95.34%,72.04%\n",
    "# (('S01,S02,S04,S05,S07_off',), 'merge_movements', 'trem_vs_hold&move') 55.94%,90.69%,63.34%\n",
    "#        cross_freqmod_beta,gamma:HFO\n",
    "# (('S01,S02,S04,S05,S07_on',), 'merge_movements', 'trem_vs_hold&move') 18.93%,97.11%,29.55%\n",
    "# (('S01,S02,S04,S05,S07_off',), 'merge_movements', 'trem_vs_hold&move') 26.17%,94.16%,37.62%\n",
    "#        cross_freqmod_tremor,beta:HFO\n",
    "# (('S01,S02,S04,S05,S07_on',), 'merge_movements', 'trem_vs_hold&move') 40.86%,95.38%,52.56%\n",
    "# (('S01,S02,S04,S05,S07_off',), 'merge_movements', 'trem_vs_hold&move') 35.36%,92.31%,46.41%\n",
    "#        cross_freqmod_tremor,gamma:beta\n",
    "# (('S01,S02,S04,S05,S07_on',), 'merge_movements', 'trem_vs_hold&move') 39.69%,96.07%,52.15%\n",
    "# (('S01,S02,S04,S05,S07_off',), 'merge_movements', 'trem_vs_hold&move') 27.67%,94.66%,39.64%\n",
    "#        modLFP\n",
    "# (('S01,S02,S04,S05,S07_on',), 'merge_movements', 'trem_vs_hold&move') 35.31%,95.57%,47.26%\n",
    "# (('S01,S02,S04,S05,S07_off',), 'merge_movements', 'trem_vs_hold&move') 4.50%,98.84%,8.41%\n",
    "#        modSrc\n",
    "# (('S01,S02,S04,S05,S07_on',), 'merge_movements', 'trem_vs_hold&move') 72.72%,97.23%,80.13%\n",
    "# (('S01,S02,S04,S05,S07_off',), 'merge_movements', 'trem_vs_hold&move') 62.01%,93.29%,70.18%\n",
    "#        modSrc_self\n",
    "# (('S01,S02,S04,S05,S07_on',), 'merge_movements', 'trem_vs_hold&move') 63.11%,95.55%,71.22%\n",
    "# (('S01,S02,S04,S05,S07_off',), 'merge_movements', 'trem_vs_hold&move') 55.49%,90.39%,62.74%\n",
    "#        onlyCBSrc\n",
    "# (('S01,S02,S04,S05,S07_on',), 'merge_movements', 'trem_vs_hold&move') 53.38%,95.51%,63.69%\n",
    "# (('S01,S02,S04,S05,S07_off',), 'merge_movements', 'trem_vs_hold&move') 22.85%,94.62%,33.94%\n",
    "#        onlyH\n",
    "# (('S01,S02,S04,S05,S07_on',), 'merge_movements', 'trem_vs_hold&move') 62.04%,95.14%,69.86%\n",
    "# (('S01,S02,S04,S05,S07_off',), 'merge_movements', 'trem_vs_hold&move') 51.43%,91.03%,60.01%\n",
    "#        onlyMotorSrc\n",
    "# (('S01,S02,S04,S05,S07_on',), 'merge_movements', 'trem_vs_hold&move') 74.52%,97.34%,81.46%\n",
    "# (('S01,S02,S04,S05,S07_off',), 'merge_movements', 'trem_vs_hold&move') 63.63%,94.94%,72.74%\n",
    "#        onlyRestSrc\n",
    "# (('S01,S02,S04,S05,S07_on',), 'merge_movements', 'trem_vs_hold&move') 66.35%,96.35%,74.51%\n",
    "# (('S01,S02,S04,S05,S07_off',), 'merge_movements', 'trem_vs_hold&move') 60.19%,92.75%,68.41%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503542ba",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(rn_,prefix,grp,int_type,fsh,featnames_nice,label_str,\\\n",
    "     scores_pre_class_curlab, feat_imp_stats ) = collect_SHAP_outs[0]\n",
    "\n",
    "print(rn_,prefix,grp,int_type)\n",
    "mult_clf_output = output_per_raw[rn_][prefix][grp][int_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a234e3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mult_clf_output = output_per_raw['S01,S02,S04,S05,S07_off']['onlyH'][grp][int_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f780228a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mult_clf_output = output_per_raw['S01,S02,S04,S05,S07_on']['onlyMotorSrc'][grp][int_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5994971",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(range(0,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f23a0a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[4  for d in [4,5] if d in [4,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b181737",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "help(plotFeatsAndRelDat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d841e7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del plotFeatsAndRelDat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b72fa07",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import plots\n",
    "import importlib as il; il.reload(plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99dea57",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "runMLvars['wbd_pri'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9706544",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ac0326",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "extdat_out_pri[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237b6517",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from globvars import gp\n",
    "beh_states_to_shade = [f'{it}_{main_side_let}' for it in gp.int_types_basic]\n",
    "\n",
    "# TODO: right now these are not correct scores (perhaps) because of the way they are averaged\n",
    "#%debug\n",
    "rng = slice(0,8)\n",
    "#rng = slice(0,2)\n",
    "rng_feats = slice(0,2)\n",
    "#rng_feats = slice(0,1)\n",
    "from plots import plotFeatsAndRelDat\n",
    "axs = plotFeatsAndRelDat(runMLvars['rawnames'][rng], \n",
    "                         featnames_VIFsel[featis[rng_feats]], dat_out_pri,\n",
    "                   subfeature_order_out_pri,\n",
    "                runMLvars['X_pri'],[featnames_best_LFP]*len(rawnames_out),\n",
    "                times_out_pri,\n",
    "                runMLvars['Xtimes_pri'],\n",
    "                subfeature_order_newsrcgrp_pri, runMLvars['wbd_pri'],\n",
    "                dat_hires_pri=dat_lfp_hires_out_pri,\n",
    "                chnames_all_hires_pri = subfeature_order_lfp_hires_out_pri,\n",
    "                times_hires_pri=times_hires_out_pri,\n",
    "                anndict_per_intcat_per_rawn=runMLvars['anndict_per_intcat_per_rawn'], \n",
    "                sfreq=sfreq, mainLFP_per_rawn = mainLFPchan_per_rawn,\n",
    "                roi_labels=roi_labels, srcgrouping_names_sorted=['all_raw']*10,\n",
    "                        main_side_let = main_side_let, ww=6,hh=3,\n",
    "                        beh_states_to_shade = beh_states_to_shade, \n",
    "                         extdat_pri=emgdat_pri)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(pjoin(gv.dir_fig,'joint',f'good_feats_dyn_{(rn_,prefix,grp,int_type,fsh)}_{rng}.pdf'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554e908a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_feat_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12772a7e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print( utsne.sprintfPerfs(clf_dict['perf'] ) )\n",
    "print( clf_dict['confmat_normalized'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4271e0fa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.argmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e347e2aa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "assert len( explainer.feature_names ) == len(scores)\n",
    "best_feat_name = explainer.feature_names [ np.argmax(scores)]\n",
    "print(best_feat_name)\n",
    "sortinds = np.argsort(scores)\n",
    "last_ind = np.where([ explainer.feature_names[ind].find(' x ') < 0 \\\n",
    "                     for ind in  sortinds])[0][-1]\n",
    "last_ind = sortinds[last_ind]\n",
    "best_feat_name_no_int = explainer.feature_names[last_ind]\n",
    "print(best_feat_name_no_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7983d5c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sortinds[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c0458d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    " len(scores), last_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b64bdce",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "explainer.feature_names[last_ind], m[last_ind], best_feat_name_no_int.find(' x ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7263e1b9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.where(m)[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d986d97",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87216f81",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m = [ explainer.feature_names[ind].find(' x ') < 0 \\\n",
    "                     for ind in np.argsort(scores) ]\n",
    "print(m[344])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf377f4d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dbf8e6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print( explainer.__dict__.keys() )\n",
    "# print( explainer.explanation_type, explainer.name, \n",
    "#      explainer.selector, explainer.feature_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af29973f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mult_clf_output['featsel_per_method']['interpret_EBM']['all'].keys()\n",
    "\n",
    "from interpret import preserve\n",
    "explainer = clf_dict['explainer']\n",
    "preserve(explainer, best_feat_name_no_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41232ff",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preserve(explainer, best_feat_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437ebd5d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "explainer.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f95b7ff",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from interpret import show\n",
    "# show(explainer)  # does not work if open saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f5b5ff",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Trying to get a better distr fit for Hjorth (no success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99d15bd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(featnames_nice), len(featnames_VIFsel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb15bde",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.array(featnames_nice)[featis[-2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757360cb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "featnames[featis[-2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dddd60",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "roi_labels['all_raw'][30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e44c69",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(featnames_nice), len(featnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589e9707",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "featnames_nice[-5:], featnames[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce35cff",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pjoin(subdir,'good_feats_dyn.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761d5eae",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from plots import plotFeatsWithEverything\n",
    "# #%debug\n",
    "# plotFeatsWithEverything(dat_pri, rawtimes_pri, X_pri, \n",
    "#                             Xtimes_pri, dat_lfp_hires_pri, times_hires_pri,\n",
    "#                             rawnames,\n",
    "#                             subfeature_order_pri, subfeature_order_newsrcgrp_pri,\n",
    "#                             subfeature_order_lfp_hires_pri,\n",
    "#                             anndict_per_intcat_per_rawn,\n",
    "#                             featnames, wbd_pri,\n",
    "#                             sfreq, raw_perband_flt_pri, raw_perband_bp_pri,\n",
    "#                             scale_data_combine_type,\n",
    "#                             stats_multiband_flt, stats_multiband_bp,\n",
    "#                             test_plots_descr, special_chns,\n",
    "#                            fband_names_inc_HFO )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12481001",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24da4f76",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67204c2e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.min(Xconcat), np.max(Xconcat_to_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86916c2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dd0 = Xconcat[:,featis[0]]\n",
    "#dd = dd[ dd< np.quantile(dd,0.95)]\n",
    "dd = np.exp(dd0) \n",
    "#dd = 1/dd\n",
    "dd = np.log( dd - np.min(dd) *.99 )\n",
    "#dd = dd[ dd< np.quantile(dd,0.99)]\n",
    "plt.hist(dd,bins=250,alpha=0.5,label='new');\n",
    "\n",
    "plt.hist(dd0,bins=250,alpha=0.5,label='old');\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938410b1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.hist(dd0,bins=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05718f5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.min(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9559a356",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ce144f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "help(dist.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2f466d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c3cdce",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "qm = np.quantile(dd,0.99)\n",
    "y = dd [ dd < qm]\n",
    "#y = np.exp(y)\n",
    "size = len(y)\n",
    "x = np.arange(np.min(y),np.max(y),0.5)\n",
    "#y = 0.01 -np.min(dd) + dd\n",
    "#x = np.arange(0.01,55,0.5)\n",
    "#y = scipy.int_(np.round_(scipy.stats.vonmises.rvs(5,size=size)*47))\n",
    "h = plt.hist(y, bins=x)\n",
    "binh,binloc,barcont = h\n",
    "\n",
    "# beta, rayleigh look ok\n",
    "#ten best\n",
    "# dist_names = ['cauchy',\n",
    "#  'dweibull',\n",
    "#  'foldcauchy',\n",
    "#  'dgamma',\n",
    "#  't',\n",
    "#  'tukeylambda',\n",
    "#  'fisk',\n",
    "#  'weibull_min', 'erlang']\n",
    "\n",
    "#'loglaplace',\n",
    " \n",
    "dist_names = ['alpha', 'cauchy',  'dgamma', 'dweibull', 'erlang', 'exponweib',\n",
    "              'genlogistic',  'foldcauchy',  'genextreme']\n",
    "#  'fisk',  'fatiguelife',  'gumbel_r',  'gengamma','invweibull',\n",
    "#  'invgamma',  'mielke',  'powerlognorm',  'nct',\n",
    "#  'johnsonsu',  'lognorm',  'invgauss',  'loglaplace',\n",
    "#  'recipinvgauss',  'pearson3',  'laplace', 't',  'tukeylambda',\n",
    "#  'hypsecant',  'weibull_min',  'logistic',  'kstwobign',\n",
    "#               'nakagami',  'rayleigh',  'rice',  'maxwell']\n",
    "dist_names = ['beta']\n",
    "dist_names = ['levy_stable']\n",
    "\n",
    "do_plot = 1\n",
    "d_per_name = {}\n",
    "pdf_fit_per_name = {}\n",
    "\n",
    "for dist_name in dist_names:\n",
    "    dist = getattr(scipy.stats, dist_name)\n",
    "    params = dist.fit(y)\n",
    "    arg = params[:-2]\n",
    "    loc = params[-2]\n",
    "    scale = params[-1]\n",
    "    if arg:\n",
    "        pdf_fitted = dist.pdf(binloc, *arg, loc=loc, scale=scale) * size\n",
    "    else:\n",
    "        pdf_fitted = dist.pdf(binloc, loc=loc, scale=scale) * size\n",
    "    if do_plot and np.max(pdf_fitted) < np.max(binh) * 3:\n",
    "        plt.plot(binloc, pdf_fitted, label=dist_name)\n",
    "    plt.xlim(-6,20)\n",
    "    pdf_fit_per_name[dist_name] = pdf_fitted\n",
    "    \n",
    "    discrep = np.sum(np.abs( binh-pdf_fitted[:-1] ) ) / len(binh)\n",
    "    d_per_name[dist_name] = discrep\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b6d8c7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb42ff72",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "help(sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a9d2f1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stl = sorted( list( d_per_name.items() ), key = lambda x: x[1] )\n",
    "stl_ext = [ (dn,v,pdf_fit_per_name[dn][0]) for  (dn, v) in stl]\n",
    "display(stl_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98137e2d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list( set( ['exponpow', 'f', 'fatiguelife', 'fisk', 'foldcauchy', 'foldnorm', \n",
    "               'frechet_r', 'frechet_l', 'genlogistic', 'genpareto', 'genexpon', \n",
    "               'genextreme', 'gausshyper', 'gamma', 'gengamma', 'genhalflogistic', \n",
    "               'gilbrat', 'gompertz', 'gumbel_r', 'gumbel_l', 'halfcauchy'] ) - \\\n",
    "set( ['frechet_r',\n",
    " 'genhalflogistic',\n",
    " 'foldnorm',\n",
    " 'gilbrat',\n",
    " 'gompertz',\n",
    " 'genpareto',\n",
    " 'genexpon',\n",
    " 'halfcauchy',\n",
    " 'exponpow',\n",
    " 'gamma',\n",
    " 'frechet_l',\n",
    " 'f',\n",
    " 'gausshyper',\n",
    " 'gumbel_l'] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b223f9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list(list(zip(*stl))[0])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab13977b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list(list(zip(*stl))[0])[-14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1939a488",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list(list(zip(*stl))[0])[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6200d0ee",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(binh), len(pdf_fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aca920",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f398bbf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(binh)\n",
    "plt.plot(pdf_fitted[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378c2c10",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb754d9c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "help(plt.subplots_adjust)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obddp_interactive",
   "language": "python",
   "name": "obddp_interactive"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
