{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969bf5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import globvars as gv\n",
    "from globvars import gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2621f551",
   "metadata": {},
   "outputs": [],
   "source": [
    "#$RS --mods msrc --feat_types H_act --parcel_group_names Sensorimotor,OccipitalI    nf,FrontalSup,FrontalInf,TemporalMid  --prefix onlyH_act_SMyOIyFSyFIyTM_noLFP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62de14ae",
   "metadata": {},
   "source": [
    "# Set params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215f0348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normally I want to join all datasets within each subject (across medcond and task)\n",
    "inc_S03 = True\n",
    "inc_noMvt = False\n",
    "join_medcond = False  # medconds merged across subj\n",
    "join_subjects = False\n",
    "\n",
    "#overlapping_windows = True\n",
    "overlapping_windows = False\n",
    "semidisjoint_windows = True\n",
    "disjoint_windows = True\n",
    "exCB_sides = True   # here we use only LFP anyway\n",
    "incCB_sides = True\n",
    "\n",
    "rawnames_dict = {}\n",
    "\n",
    "prefixes_types = ['PREFIXES_H']\n",
    "prefixes_types = ['PREFIXES_H_LFP_SIDED']\n",
    "prefixes_types += ['PREFIXES_H_CTXLFP_SIDED']\n",
    "\n",
    "#fname_runstr = '_runstrings_ML_test.txt'\n",
    "fname_runstr = '_runstrings_ML_searchLFP.txt'\n",
    "g_it_strs = []\n",
    "g_it_strs += [' --groupings_to_use merge_all_not_trem --int_types_to_use basic']\n",
    "g_it_strs += [' --groupings_to_use merge_nothing   --int_types_to_use basic']\n",
    "g_it_strs += [' --groupings_to_use merge_movements --int_types_to_use basic']\n",
    "g_it_strs += [' --groupings_to_use merge_nothing   --int_types_to_use trem_vs_quiet']\n",
    "\n",
    "comment = 'Select best LFP using H act on both sides, no XGB tuning'\n",
    "\n",
    "runpars = {}\n",
    "runpars['inc_S03'] = inc_S03\n",
    "runpars['join_subjects'] =join_subjects\n",
    "runpars['inc_noMvt'] = inc_noMvt\n",
    "runpars['join_medcond'] = join_medcond\n",
    "runpars['prefixes_types'] = prefixes_types\n",
    "runpars['fname_runstr'] = fname_runstr\n",
    "#runpars['barain_area_inclusion_modes'] = modes\n",
    "runpars['run_specific_args'] = ' --XGB_tune_param 0'  #techincal params about inclusion of some algortihms or no\n",
    "runpars['comment'] = comment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501d7b49",
   "metadata": {},
   "source": [
    "# Apply params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761450c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawnames_dict['off_Mvt_best'] = ['S01_off_hold',\n",
    " 'S01_off_move',\n",
    " 'S02_off_hold',\n",
    " 'S02_off_move',\n",
    " 'S04_off_hold',\n",
    " 'S04_off_move',\n",
    " 'S05_off_hold',\n",
    " 'S05_off_move',\n",
    " 'S07_off_hold',\n",
    " 'S07_off_move']\n",
    "rawnames_dict['off_unsure'] = ['S03_off_hold', 'S03_off_move']\n",
    "rawnames_dict['off_Mvt'] = rawnames_dict['off_Mvt_best'] + rawnames_dict['off_unsure']\n",
    "rawnames_dict['on_Mvt'] = ['S01_on_hold',\n",
    " 'S01_on_move',\n",
    " 'S02_on_hold',\n",
    " 'S02_on_move',\n",
    " 'S04_on_hold',\n",
    " 'S04_on_move',\n",
    " 'S05_on_hold',\n",
    " 'S05_on_move',\n",
    " 'S07_on_hold',\n",
    " 'S07_on_move'] \n",
    "\n",
    "rns = rawnames_dict['off_Mvt_best'] + rawnames_dict['on_Mvt']\n",
    "z = zip(rns[::2], rns[1::2])\n",
    "per_subj_tasks_merged = list(z)\n",
    "per_subj_tasks_merged = [ rawnames_dict['off_unsure'] ] + per_subj_tasks_merged\n",
    "##############################################\n",
    "rawnames_list = []\n",
    "if join_subjects:\n",
    "    if not join_medcond:\n",
    "        if inc_S03:\n",
    "            rawnames_list += [ ('normal', rawnames_dict['off_Mvt'] ) ] \n",
    "        else:\n",
    "            rawnames_list += [ ('normal', rawnames_dict['off_Mvt_best'] ) ] \n",
    "        if inc_noMvt:\n",
    "            raise ValueError('not implemented')\n",
    "\n",
    "        rawnames_list += [ ('normal',rawnames_dict['on_Mvt']) ] \n",
    "\n",
    "        if inc_noMvt:\n",
    "            raise ValueError('not implemented')\n",
    "    else:\n",
    "        if inc_S03:\n",
    "            kk = 'off_Mvt'\n",
    "        else:\n",
    "            kk = 'off_Mvt_best'\n",
    "        rns = rawnames_dict[kk] + rawnames_dict['on_Mvt']\n",
    "\n",
    "        rawnames_list += [ ('normal',rns ) ] \n",
    "else:\n",
    "    if not join_medcond:\n",
    "        for tpl in per_subj_tasks_merged:\n",
    "            rawnames_list += [ ('normal', list(tpl) ) ] \n",
    "    else:\n",
    "        from utils_preproc import getRawnameListStructure\n",
    "        rnstruct,rnstruct_glob = getRawnameListStructure(list(set(sum(rawnames_dict.values(),[]) )), ret_glob=1)\n",
    "        for subj,v in rnstruct.items():\n",
    "            rawnames_list += [ ('normal', list(sorted(v['datasets']))  )  ]\n",
    "            #s = ','.join(v['datasets'])\n",
    "            #print(s)\n",
    "\n",
    "##############################################\n",
    "if join_subjects:\n",
    "    if join_medcond:\n",
    "        rn_test =  ('test',[ 'S01_off_hold', 'S04_off_hold', 'S05_off_move'] ) \n",
    "    else:\n",
    "        rn_test =  ('test',[ 'S01_off_hold', 'S01_on_move', 'S04_off_hold', 'S05_on_move'] ) \n",
    "else:\n",
    "    if not join_medcond:\n",
    "        rn_test =  ('test',[ 'S04_off_hold', 'S04_off_move'] ) \n",
    "    else:\n",
    "        rn_test =  ('test',[ 'S04_off_hold', 'S04_on_move'] ) \n",
    "rawnames_list += [rn_test]\n",
    "##############################################\n",
    "pfstr_per_rnt = {}\n",
    "\n",
    "if join_subjects:\n",
    "    raise ValueError(\"not implemented\")\n",
    "    if join_medcond:\n",
    "        pfile_str = ' --param_file ML_joint2_one_LFP_HPC.ini'\n",
    "        #TODO: create a new pfile for testing, this one does not exit\n",
    "        pfile_str_test = ' --param_file ML_joint2_one_LFP_HPC_fast.ini'\n",
    "    else:\n",
    "        pfile_str = ' --param_file ML_joint_one_LFP_HPC.ini'\n",
    "        pfile_str_test = ' --param_file ML_joint_one_LFP_HPC_fast.ini' \n",
    "else:\n",
    "    if not join_medcond:\n",
    "        #raise ValueError('not implemented')\n",
    "        pfile_str      = ' --param_file ML_searchLFP_both_HPC.ini'\n",
    "        pfile_str_test = ' --param_file ML_searchLFP_both_HPC_fast.ini' \n",
    "    else:\n",
    "        pfile_str      = ' --param_file ML_searchLFP_both_HPC.ini'\n",
    "        pfile_str_test = ' --param_file ML_searchLFP_both_HPC_fast.ini' \n",
    "    \n",
    "pfstr_per_rnt ['normal'] = pfile_str\n",
    "pfstr_per_rnt ['test']   = pfile_str_test\n",
    "\n",
    "\n",
    "runpars['incCB_sides'] = incCB_sides\n",
    "runpars['exCB_sides'] = exCB_sides\n",
    "runpars['inc_disjoint_windows'] = disjoint_windows\n",
    "runpars['inc_overlapping_windows'] = overlapping_windows\n",
    "runpars['prefixes_types'] = prefixes_types\n",
    "#############################################\n",
    "BANDS_BETA = 'beta'\n",
    "BANDS_GAMMA = 'gamma'\n",
    "BANDS_TREMOR = 'tremor'\n",
    "\n",
    "rslist_cur = []\n",
    "if \"PREFIXES_H\" in prefixes_types:    \n",
    "    if disjoint_windows:\n",
    "        rslist_cur += [('modLFP_onlyH_act_disjoint',          '--mods LFP --feat_types H_act --subskip_fit 8')]        \n",
    "        rslist_cur += [('modLFP_onlyH_disjoint',               '--mods LFP --feat_types H_act,H_mob,H_compl  --subskip_fit 8')] \n",
    "    if semidisjoint_windows:\n",
    "        rslist_cur += [('modLFP_onlyH_act_semidisjoint',          '--mods LFP --feat_types H_act --subskip_fit 4')]        \n",
    "        rslist_cur += [('modLFP_onlyH_semidisjoint',               '--mods LFP --feat_types H_act,H_mob,H_compl  --subskip_fit 4')]         \n",
    "    if overlapping_windows:\n",
    "        rslist_cur += [('modLFP_onlyH_act',           '--mods LFP --feat_types H_act')]        \n",
    "        rslist_cur += [('modLFP_onlyH',               '--mods LFP --feat_types H_act,H_mob,H_compl')] \n",
    "    \n",
    "if \"PREFIXES_H_LFP_SIDED\" in prefixes_types:\n",
    "    side_pairs = [('both','both')]\n",
    "    if incCB_sides:\n",
    "        side_pairs += [('left','left'), ('right','right')]\n",
    "    for side1,side2 in side_pairs:\n",
    "        addstr = f' --brain_side_to_use {side1} --LFP_side_to_use {side2}'\n",
    "        if disjoint_windows:\n",
    "            rslist_cur += [(f'modLFP_onlyH_act_brain{side1}_disjoint',  f'--mods LFP --feat_types H_act --subskip_fit 8'  + addstr)]        \n",
    "            rslist_cur += [(f'modLFP_onlyH_brain{side1}_disjoint',      f'--mods LFP --feat_types H_act,H_mob,H_compl --subskip_fit 8' + addstr)] \n",
    "        if semidisjoint_windows:\n",
    "            rslist_cur += [(f'modLFP_onlyH_act_brain{side1}_semidisjoint',  f'--mods LFP --feat_types H_act --subskip_fit 4'  + addstr)]        \n",
    "            rslist_cur += [(f'modLFP_onlyH_brain{side1}_semidisjoint',      f'--mods LFP --feat_types H_act,H_mob,H_compl --subskip_fit 4' + addstr)] \n",
    "        if overlapping_windows:\n",
    "            rslist_cur += [(f'modLFP_onlyH_act_brain{side1}',           f'--mods LFP --feat_types H_act' + addstr )]        \n",
    "            rslist_cur += [(f'modLFP_onlyH_brain{side1}',               f'--mods LFP --feat_types H_act,H_mob,H_compl' + addstr)]         \n",
    "            \n",
    "if \"PREFIXES_H_CTXLFP_SIDED\" in prefixes_types:\n",
    "    side_pairs = [('both','both')]\n",
    "#     if incCB_sides:\n",
    "#         side_pairs += [('left','left'), ('right','right')]\n",
    "    if exCB_sides:\n",
    "        side_pairs += [ ('left_exCB','left'), ('right_exCB','right') ]\n",
    "    for side1,side2 in side_pairs:\n",
    "        addstr = f' --brain_side_to_use {side1} --LFP_side_to_use {side2}'\n",
    "        if disjoint_windows:\n",
    "            rslist_cur += [(f'onlyH_act_brain{side1}_disjoint',  f'--mods LFP,msrc --feat_types H_act --subskip_fit 8'  + addstr)]        \n",
    "            rslist_cur += [(f'onlyH_brain{side1}_disjoint',      f'--mods LFP,msrc --feat_types H_act,H_mob,H_compl --subskip_fit 8' + addstr)] \n",
    "        if semidisjoint_windows:\n",
    "            rslist_cur += [(f'onlyH_act_brain{side1}_semidisjoint',  f'--mods LFP,msrc --feat_types H_act --subskip_fit 4'  + addstr)]        \n",
    "            rslist_cur += [(f'onlyH_brain{side1}_semidisjoint',      f'--mods LFP,msrc --feat_types H_act,H_mob,H_compl --subskip_fit 4' + addstr)]     \n",
    "        if overlapping_windows:\n",
    "            rslist_cur += [(f'onlyH_act_brain{side1}',           f'--mods LFP,msrc --feat_types H_act' + addstr )]        \n",
    "            rslist_cur += [(f'onlyH_brain{side1}',               f'--mods LFP,msrc --feat_types H_act,H_mob,H_compl' + addstr)] \n",
    "        \n",
    "    \n",
    "    #rslist_cur += ['--feat_types H_act --mods LFP      --prefix onlyH_act_onlyLFP         ']        \n",
    "    #rslist_cur += ['--feat_types H_act --mods LFP      --prefix onlyH_act_onlyLFP         ']    \n",
    "assert len(rslist_cur) == len(set(rslist_cur))  # I don't want reapeats\n",
    "prefs = list( list( zip(*rslist_cur) )[0] )\n",
    "assert len(prefs) == len(set(prefs))  # I don't want reapeats even in prefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cd38a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34bbbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rawnames_list,rslist_cur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3e812d",
   "metadata": {},
   "source": [
    "# Set timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74869018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "print(f'Set new timestamp at {datetime.datetime.now()}')\n",
    "run_corresp_id = int( time.time() * 10000 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d38f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rawnames_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad821ad",
   "metadata": {},
   "source": [
    "# Generate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7f144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prefixes_types, pfstr_per_rnt, g_it_strs, rslist_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fea280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True\n",
    "special_globinds = []  \n",
    "# these are globinds that don't take into account test strings that will be added in the beginning\n",
    "\n",
    "runstrings_per_rnt = {}\n",
    "    \n",
    "n_testrunstr_to_include = 1\n",
    "runfile = 'run_ML.py' \n",
    "no_LFP_unless_explicit = 1\n",
    "    \n",
    "global_ind = 0\n",
    "runstrings = []\n",
    "\n",
    "for g_it_str in g_it_strs:\n",
    "    pref2pgn = {}\n",
    "    for rnt in pfstr_per_rnt:\n",
    "        runstrings_per_rnt[rnt ] = []\n",
    "    # Cycle over rawnames\n",
    "    for rnt,rawnames in rawnames_list:\n",
    "        rawstr = ','.join(rawnames)    \n",
    "        for tpl in rslist_cur:  #prefix name, prefix param\n",
    "            prefix,rs = tpl[:2]\n",
    "            s = runfile\n",
    "            s+= f' -r {rawstr}' \n",
    "            s+= f' --prefix {prefix}'\n",
    "            s+= ' ' + rs\n",
    "            s+= pfstr_per_rnt[rnt]  # param file\n",
    "            s+= g_it_str\n",
    "            s+= f' --runCID {run_corresp_id}'\n",
    "            s+= ' ' + runpars['run_specific_args']                 \n",
    "            descr = None\n",
    "            if len(tpl) > 2:\n",
    "                descr = tpl[2]\n",
    "            pref2pgn[prefix] = [None,None,descr]\n",
    "            \n",
    "            if rnt == 'test':\n",
    "                s = s.replace('--subskip_fit 8','')\n",
    "\n",
    "            if s in runstrings_per_rnt[rnt]:\n",
    "                raise ValueError('repeat')\n",
    "            runstrings_per_rnt[rnt ] += [s]; \n",
    "            if rnt != 'test':\n",
    "                global_ind += 1            \n",
    "        #runstrings += runstrings_per_rnt['normal' ]\n",
    "        \n",
    "    runstrings += runstrings_per_rnt['normal' ]\n",
    "    \n",
    "if n_testrunstr_to_include > 0:\n",
    "    runstrings = runstrings_per_rnt['test'][:n_testrunstr_to_include] + runstrings\n",
    "\n",
    "srs = set(runstrings)\n",
    "assert len(srs) == len(runstrings),  f'there are repeating runstrings {len(srs)} , {len(runstrings)}'\n",
    "assert len(runstrings), 'Got zero runstrings'\n",
    "\n",
    "####################\n",
    "        \n",
    "from os.path import join as pjoin\n",
    "import json\n",
    "\n",
    "if save:\n",
    "    fname_full_runstr = pjoin(gv.code_dir, 'run', fname_runstr)\n",
    "    with open( fname_full_runstr, 'w' ) as f:\n",
    "        for s in runstrings:\n",
    "            f.write(s + '\\n')\n",
    "    fname_full_runstr_archive = pjoin(gv.code_dir, 'run', f'__{fname_runstr[:-4]}_{run_corresp_id}.json')\n",
    "    with open( fname_full_runstr, 'w' ) as f:\n",
    "        for s in runstrings:\n",
    "            f.write(s + '\\n')\n",
    "            \n",
    "    print(fname_full_runstr)\n",
    "    print(fname_full_runstr_archive)\n",
    "\n",
    "c = {'correspondance':pref2pgn, 'prefixes_types':prefixes_types, \n",
    "         'param_dir_str':pfstr_per_rnt ['normal'], 'rawnames_list':rawnames_list,\n",
    "        'comment':comment, 'runpars':runpars, 'runstrings':runstrings}\n",
    "if save:\n",
    "    fn = pjoin(gv.code_dir, 'run', f'___run_corresp_{run_corresp_id}.txt')    \n",
    "    with open(fn , 'w' ) as f:\n",
    "        json.dump(c, f, indent =2)\n",
    "#     f.write(json.dumps(pref2pgn))\n",
    "\n",
    "    print(fn)\n",
    "    print(f'Saved res for run_corresp_id = {run_corresp_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f00238",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(runstrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7602241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "runstrings_per_rnt['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ccb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_it_str,rawstr,tpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32ef24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vi numbers\n",
    "110 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35944d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_per_substrings = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082fbf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_per_substrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e809aed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len( runstrings_per_rnt['normal'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5ece5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = map(int, ','.join( list( inds_per_substrings.values() ) ).split(',') )\n",
    "mr = list(mr)\n",
    "mr_ext = mr[:]\n",
    "for m in mr:\n",
    "    m2 = m + maxjobs\n",
    "    if m < maxjobs and m2 not in mr_ext:\n",
    "        mr_ext += [m2]\n",
    "not_submitted = list(sorted(  set(range(len(runstrings) ) ) - set(mr_ext)  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005add7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mr_ext), len(mr), len(runstrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7b87e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (','.join( map(str,not_submitted) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f836bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#16:26\n",
    "#substrings = ['_disjoint', '--mods LFP ' ] #, 'S04']\n",
    "#substrings = ['_semidisjoint', '--mods LFP ' ] #, 'S04']\n",
    "#substrings = ['_disjoint', '--mods LFP,msrc ' ] #, 'S04']\n",
    "substrings = ['_semidisjoint', '--mods LFP,msrc ' ] #, 'S04']\n",
    "inds = []\n",
    "maxjobs = 256\n",
    "small_inds_only = False\n",
    "for rsi,rs in enumerate(runstrings):\n",
    "    if rsi == 0:  # test index\n",
    "        continue\n",
    "    found_all = True\n",
    "    for ss in substrings:\n",
    "        if rs.find(ss) < 0:\n",
    "            found_all = False\n",
    "            break\n",
    "    if found_all:\n",
    "        if rsi > maxjobs and small_inds_only:\n",
    "            rsi = rsi % maxjobs\n",
    "        inds += [rsi]\n",
    "uinds = sorted(set(inds) )\n",
    "print( len( uinds) )\n",
    "runstrings_subsel = np.array(runstrings)[inds].tolist()\n",
    "s = ','.join( map(str,uinds  ) )\n",
    "inds_per_substrings[tuple(substrings)] = s\n",
    "print(s)\n",
    "display( runstrings_subsel  )\n",
    "#[i for i in range(len(runstrings)) if runstrings[i].find('_disjoint') >= 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cbf0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "runstrings_per_rnt['test'][:n_testrunstr_to_include]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe43e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.histogram(runstrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84c22a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "runstrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fd08b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eb7406",
   "metadata": {},
   "source": [
    "## find inds to recalc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e56c9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_recalc = [('S07_on', 'OccipitalMid')]\n",
    "#to_recalc += [('S01_off', 'SupraMarginal')]\n",
    "to_recalc = [('S01_off', 'SupraMarginal')]\n",
    "to_recalc += [('S01_off',   'onlyH_act_LFPand_only13') ]# 'onlyH_act_LFPand_only13')]\n",
    "#'S01_off': {'onlyH_act_LFPand_only13'}\n",
    "to_recalc = [('S02_on',   'onlyH_act_only15') ]\n",
    "\n",
    "rsis = []\n",
    "for rn,name in to_recalc:\n",
    "    key_founds = []\n",
    "    for key,item in pref2pgn.items():\n",
    "        if item[1] == name:\n",
    "            key_founds += [key]\n",
    "    if not len(key_founds) and (name in pref2pgn):\n",
    "        key_founds = [name]\n",
    "        roi = pref2pgn[name][1]\n",
    "    else:\n",
    "        roi = name\n",
    "    print('key_founds = ', key_founds)\n",
    "        \n",
    "    for rsi,rs in enumerate(runstrings):\n",
    "        if rs.find('_test') >= 0 or rs.find('_fast') >= 0:\n",
    "            continue\n",
    "        items = rs.split()\n",
    "        a = items[1::2]\n",
    "        b = items[2::2]\n",
    "        d = dict( zip(a,b) )\n",
    "        \n",
    "        c1 = d['-r'].find(rn) >= 0 \n",
    "        c2 = d['--prefix'] in key_founds\n",
    "        \n",
    "        if c1 and c2:\n",
    "            rsis += [rsi]\n",
    "            print(f'{rsi:4} = {rn} : {roi:18} -> {d[\"--prefix\"]}')\n",
    "            #print(rsi)\n",
    "            \n",
    "rsis = list(sorted(set(rsis)))\n",
    "print('\\nto be given to sbatch: ', rsis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3ec847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e09eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e7d5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pref2pgn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6e4dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pref2pgn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90766197",
   "metadata": {},
   "outputs": [],
   "source": [
    "runpars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad62727",
   "metadata": {},
   "outputs": [],
   "source": [
    "pref2pgn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e69f81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prefixes_types, pfstr_per_rnt ['normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e22a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "runstrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af4b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pref2pgn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2f90a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_globinds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbab422",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(runstrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c238bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#special_globinds_mod = special_globinds\n",
    "special_globinds_mod = [gi + n_testrunstr_to_include for gi in special_globinds]\n",
    "#[runstrings[gi][120:-93] for gi in special_globinds_mod]\n",
    "runstrings_sub = [runstrings[gi] for gi in special_globinds_mod]\n",
    "display( runstrings_sub )\n",
    "#special_globinds_mod\n",
    "print( ','.join(map(str,special_globinds_mod) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e45bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(runstrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e637094",
   "metadata": {},
   "outputs": [],
   "source": [
    "sis = []\n",
    "for rsi,rs in enumerate(runstrings):\n",
    "    #if rs.find('--mods LFP') >= 0:\n",
    "    if rs.find('15') >= 0:\n",
    "        sis += [rsi]\n",
    "        print(rs)\n",
    "print( ','.join(map(str,sis) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d513a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "corresp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de14e7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b6af71",
   "metadata": {},
   "outputs": [],
   "source": [
    "runstrings_per_rnt['test' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48317c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "runstrings_per_rnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ed2d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gv.data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896cd42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f2fe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pref2pgn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ef4c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8a1718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae592ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "runstrings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefc2479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3921962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1d1b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dddb865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cobd",
   "language": "python",
   "name": "cobd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
