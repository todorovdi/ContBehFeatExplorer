{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444beac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46022808",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import globvars as gv\n",
    "import utils\n",
    "import utils_tSNE as utsne\n",
    "import utils_preproc as upre\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import mne\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import multiprocessing as mpr\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "import gc;\n",
    "import scipy.signal as sig\n",
    "import pandas as pd \n",
    "\n",
    "import numpy as np\n",
    "import utils_postprocess_HPC as postp\n",
    "import pymatreader\n",
    "\n",
    "data_dir = gv.data_dir\n",
    "from os.path import join as pjoin\n",
    "\n",
    "light_only = True\n",
    "\n",
    "from dateutil import parser\n",
    "#start_time = parser.parse(\"19 Aug 2021 03:05:15\")\n",
    "#start_time = parser.parse(\"14 April 2022 10:05:15\")\n",
    "#start_time = parser.parse(\"20 April 2022 10:05:15\")\n",
    "start_time = parser.parse(\"22 April 2022 17:11:15\")  #2022, 4, 22, 17, 12, 27, 37491)\n",
    "end_time = parser.parse(\"19 Aug 2031 21:21:45\")\n",
    "#end_time = parser.parse(\"19 Aug 2021 03:41:45\") # this one is just to make things faster\n",
    "ndaysBefore = None\n",
    "#subdir = 'nointerp'\n",
    "#subdir = 'nofeatsel'\n",
    "#subdir = 'searchLFP'\n",
    "#subdir = 'searchLFP_both_sides'\n",
    "subdir = 'searchLFP_both_sides_oversample2'\n",
    "lookup_dir = pjoin(gv.data_dir,subdir)\n",
    "recent = postp.listRecent(days=ndaysBefore, lookup_dir= lookup_dir,\n",
    "                          start_time=start_time, end_time=end_time)\n",
    "subjs = []\n",
    "print(f'Found {len(recent)} recent files')\n",
    "for lf in recent:\n",
    "    st = 0\n",
    "    if light_only:\n",
    "        if not lf.startswith('_!'):\n",
    "            continue\n",
    "        st = 2\n",
    "    subjs += [lf[st+1:st+4]]\n",
    "subjs = list(sorted(set(subjs)))\n",
    "print(subjs)\n",
    "\n",
    "import utils_postprocess_HPC as postp\n",
    "#Earliest file 19 Aug 2021 03:05:15, latest file 19 Aug 2021 21:21:45\n",
    "prefixes = postp.listRecentPrefixes(days = ndaysBefore, light_only=light_only, \n",
    "                                    lookup_dir= lookup_dir,\n",
    "                                   start_time=start_time, end_time=end_time)\n",
    "display(prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b96047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_postprocess_HPC import checkPrefixCollectionConsistencty\n",
    "ignore_missing = False\n",
    "for  grouping_to_check in ['merge_nothing', 'merge_movements']:\n",
    "    #grouping_to_check= 'merge_nothing'\n",
    "    it_to_check = 'basic'\n",
    "\n",
    "    r = checkPrefixCollectionConsistencty(subdir,prefixes,start_time, end_time,\n",
    "                                        grouping_to_check, it_to_check,\n",
    "                                        use_main_LFP_chan=0, light_only=1,\n",
    "                                        prefixes_ignore  = [], preloaded=None)\n",
    "    missing, preloaded = r\n",
    "    import gc; gc.collect()\n",
    "    if missing is None:\n",
    "        continue\n",
    "    print(missing)\n",
    "    if max( [len(m) for m in missing.values()] ) != 0 and not ignore_missing:\n",
    "        raise ValueError('something is missing')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c89a24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes_to_load = prefixes\n",
    "sources_type = 'parcel_aal'  # or ''\n",
    "r = postp.collectPerformanceInfo3(subjs,prefixes_to_load, nraws_used='[0-9]+',   \n",
    "    start_time=start_time, end_time=end_time, use_main_LFP_chan=0,\n",
    "    ndays_before=None, sources_type = sources_type, printFilenames=1,\n",
    "    subdir=subdir, remove_large_items = 1,\n",
    "    list_only=0, allow_multi_fn_same_prefix=0,\n",
    "    use_light_files = light_only, rawname_regex_full=0)\n",
    "#output_per_raw,Ximp_per_raw,gis_per_raw = r\n",
    "output_per_raw,_,_ = r\n",
    "print('len(output_per_raw) =', len(output_per_raw))\n",
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcde644",
   "metadata": {
    "code_folding": [
     9
    ]
   },
   "outputs": [],
   "source": [
    "import utils_postprocess as pp\n",
    "from datetime import datetime\n",
    "from utils_postprocess_HPC import loadRunCorresp\n",
    "from utils_postprocess import printDict\n",
    "#\n",
    "update_outputs = False\n",
    "#\n",
    "tpll = pp.multiLevelDict2TupleList(output_per_raw,4,3)\n",
    "CIDs,cretimes = [],[]\n",
    "for tpl in tpll:\n",
    "    moc = tpl[-1]\n",
    "    corresp,all_info = loadRunCorresp(moc)\n",
    "    runCID = dict( moc['cmd'][0] ).get('--runCID', None) \n",
    "    moc['runstrings_creation_time'] = all_info['date_created']\n",
    "    moc['runCID'] = runCID\n",
    "    CIDs += [runCID]\n",
    "    cretimes += [all_info['date_created']]\n",
    "    \n",
    "    mod_time = os.stat( moc['filename_full'] ).st_mtime\n",
    "    dt = datetime.fromtimestamp(mod_time)\n",
    "    moc['fname_mod_time'] = dt\n",
    "\n",
    "CIDs = list( map(int,CIDs) ) \n",
    "CIDs_sorted = list( sorted( set( map(int,CIDs) ) ) )\n",
    "print('CIDs_sorted=', CIDs_sorted )\n",
    "    \n",
    "\n",
    "if len(CIDs_sorted) > 1:\n",
    "    for CID in CIDs_sorted:\n",
    "        print(CID, sum( np.array(CIDs) == CID) )\n",
    "    CID_most_recent = list( sorted( map(int,CIDs) ) )[-1]\n",
    "    print('most recent', CID_most_recent )\n",
    "\n",
    "    desired_CIDs = [CID_most_recent]\n",
    "    newtpll = []\n",
    "    for tpl in tpll:\n",
    "        moc = tpl[-1]\n",
    "        #print(moc['runCID'])\n",
    "        if int(moc['runCID']) in desired_CIDs:\n",
    "            newtpll += [tpl]\n",
    "\n",
    "    from utils_postprocess_HPC import tupleList2multiLevelDict\n",
    "    d = tupleList2multiLevelDict(newtpll)\n",
    "    \n",
    "    # THIS IS IRREVERSIBLE WHEN RAN TWICE\n",
    "    if update_outputs:\n",
    "        output_per_raw_notflt = output_per_raw\n",
    "        output_per_raw_flt = d\n",
    "        output_per_raw = output_per_raw_flt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f3b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_postprocess_HPC import getOutputSetInfo\n",
    "from utils_postprocess_HPC import checkPrefixCollectionConsistencty\n",
    "rawnames_found, groupings_found, its_found, prefixes_found = getOutputSetInfo( output_per_raw )\n",
    "#output_per_raw.keys()\n",
    "#tpll = pp.multiLevelDict2TupleList(output_per_raw,4,3)\n",
    "preloaded = output_per_raw\n",
    "#preloaded = output_per_raw\n",
    "for grouping_to_check in groupings_found:\n",
    "    print('   ',grouping_to_check)\n",
    "    #grouping_to_check= 'merge_nothing'\n",
    "    it_to_check = 'basic'\n",
    "    r = checkPrefixCollectionConsistencty(subdir,prefixes,start_time, end_time,  \n",
    "                                          grouping_to_check, it_to_check,\n",
    "                                          use_main_LFP_chan=1, light_only=1, \n",
    "                                         prefixes_ignore  = [], preloaded=preloaded)\n",
    "    missing, _ = r\n",
    "    print(missing)\n",
    "#     if max( [len(m) for m in missing.values()] ) != 0 and not ignore_missing:\n",
    "#         raise ValueError('something is missing')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3026c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename when needed\n",
    "change_keys = False\n",
    "if change_keys:\n",
    "    from utils_preproc import getRawnameListStructure\n",
    "    # force rename keys outside the function (doing it inside would complicate it too much)\n",
    "    newkeys = []\n",
    "    ordered = list(output_per_raw.items())\n",
    "    vals = []\n",
    "    #%debug\n",
    "    for rawkey,vv in ordered:\n",
    "        rawnames_cur = rawkey.split(',')\n",
    "        subjs_analyzed, subjs_analyzed_glob = \\\n",
    "            getRawnameListStructure(rawnames_cur, ret_glob=True)\n",
    "        sl = subjs_analyzed_glob['subject_list']\n",
    "        mcl = list( subjs_analyzed_glob['per_medcond'].keys() )\n",
    "        assert len(sl) == 1\n",
    "        newkey = f'{sl[0]}'\n",
    "    #     if len(mcl) == 1:\n",
    "    #         newkey = f'{sl[0]}_{mcl[0]}'\n",
    "    #     elif len(rawnames_cur) == 4 or (len(rawnames_cur) == 2 and sl[0] == 'S03'):\n",
    "    #         newkey = f'{sl[0]}'\n",
    "        newkeys += [newkey]\n",
    "        vals += [vv]\n",
    "\n",
    "    output_per_raw = dict(zip(newkeys,vals))\n",
    "\n",
    "# import utils_postprocess as pp\n",
    "# pp.printDict(output_per_raw,max_depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4858c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "for tpl in newtpll:\n",
    "    times += [tpl[-1]['fname_mod_time']]\n",
    "min(times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a33fef",
   "metadata": {},
   "source": [
    "# Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db0b2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #gv.gen_subj_info[subj].get('move_side',None)\n",
    "# #help(utsne.selFeatsRegex)\n",
    "# chnames_LFP_contralat_to_move\n",
    "# cdk\n",
    "# mult_clf_output['best_LFP']['XGB']['perf_drop']\n",
    "\n",
    "#[n for n in list(mult_clf_output.keys()) if n.find('name') >= 0]\n",
    "\n",
    "#mult_clf_output['filename_full']\n",
    "\n",
    "#[tpl[-1] for tpl in outputs_grouped_tpll]\n",
    "\n",
    "#mult_clf_output['class_labels_good_for_classif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1cf54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_postprocess as pp\n",
    "import json\n",
    "save_result = False\n",
    "outputs_grouped_tpll = pp.multiLevelDict2TupleList(output_per_raw,4,3)\n",
    "\n",
    "cpd = 'sens,spec,F1'\n",
    "metrics = ['balanced_accuracy', cpd, 'sens', 'spec']\n",
    "from utils_tSNE import selBestLFP\n",
    "\n",
    "def extractPerf(p,metric_cur):\n",
    "    if metric_cur == cpd:\n",
    "        v = np.array( p['sens'],p['spec'] ) \n",
    "    else:\n",
    "        v = np.array( p[metric_cur] )\n",
    "    return (v*100).tolist()\n",
    "    \n",
    "best_LFP_dict = {}\n",
    "for tpl in outputs_grouped_tpll:\n",
    "    subj, prefix, grp, int_type, mult_clf_output = tpl\n",
    "    pd0 = mult_clf_output['best_LFP']['XGB']['perf_drop']['only']\n",
    "    chnames_LFP = list( pd0.keys() )\n",
    "    if not chnames_LFP[0].startswith('LFP'):\n",
    "        pd0 = list(pd0.values())[0].keys()\n",
    "        chnames_LFP = list( pd0.keys() )\n",
    "    \n",
    "    cdk = ','.join([prefix,grp,int_type])\n",
    "    if subj not in best_LFP_dict:\n",
    "        best_LFP_dict[subj]= {}\n",
    "    best_LFP_dict[subj][cdk] = {}\n",
    "    \n",
    "    mainmoveside_cur = gv.gen_subj_info[subj].get('move_side',None)\n",
    "    movesidelet = mainmoveside_cur[0].upper()\n",
    "    \n",
    "    contralat_to_move_sidelet = utils.getOppositeSideStr( movesidelet )\n",
    "    _,chnames_LFP_contralat_to_move = utsne.selFeatsRegex(None,chnames_LFP,[f'LFP{contralat_to_move_sidelet}'])\n",
    "    \n",
    "    d = {}\n",
    "    for metric in metrics:    \n",
    "        print(f'   metric = {metric}')\n",
    "        d[metric] ={}\n",
    "        d[metric + '_shuffled'] = {}\n",
    "        \n",
    "        #if isinstance(subj,tuple):\n",
    "        #    subj = subj[0]\n",
    "        #kk, mult_clf_output = tpl\n",
    "        #print(kk)\n",
    "        #(prefix,grp,int_type) = kk\n",
    "        #for clf_type in ['LDA','XGB']:\n",
    "        #chnames_LFP_controlat_to_move\n",
    "        pdrop_cl,winning_chan_cl = selBestLFP(mult_clf_output, 'XGB', chnames_LFP=chnames_LFP_contralat_to_move, \n",
    "                                              metric=metric, verbose=0)\n",
    "        d[metric]['best_LFP_contralat_to_move']      = winning_chan_cl\n",
    "        \n",
    "        pdrop,winning_chan = selBestLFP(mult_clf_output, 'XGB', chnames_LFP=chnames_LFP, metric=metric, verbose=1)\n",
    "        best_LFP = winning_chan\n",
    "        #pd = dict( [(chn, (100*a).tolist()) for chn,a in list( pdrop.items() )] )\n",
    "        d[metric]['best_LFP']      = best_LFP\n",
    "        d[metric]['perf_drop_pct'] = pdrop\n",
    "\n",
    "        # save actual values as well\n",
    "        kn = f'all_present_features'\n",
    "        perf_aver = mult_clf_output['XGB_analysis_versions'][kn]['perf_dict']['perf_aver']\n",
    "        d[metric][kn] = extractPerf(perf_aver,metric)\n",
    "        perf_all_feats = d[metric][kn]\n",
    "        \n",
    "        perf_shuffled = mult_clf_output['XGB_analysis_versions'][kn]['perf_dict']['fold_type_shuffled'][-1]\n",
    "        d[metric + '_shuffled'][kn ] = extractPerf(perf_shuffled,metric)\n",
    "        \n",
    "        for chn in chnames_LFP:\n",
    "            kn = f'all_present_features_only_{chn}'\n",
    "            perf_aver = mult_clf_output['XGB_analysis_versions'][kn]['perf_dict']['perf_aver']\n",
    "            d[metric][kn] = extractPerf(perf_aver,metric)\n",
    "            \n",
    "            perf_shuffled = mult_clf_output['XGB_analysis_versions'][kn]['perf_dict']['fold_type_shuffled'][-1]\n",
    "            d[metric + '_shuffled'][kn ] = extractPerf(perf_shuffled,metric)\n",
    "\n",
    "        for chn in chnames_LFP:\n",
    "            kn = f'all_present_features_but_{chn}'\n",
    "            perf_aver = mult_clf_output['XGB_analysis_versions'][kn]['perf_dict']['perf_aver']\n",
    "            d[metric][kn] = extractPerf(perf_aver,metric)\n",
    "            \n",
    "            perf_shuffled = mult_clf_output['XGB_analysis_versions'][kn]['perf_dict']['fold_type_shuffled'][-1]\n",
    "            d[metric + '_shuffled'][kn ] = extractPerf(perf_shuffled,metric)\n",
    "            \n",
    "            dif = np.max( np.abs( np.array(perf_all_feats) - np.array(d[metric][kn] ) ) )\n",
    "            if dif > 5:\n",
    "                print(tpl[:-1],metric,'but',chn,dif)\n",
    "            \n",
    "        d['total_num_feats'] = len( mult_clf_output['featnames_for_fit'] )\n",
    "        d['total_num_datapoints'] = len( mult_clf_output['class_labels_good_for_classif'] )\n",
    "        d['runCID'] = mult_clf_output['runCID']\n",
    "        d['fname_mod_time'] = mult_clf_output['fname_mod_time'].strftime(\"%d %b %Y %H:%M\")\n",
    "\n",
    "        best_LFP_dict[subj][cdk] = d\n",
    "        #if subj in best_LFP_dict:\n",
    "        #    \n",
    "        #else:\n",
    "        #    best_LFP_dict[subj] = d\n",
    "\n",
    "        print(subj,prefix,f'true best={best_LFP}, best_cl={winning_chan_cl}, in paper={gv.gen_subj_info[subj][\"lfpchan_used_in_paper\"] }')        \n",
    "#json.dumps(best_LFP_dict)\n",
    "#gv.code_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0badf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result = 1\n",
    "fname_full = pjoin(gv.data_dir, subdir, f'best_LFP_info_both_sides_ext.json')\n",
    "print(fname_full)\n",
    "if save_result:\n",
    "    #fname = pjoin(gv.data_dir, subdir, f'best_LFP_info_both_sides.json')\n",
    "    with open(fname_full, 'w') as f:\n",
    "        json.dump(best_LFP_dict, f)\n",
    "    import subprocess as sp\n",
    "    r = sp.getoutput(f'python -m json.tool {fname_full}') \n",
    "    with open(fname_full,'w') as f:\n",
    "        f.write(r)\n",
    "    #print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaa9bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbd7e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#r[:2000].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911db1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_LFP_dict[subj].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d148d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = best_LFP_dict[subj]['modLFP_onlyH_act_brainright_disjoint,merge_nothing,basic'][metric]['best_LFP']\n",
    "# 53 KeyError: 'modLFP_onlyH_act_brainright_disjoint,merge_nothing,basic'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec654817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "dt = datetime.datetime.now()\n",
    "dt.strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00523ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bcbff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_postprocess import getBestLFP_clToMove\n",
    "getBestLFP_clToMove(best_LFP_dict,subj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4be57da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to have easy to use cl to move best LFP\n",
    "for subj,vals in best_LFP_dict.items():\n",
    "    ks = list( vals.keys() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab66ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'_postproc','modLFP_onlyH_act_*_disjoint,merge_movements,basic'\n",
    "\n",
    "brainright_exCB\n",
    "\n",
    "best_LFP_dict[subj]['modLFP_onlyH_act_brainright_exCB_disjoint,merge_movements,basic']['balanced_accuracy']['best_LFP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c85c459",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = pjoin(gv.data_dir, 'best_LFP_info.json')\n",
    "with open(fname, 'r') as f:\n",
    "    jl = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50113b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc1092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jl['S01']['modLFP,merge_movements,basic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c38bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "jl['S02']['modLFP,merge_movements,basic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0231c07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for kk in jl['S01'].keys():\n",
    "    print(kk.split(',')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550b4520",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_thrs = mult_clf_output['feat_variance_q_thr']\n",
    "#thr0,thr1,thr2='0.6','0.75','0.9'\n",
    "thr0,thr1,thr2='0.87','0.92','0.99'\n",
    "\n",
    "all_LDA =  []\n",
    "all_XGB = ['all_present_features', \n",
    "           'best_LFP']\n",
    "\n",
    "\n",
    "perf_to_use_list = []\n",
    "if len(all_LDA):\n",
    "    for v in all_LDA[1:]:\n",
    "        perf_to_use_list += [('LDA',all_LDA[0],v)]\n",
    "for v in all_XGB[1:]:\n",
    "    perf_to_use_list += [('XGB',all_XGB[0],v)]\n",
    "\n",
    "###########################################\n",
    "display(perf_to_use_list)\n",
    "\n",
    "to_show = [('allsep','merge_nothing','basic'), ('trem_vs_all','merge_all_not_trem','basic'),\n",
    "        ('trem_vs_2class','merge_movements','basic')]\n",
    "to_show = [('trem_vs_2class','merge_movements','basic')]\n",
    "\n",
    "\n",
    "# warnings.simplefilter('error')\n",
    "# table_info_per_perf_type, table_per_perf_type = \\\n",
    "#     postp.prepTableInfo2(output_per_raw, prefixes=prefixes, \n",
    "#     perf_to_use_list=perf_to_use_list)\n",
    "\n",
    "#%debug\n",
    "# import warnings\n",
    "# with warnings.catch_warnings():\n",
    "#warnings.simplefilter('error')\n",
    "table_info_per_perf_type, table_per_perf_type = \\\n",
    "    postp.prepTableInfo3(output_per_raw, prefixes=prefixes, \n",
    "    perf_to_use_list=perf_to_use_list, to_show=to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac1d011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e366c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dumps(best_LFP_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perf_tuple = perf_to_use_list[0]\n",
    "#%debug\n",
    "#for perf_tuple in perf_to_use_list[:1]:\n",
    "for perf_tuple in perf_to_use_list:\n",
    "    print(perf_tuple)\n",
    "    postp.plotTableInfos2(table_info_per_perf_type, perf_tuple=perf_tuple, \n",
    "                          output_subdir=subdir) \n",
    "    plt.close()\n",
    "    import gc;gc.collect()\n",
    "#postp.plotTableInfos2(table_info_per_perf_type, perf_kind='LDA', keys = None, output_subdir=''): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe5d588",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(plt.suptitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d137273",
   "metadata": {},
   "outputs": [],
   "source": [
    "rncur = 'S01_off_hold'\n",
    "sind_str,mc,tk  = utils.getParamsFromRawname(rncur)\n",
    "sources_type='parcel_aal'\n",
    "src_file_grouping_ind = 10\n",
    "src_rec_info_fn = '{}_{}_grp{}_src_rec_info'.format(rncur,\n",
    "                                                    sources_type,src_file_grouping_ind)\n",
    "src_rec_info_fn_full = os.path.join(gv.data_dir, src_rec_info_fn + '.npz')\n",
    "rec_info = np.load(src_rec_info_fn_full, allow_pickle=True)\n",
    "\n",
    "\n",
    "print( list(rec_info.keys()) )\n",
    "\n",
    "labels_dict = rec_info['label_groups_dict'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe897e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_postprocess as pp\n",
    "\n",
    "prefixes_to_use = ['cross_freqmod_beta,gamma:HFO']\n",
    "prefixes_to_use = ['LFPrel_noself']\n",
    "#for prefix_cur in list(sorted( set(prefixes) - set(['all']) )):\n",
    "#for prefix_cur in ['cross_freqmod_beta,gamma:HFO']:\n",
    "#for prefix_cur in [ 'LFPrel_noself']:\n",
    "for prefix_cur in [ 'onlyH']:\n",
    "    prefixes_to_use = [prefix_cur]\n",
    "\n",
    "    outputs_grouped = pp.groupOutputs(output_per_raw, prefixes_to_use,['merge_movements'],['basic'])\n",
    "    #pp.printDict(outputs_grouped,1,print_leaves=1)\n",
    "\n",
    "\n",
    "    use_light_file = 1\n",
    "    perf_thr = 0.7\n",
    "\n",
    "    rname_crop = slice(0,3)\n",
    "\n",
    "    #(prefix,grp,int_type), output = u\n",
    "    print(f'Starting plotting for {len(outputs_grouped)} grouped outputs')\n",
    "    info_cur = {}\n",
    "    #sens,spec = res[rn].get(pref, (np.nan, np.nan))\n",
    "    (prefix,grp,int_type), mult_clf_output = list(outputs_grouped.values())[0]\n",
    "\n",
    "    output_subdir = ''\n",
    "    rnstr = ';'.join( list( outputs_grouped.values() )[0][0] )\n",
    "    out_name_plot = f'{\",\".join((prefix,grp,int_type) ) }_feat_signif'        \n",
    "    #chnames_LFP = ['LFPR01', 'LFPR12', 'LFPR23']\n",
    "\n",
    "    str_to_put_ = ''\n",
    "    #     pvec = mult_clf_output['XGB_analysis_versions']['all_present_features']['perf_dict']['perf_aver']\n",
    "    #     sens,spec,F1 = pvec\n",
    "    #     str_to_put_ =  '{:.0f}%,{:.0f}%,{:.0f}%'.format(100*pvec[0],100*pvec[1],100*pvec[2])\n",
    "    #     if min(sens,spec) < perf_thr:\n",
    "    #         print('  Skipping due to low perf ',str_to_put_)\n",
    "    #         continue\n",
    "    #hh = int( 20 * len(featnames) / 270  ), \n",
    "    #%debug\n",
    "\n",
    "    #outputs_grouped   # \n",
    "    #(prefix,grp,int_type), mult_clf_output = output_list[0]\n",
    "    #%debug\n",
    "    from matplotlib.backends.backend_pdf import PdfPages\n",
    "    try:\n",
    "        pdf= PdfPages(pjoin(gv.dir_fig, subdir, out_name_plot + '.pdf' ))    \n",
    "        postp.plotFeatSignifSHAP_list(pdf=None,\n",
    "                                 outputs_grouped=outputs_grouped, fshs='XGB_Shapley',                                  \n",
    "                                 figname_prefix=prefix, roi_labels=labels_dict['all_raw'],\n",
    "                                 body_side='left', chnames_LFP=chnames_LFP, \n",
    "                                 hh = 12, \n",
    "                                 tickfontsize = 10, markersize=8,\n",
    "                                 suptitle = str_to_put_, use_best_LFP=True,\n",
    "                                 suptitle_fontsize=20, show_bias=0, show_max = False, \n",
    "                                 show_std = False, average_over_subjects = True,\n",
    "                                 merge_Hjorth = prefix_cur != 'onlyH',alpha=0.4);                  \n",
    "\n",
    "        pdf.savefig()\n",
    "        plt.close()        \n",
    "\n",
    "        #plt.close('all')\n",
    "    except KeyError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    \n",
    "    cax,clrb = postp.plotConfmats(outputs_grouped, best_LFP=1)\n",
    "    kind = ';'.join( list( outputs_grouped.values() )[0][0] )\n",
    "    figname = ','.join( [k[0] for k in outputs_grouped.keys()] ) + f'_confmats_{kind}.pdf'\n",
    "    kind = ';  '.join( list( outputs_grouped.values() )[0][0] )\n",
    "    plt.suptitle(kind)\n",
    "    #plt.savefig( pjoin(gv.dir_fig,subdir,figname) )\n",
    "    \n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "    \n",
    "    pdf.close()\n",
    "\n",
    "#             break\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b6c095",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8972615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([np.eye(3),np.eye(3)])\n",
    "print( a.shape )\n",
    "ais = np.where(a)\n",
    "a[ais]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf0db33",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array( [np.zeros((2,2)), np.zeros((2,2))] ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4811337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[4.4,5],[4,5]]).dtype == np.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237146f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple( np.array([[4,5],[4,5]]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2eb320",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple( np.array(['fd','fds']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb754d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
