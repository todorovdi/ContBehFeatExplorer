{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0473d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b61a557",
   "metadata": {},
   "outputs": [],
   "source": [
    "searchLFP_both_sides_oversample2_LFP256_allaritf_medcondsep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096e689f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Using 4 rawnames per subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c9c68c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from utils_postprocess_HPC import collectBestLFP\n",
    "import sys,traceback\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#%debug\n",
    "\n",
    "#output_per_raw= None\n",
    "try:\n",
    "    savefile_rawname_format='subj'\n",
    "    #savefile_rawname_format = 'subj'\n",
    "    #test(100)\n",
    "    # n =searchLFP_both_sides_oversample2_LFP256_allartif\n",
    "    rr = collectBestLFP('searchLFP_both_sides_oversample2_LFP256_allaritf', \n",
    "                        save_result = 1, savefile_rawname_format=savefile_rawname_format,\n",
    "                       output_per_raw = output_per_raw);\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    exc_info = sys.exc_info()\n",
    "    exc = traceback.TracebackException(*exc_info, capture_locals=True)\n",
    "    \n",
    "    \n",
    "    stackframe = exc_info[2].tb_next.tb_frame\n",
    "    local_vars_in_fun = stackframe.f_locals\n",
    "    display(exc_info, stackframe,  exc_info[2].tb_next.tb_lineno)\n",
    "    #display(local_vars_in_fun)\n",
    "\n",
    "#r = collectBestLFP('test_searchLFP', save_result = 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3772ec25",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bld, output_per_raw = rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68506e3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bld.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008a509b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output_per_raw.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef18403e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bld.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3daae1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rr = bld\n",
    "keys = ['S07_off,on', 'S01_off,on', 'S03_off', 'S05_off,on', 'S04_off,on', 'S02_off,on']\n",
    "keys2 = [k.split('_')[0] for k in keys]; keys2\n",
    "keys_rename = dict(zip(keys,keys2) )\n",
    "rr2 = dict((keys_rename[key], value) for (key, value) in rr.items())\n",
    "#rr2.keys()\n",
    "best_LFP_dict = rr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c608288",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output_per_raw = dict((keys_rename[key], value) for (key, value) in output_per_raw.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de47c4f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# d = {'x':1, 'y':2, 'z':3}  # old\n",
    "# d1 = {'x':'a', 'y':'b', 'z':'c'}\n",
    "# dict((d1[key], value) for (key, value) in d.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c9731f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#!ls -d /p/project/icei-hbp-2020-0012/OSCBAGDIS/data_duss/sear*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40228844",
   "metadata": {},
   "source": [
    "# Using 2 rawnames per subj (so medcond-restr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b47b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_postprocess_HPC import collectBestLFP\n",
    "import sys,traceback\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#%debug\n",
    "\n",
    "#output_per_raw2 = None\n",
    "\n",
    "try:\n",
    "    #test(100)\n",
    "    # n =searchLFP_both_sides_oversample2_LFP256_allartif\n",
    "    start_time_str = \"27 January 2023 00:45:00\"\n",
    "    rrr = collectBestLFP('searchLFP_both_sides_oversample2_LFP256_allaritf_medcondsep', \n",
    "                        save_result = 1, savefile_rawname_format='subj,medcond_glob',\n",
    "                        start_time_str = start_time_str, output_per_raw = output_per_raw2);\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    exc_info = sys.exc_info()\n",
    "    exc = traceback.TracebackException(*exc_info, capture_locals=True)\n",
    "    \n",
    "    \n",
    "    stackframe = exc_info[2].tb_next.tb_frame\n",
    "    local_vars_in_fun = stackframe.f_locals\n",
    "    display(exc_info, stackframe,  exc_info[2].tb_next.tb_lineno)\n",
    "    #display(local_vars_in_fun)\n",
    "\n",
    "#r = collectBestLFP('test_searchLFP', save_result = 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e27e163",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Basic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afadce5b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bld2, output_per_raw2 = rrr\n",
    "\n",
    "from utils_postprocess_HPC import multiLevelDict2TupleList,prepTableInfo3\n",
    "\n",
    "opr = output_per_raw2\n",
    "outputs_grouped_tpll = multiLevelDict2TupleList(opr,4,3)\n",
    "outputs_grouped_tpll[0][:-1]\n",
    "dfunproc = pd.DataFrame(outputs_grouped_tpll, \n",
    "    columns = ['rawname','prefix','grouping','interval_set','mcf'] )\n",
    "prefixes = list( dfunproc['prefix'].unique() )\n",
    "\n",
    "perf_to_use_list = [('XGB','all_present_features', f'best_PCA-derived_features_0.99')]\n",
    "\n",
    "to_show = []\n",
    "to_show += [('allsep','merge_nothing','basic') ]\n",
    "to_show += [('trem_vs_2class','merge_movements','basic')]\n",
    "to_show += [('trem_vs_all','merge_all_not_trem','basic')]\n",
    "to_show += [('trem_vs_quiet','merge_nothing','trem_vs_quiet') ]\n",
    "\n",
    "# warnings.simplefilter('error')\n",
    "df, table_info_per_perf_type, table_per_perf_type = \\\n",
    "    prepTableInfo3(opr, prefixes=prefixes, \n",
    "    perf_to_use_list=perf_to_use_list, to_show=to_show, return_df = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca85351",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import gc; gc.collect()\n",
    "from utils_postprocess_HPC import extendDf\n",
    "\n",
    "df = extendDf(df, opr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbcf49c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "use_prefix = False\n",
    "#dfsub = df[['rawname','prefix','prefix_templ', 'num','numpts','bacc','bacc_shuffled']]\n",
    "dfsub = df[['rawname','grouping','interval_set',\n",
    "            'prefix','prefix_templ', 'num','numpts','bacc','bacc_shuffled','sens','spec',\n",
    "           'tremor_det_perf']]\n",
    "\n",
    "prefs_to_compare = ['onlyH_subskip8','onlyH_act_subskip8','onlyH_mob_subskip8','onlyH_compl_subskip8','allb_beta_noH_subskip8','allb_gamma_noH_subskip8','allb_tremor_noH_subskip8',\n",
    "        'LFPrel_noself_subskip8','modSrc_self_subskip8','modSrc_subskip8','modLFP_subskip8']\n",
    "\n",
    "if use_prefix:\n",
    "    prefs_to_compare = ['onlyH_subskip8','onlyH_act_subskip8',\n",
    "                        'onlyH_mob_subskip8','onlyH_compl_subskip8']\n",
    "    prefix_role = 'prefix'\n",
    "else:\n",
    "    pref_templs_to_compare = ['onlyH_subskip8%%','onlyH_act_subskip8%%',\n",
    "                        'onlyH_mob_subskip8%%','onlyH_compl_subskip8%%',\n",
    "                             'onlyH_modLFP_subskip8%%']\n",
    "    prefix_role = 'prefix_templ'\n",
    "\n",
    "dfsub2 = dfsub[ dfsub[prefix_role].isin(pref_templs_to_compare) ]\n",
    "\n",
    "#dfsub2 = dfsub2[ (dfsub2['grouping'] == grp) & (dfsub2['interval_set'] == it) ]\n",
    "grp =  dfsub2.groupby( by=[ prefix_role,'grouping','interval_set'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a2f151",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prefixes = list( df['prefix'].unique() )\n",
    "prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d437bca2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c690ee6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfsub_ = df.query('rawname == \"S05_off\"')\n",
    "dfsub_= dfsub_[dfsub_['prefix'].str.endswith('_disjoint')]\n",
    "#[['rawname', 'grouping', 'interval_set', 'prefix','prefix_templ', 'numpts']]\n",
    "grpiset = dfsub_.groupby('interval_set')\n",
    "display(grpiset.size())\n",
    "grprnstd = grpiset.std().reset_index()\n",
    "grprnstd[[ 'interval_set', 'numpts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fb6edd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.query('subject == [S01]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9eb950",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#grprn = dfsub.groupby( by=['rawname', 'interval_set'] )\n",
    "#dfsub3 = dfsub[dfsub['prefix'].str.startswith('onlyH_act_only11') |\\\n",
    "#               dfsub['prefix'].str.startswith('onlyH_act_only12')]\n",
    "grprn = dfsub.groupby( by=[ 'rawname', 'grouping','interval_set'] )\n",
    "grprnstd = grprn.std()\n",
    "#grprnmn = grprn.mean()\n",
    "display( grprn.size() )\n",
    "grprnstd['numpts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659df04e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bld2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de058b29",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_LFP_dict = bld2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f0264d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# manual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca32b9ea",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46022808",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import globvars as gv\n",
    "import utils\n",
    "import utils_tSNE as utsne\n",
    "import utils_preproc as upre\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import mne\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import multiprocessing as mpr\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "import gc;\n",
    "import scipy.signal as sig\n",
    "import pandas as pd \n",
    "\n",
    "import numpy as np\n",
    "import utils_postprocess_HPC as postp\n",
    "import pymatreader\n",
    "\n",
    "data_dir = gv.data_dir\n",
    "from os.path import join as pjoin\n",
    "\n",
    "light_only = True\n",
    "\n",
    "from dateutil import parser\n",
    "#start_time = parser.parse(\"19 Aug 2021 03:05:15\")\n",
    "#start_time = parser.parse(\"14 April 2022 10:05:15\")\n",
    "#start_time = parser.parse(\"20 April 2022 10:05:15\")\n",
    "start_time = parser.parse(\"22 April 2022 17:11:15\")  #2022, 4, 22, 17, 12, 27, 37491)\n",
    "end_time = parser.parse(\"19 Aug 2031 21:21:45\")\n",
    "#end_time = parser.parse(\"19 Aug 2021 03:41:45\") # this one is just to make things faster\n",
    "ndaysBefore = None\n",
    "#subdir = 'nointerp'\n",
    "#subdir = 'nofeatsel'\n",
    "#subdir = 'searchLFP'\n",
    "#subdir = 'searchLFP_both_sides'\n",
    "#subdir = 'searchLFP_both_sides_oversample2'\n",
    "subdir = 'searchLFP_both_sides_oversample2_LFP256_allaritf'\n",
    "lookup_dir = pjoin(gv.data_dir,subdir)\n",
    "recent = postp.listRecent(days=ndaysBefore, lookup_dir= lookup_dir,\n",
    "                          start_time=start_time, end_time=end_time)\n",
    "subjs = []\n",
    "print(f'Found {len(recent)} recent files')\n",
    "for lf in recent:\n",
    "    st = 0\n",
    "    if light_only:\n",
    "        if not lf.startswith('_!'):\n",
    "            continue\n",
    "        st = 2\n",
    "    subjs += [lf[st+1:st+4]]\n",
    "subjs = list(sorted(set(subjs)))\n",
    "print(subjs)\n",
    "\n",
    "import utils_postprocess_HPC as postp\n",
    "#Earliest file 19 Aug 2021 03:05:15, latest file 19 Aug 2021 21:21:45\n",
    "prefixes = postp.listRecentPrefixes(days = ndaysBefore, light_only=light_only, \n",
    "                                    lookup_dir= lookup_dir,\n",
    "                                   start_time=start_time, end_time=end_time)\n",
    "display(prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404d543a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from utils_postprocess_HPC import listComputedData\n",
    "r = listComputedData(subdir,prefixes,start_time, end_time, use_main_LFP_chan=0)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b96047",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# check consistency directly from files (before collecting)\n",
    "from utils_postprocess_HPC import checkPrefixCollectionConsistencty\n",
    "ignore_missing = False\n",
    "#for  grouping_to_check in ['merge_nothing', 'merge_movements']:\n",
    "for  grouping_to_check in ['merge_movements']:\n",
    "    #grouping_to_check= 'merge_nothing'\n",
    "    it_to_check = 'basic'\n",
    "\n",
    "    r = checkPrefixCollectionConsistencty(subdir,prefixes,start_time, end_time,\n",
    "                                        grouping_to_check, it_to_check,\n",
    "                                        use_main_LFP_chan=0, light_only=1,\n",
    "                                        prefixes_ignore  = [], preloaded=None)\n",
    "    missing, preloaded = r\n",
    "    import gc; gc.collect()\n",
    "    if missing is None:\n",
    "        continue\n",
    "    print(missing)\n",
    "    if max( [len(m) for m in missing.values()] ) != 0 and not ignore_missing:\n",
    "        raise ValueError('something is missing')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c89a24e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# here load data in memory\n",
    "prefixes_to_load = prefixes\n",
    "sources_type = 'parcel_aal'  # or ''\n",
    "r = postp.collectPerformanceInfo3(subjs,prefixes_to_load, nraws_used='[0-9]+',   \n",
    "    start_time=start_time, end_time=end_time, use_main_LFP_chan=0,\n",
    "    ndays_before=None, sources_type = sources_type, printFilenames=1,\n",
    "    subdir=subdir, remove_large_items = 1,\n",
    "    list_only=0, allow_multi_fn_same_prefix=0,\n",
    "    use_light_files = light_only, rawname_regex_full=0)\n",
    "#output_per_raw,Ximp_per_raw,gis_per_raw = r\n",
    "output_per_raw,_,_ = r\n",
    "print('len(output_per_raw) =', len(output_per_raw))\n",
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcde644",
   "metadata": {
    "code_folding": [
     9
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# check multiple runs that we might have done in order to arrive to this dataset\n",
    "import utils_postprocess as pp\n",
    "from datetime import datetime\n",
    "from utils_postprocess_HPC import loadRunCorresp\n",
    "from utils_postprocess import printDict\n",
    "#\n",
    "update_outputs = False\n",
    "#\n",
    "tpll = pp.multiLevelDict2TupleList(output_per_raw,4,3)\n",
    "CIDs,cretimes = [],[]\n",
    "for tpl in tpll:\n",
    "    moc = tpl[-1]\n",
    "    corresp,all_info = loadRunCorresp(moc)\n",
    "    runCID = dict( moc['cmd'][0] ).get('--runCID', None) \n",
    "    moc['runstrings_creation_time'] = all_info['date_created']\n",
    "    moc['runCID'] = runCID\n",
    "    CIDs += [runCID]\n",
    "    cretimes += [all_info['date_created']]\n",
    "    \n",
    "    mod_time = os.stat( moc['filename_full'] ).st_mtime\n",
    "    dt = datetime.fromtimestamp(mod_time)\n",
    "    moc['fname_mod_time'] = dt\n",
    "\n",
    "CIDs = list( map(int,CIDs) ) \n",
    "CIDs_sorted = list( sorted( set( map(int,CIDs) ) ) )\n",
    "print('CIDs_sorted=', CIDs_sorted )\n",
    "    \n",
    "\n",
    "if len(CIDs_sorted) > 1:\n",
    "    for CID in CIDs_sorted:\n",
    "        print(CID, sum( np.array(CIDs) == CID) )\n",
    "    CID_most_recent = list( sorted( map(int,CIDs) ) )[-1]\n",
    "    print('most recent', CID_most_recent )\n",
    "\n",
    "    desired_CIDs = [CID_most_recent]\n",
    "    newtpll = []\n",
    "    for tpl in tpll:\n",
    "        moc = tpl[-1]\n",
    "        #print(moc['runCID'])\n",
    "        if int(moc['runCID']) in desired_CIDs:\n",
    "            newtpll += [tpl]\n",
    "\n",
    "    from utils_postprocess_HPC import tupleList2multiLevelDict\n",
    "    d = tupleList2multiLevelDict(newtpll)\n",
    "    \n",
    "    # THIS IS IRREVERSIBLE WHEN RAN TWICE\n",
    "    if update_outputs:\n",
    "        output_per_raw_notflt = output_per_raw\n",
    "        output_per_raw_flt = d\n",
    "        output_per_raw = output_per_raw_flt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f3b29c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# check conssitency after collecting and loading\n",
    "from utils_postprocess_HPC import getOutputSetInfo\n",
    "from utils_postprocess_HPC import checkPrefixCollectionConsistencty\n",
    "rawnames_found, groupings_found, its_found, prefixes_found = getOutputSetInfo( output_per_raw )\n",
    "#output_per_raw.keys()\n",
    "#tpll = pp.multiLevelDict2TupleList(output_per_raw,4,3)\n",
    "preloaded = output_per_raw\n",
    "#preloaded = output_per_raw\n",
    "for grouping_to_check in groupings_found:\n",
    "    print('   ',grouping_to_check)\n",
    "    #grouping_to_check= 'merge_nothing'\n",
    "    it_to_check = 'basic'\n",
    "    r = checkPrefixCollectionConsistencty(subdir,prefixes,start_time, end_time,  \n",
    "                                          grouping_to_check, it_to_check,\n",
    "                                          use_main_LFP_chan=1, light_only=1, \n",
    "                                         prefixes_ignore  = [], preloaded=preloaded)\n",
    "    missing, _ = r\n",
    "    print(missing)\n",
    "#     if max( [len(m) for m in missing.values()] ) != 0 and not ignore_missing:\n",
    "#         raise ValueError('something is missing')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3026c684",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#rename when needed (handling multi-dataset items, makeing them keyed by subjet only)\n",
    "change_keys = False\n",
    "if change_keys:\n",
    "    from utils_preproc import getRawnameListStructure\n",
    "    # force rename keys outside the function (doing it inside would complicate it too much)\n",
    "    newkeys = []\n",
    "    ordered = list(output_per_raw.items())\n",
    "    vals = []\n",
    "    #%debug\n",
    "    for rawkey,vv in ordered:\n",
    "        rawnames_cur = rawkey.split(',')\n",
    "        subjs_analyzed, subjs_analyzed_glob = \\\n",
    "            getRawnameListStructure(rawnames_cur, ret_glob=True)\n",
    "        sl = subjs_analyzed_glob['subject_list']\n",
    "        mcl = list( subjs_analyzed_glob['per_medcond'].keys() )\n",
    "        assert len(sl) == 1\n",
    "        newkey = f'{sl[0]}'\n",
    "    #     if len(mcl) == 1:\n",
    "    #         newkey = f'{sl[0]}_{mcl[0]}'\n",
    "    #     elif len(rawnames_cur) == 4 or (len(rawnames_cur) == 2 and sl[0] == 'S03'):\n",
    "    #         newkey = f'{sl[0]}'\n",
    "        newkeys += [newkey]\n",
    "        vals += [vv]\n",
    "\n",
    "    output_per_raw = dict(zip(newkeys,vals))\n",
    "\n",
    "# import utils_postprocess as pp\n",
    "# pp.printDict(output_per_raw,max_depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4858c2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "times = []\n",
    "for tpl in newtpll:\n",
    "    times += [tpl[-1]['fname_mod_time']]\n",
    "min(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd91297f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03a33fef",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db0b2d6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #gv.gen_subj_info[subj].get('move_side',None)\n",
    "# #help(utsne.selFeatsRegex)\n",
    "# chnames_LFP_contralat_to_move\n",
    "# cdk\n",
    "# mult_clf_output['best_LFP']['XGB']['perf_drop']\n",
    "\n",
    "#[n for n in list(mult_clf_output.keys()) if n.find('name') >= 0]\n",
    "\n",
    "#mult_clf_output['filename_full']\n",
    "\n",
    "#[tpl[-1] for tpl in outputs_grouped_tpll]\n",
    "\n",
    "#mult_clf_output['class_labels_good_for_classif']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92820c3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1cf54b",
   "metadata": {
    "code_folding": [
     17
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import utils_postprocess as pp\n",
    "import json\n",
    "save_result = False\n",
    "outputs_grouped_tpll = pp.multiLevelDict2TupleList(output_per_raw,4,3)\n",
    "\n",
    "cpd = 'sens,spec,F1'\n",
    "metrics = ['balanced_accuracy', cpd, 'sens', 'spec']\n",
    "from utils_tSNE import selBestLFP\n",
    "\n",
    "def extractPerf(p,metric_cur):\n",
    "    if metric_cur == cpd:\n",
    "        v = np.array( p['sens'],p['spec'] ) \n",
    "    else:\n",
    "        v = np.array( p[metric_cur] )\n",
    "    return (v*100).tolist()\n",
    "    \n",
    "best_LFP_dict = {}\n",
    "for tpl in outputs_grouped_tpll:\n",
    "    subj, prefix, grp, int_type, mult_clf_output = tpl\n",
    "    pd0 = mult_clf_output['best_LFP']['XGB']['perf_drop']['only']\n",
    "    chnames_LFP = list( pd0.keys() )\n",
    "    if not chnames_LFP[0].startswith('LFP'):\n",
    "        pd0 = list(pd0.values())[0].keys()\n",
    "        chnames_LFP = list( pd0.keys() )\n",
    "    \n",
    "    cdk = ','.join([prefix,grp,int_type])\n",
    "    if subj not in best_LFP_dict:\n",
    "        best_LFP_dict[subj]= {}\n",
    "    best_LFP_dict[subj][cdk] = {}\n",
    "    \n",
    "    mainmoveside_cur = gv.gen_subj_info[subj].get('move_side',None)\n",
    "    movesidelet = mainmoveside_cur[0].upper()\n",
    "    \n",
    "    contralat_to_move_sidelet = utils.getOppositeSideStr( movesidelet )\n",
    "    _,chnames_LFP_contralat_to_move = utsne.selFeatsRegex(None,chnames_LFP,[f'LFP{contralat_to_move_sidelet}'])\n",
    "    \n",
    "    d = {}\n",
    "    for metric in metrics:    \n",
    "        print(f'   metric = {metric}')\n",
    "        d[metric] ={}\n",
    "        d[metric + '_shuffled'] = {}\n",
    "        \n",
    "        #if isinstance(subj,tuple):\n",
    "        #    subj = subj[0]\n",
    "        #kk, mult_clf_output = tpl\n",
    "        #print(kk)\n",
    "        #(prefix,grp,int_type) = kk\n",
    "        #for clf_type in ['LDA','XGB']:\n",
    "        #chnames_LFP_controlat_to_move\n",
    "        pdrop_cl,winning_chan_cl = selBestLFP(mult_clf_output, 'XGB', chnames_LFP=chnames_LFP_contralat_to_move, \n",
    "                                              metric=metric, verbose=0)\n",
    "        d[metric]['best_LFP_contralat_to_move']      = winning_chan_cl\n",
    "        \n",
    "        pdrop,winning_chan = selBestLFP(mult_clf_output, 'XGB', chnames_LFP=chnames_LFP, metric=metric, verbose=1)\n",
    "        best_LFP = winning_chan\n",
    "        #pd = dict( [(chn, (100*a).tolist()) for chn,a in list( pdrop.items() )] )\n",
    "        d[metric]['best_LFP']      = best_LFP\n",
    "        d[metric]['perf_drop_pct'] = pdrop\n",
    "\n",
    "        # save actual values as well\n",
    "        kn = f'all_present_features'\n",
    "        perf_aver = mult_clf_output['XGB_analysis_versions'][kn]['perf_dict']['perf_aver']\n",
    "        d[metric][kn] = extractPerf(perf_aver,metric)\n",
    "        perf_all_feats = d[metric][kn]\n",
    "        \n",
    "        perf_shuffled = mult_clf_output['XGB_analysis_versions'][kn]['perf_dict']['fold_type_shuffled'][-1]\n",
    "        d[metric + '_shuffled'][kn ] = extractPerf(perf_shuffled,metric)\n",
    "        \n",
    "        for chn in chnames_LFP:\n",
    "            kn = f'all_present_features_only_{chn}'\n",
    "            perf_aver = mult_clf_output['XGB_analysis_versions'][kn]['perf_dict']['perf_aver']\n",
    "            d[metric][kn] = extractPerf(perf_aver,metric)\n",
    "            \n",
    "            perf_shuffled = mult_clf_output['XGB_analysis_versions'][kn]['perf_dict']['fold_type_shuffled'][-1]\n",
    "            d[metric + '_shuffled'][kn ] = extractPerf(perf_shuffled,metric)\n",
    "\n",
    "        for chn in chnames_LFP:\n",
    "            kn = f'all_present_features_but_{chn}'\n",
    "            perf_aver = mult_clf_output['XGB_analysis_versions'][kn]['perf_dict']['perf_aver']\n",
    "            d[metric][kn] = extractPerf(perf_aver,metric)\n",
    "            \n",
    "            perf_shuffled = mult_clf_output['XGB_analysis_versions'][kn]['perf_dict']['fold_type_shuffled'][-1]\n",
    "            d[metric + '_shuffled'][kn ] = extractPerf(perf_shuffled,metric)\n",
    "            \n",
    "            dif = np.max( np.abs( np.array(perf_all_feats) - np.array(d[metric][kn] ) ) )\n",
    "            if dif > 5:\n",
    "                print(tpl[:-1],metric,'but',chn,dif)\n",
    "            \n",
    "        d['total_num_feats'] = len( mult_clf_output['featnames_for_fit'] )\n",
    "        d['total_num_datapoints'] = len( mult_clf_output['class_labels_good_for_classif'] )\n",
    "        d['runCID'] = mult_clf_output['runCID']\n",
    "        mtime = mult_clf_output.get('mod_time',None)\n",
    "        mtime= datetime.datetime.fromtimestamp( mtime )\n",
    "        d['fname_mod_time'] = mtime.strftime(\"%d %b %Y %H:%M\")\n",
    "\n",
    "        best_LFP_dict[subj][cdk] = d\n",
    "        #if subj in best_LFP_dict:\n",
    "        #    \n",
    "        #else:\n",
    "        #    best_LFP_dict[subj] = d\n",
    "\n",
    "        print(subj,prefix,f'true best={best_LFP}, best_cl={winning_chan_cl}, in paper={gv.gen_subj_info[subj][\"lfpchan_used_in_paper\"] }')        \n",
    "#json.dumps(best_LFP_dict)\n",
    "#gv.code_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adf9aa3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subdir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aded6c25",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## save_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0badf3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_result = 1\n",
    "fname_full = pjoin(gv.data_dir, subdir, f'best_LFP_info_both_sides_ext.json')\n",
    "print(fname_full)\n",
    "if save_result:\n",
    "    #fname = pjoin(gv.data_dir, subdir, f'best_LFP_info_both_sides.json')\n",
    "    with open(fname_full, 'w') as f:\n",
    "        json.dump(best_LFP_dict, f)\n",
    "    import subprocess as sp\n",
    "    r = sp.getoutput(f'python -m json.tool {fname_full}') \n",
    "    with open(fname_full,'w') as f:\n",
    "        f.write(r)\n",
    "    #print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe84e267",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaa9bc5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbd7e9e",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#r[:2000].split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3a1907",
   "metadata": {},
   "source": [
    "# best LFP-specific analysis to DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256d5970",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_LFP_info = best_LFP_dict\n",
    "from utils_postprocess_HPC import sidelet2sideTempl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d8ecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc9627f",
   "metadata": {
    "code_folding": [
     88
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "permlvl = '0.9'\n",
    "rows = []\n",
    "ps = []\n",
    "for subjlike,d0 in best_LFP_info.items():\n",
    "    rnparts = subjlike.split('_')\n",
    "    subj = rnparts[0]\n",
    "    if len(rnparts) > 1:\n",
    "        mcstr = rnparts[1]\n",
    "    for ks,d1 in d0.items():\n",
    "        row = {}\n",
    "        (prefix,grouping,iset) = ks.split(',')\n",
    "        ps += [prefix]\n",
    "        d2  = d1['balanced_accuracy']\n",
    "        d2s = d1['balanced_accuracy_shuffled']\n",
    "        d2p = d1[f'balanced_accuracy_perm_{permlvl}']\n",
    "        \n",
    "        chn = d2['best_LFP']['only']\n",
    "        chn_cl = d2['best_LFP_contralat_to_move']['only']\n",
    "        \n",
    "        p    = d2['all_present_features']\n",
    "        pb   = d2[f'all_present_features_but_{chn}']\n",
    "        pbcl = d2.get(f'all_present_features_but_{chn_cl}',None)    \n",
    "        \n",
    "        p_s    = d2s['all_present_features']\n",
    "        pb_s   = d2s[f'all_present_features_but_{chn}']\n",
    "        pbcl_s = d2s.get(f'all_present_features_but_{chn_cl}',None)\n",
    "        \n",
    "        p_p    = d2p['all_present_features'] * 100\n",
    "        pb_p   = d2p.get(f'all_present_features_but_{chn}',None)\n",
    "        pbcl_p = d2p.get(f'all_present_features_but_{chn_cl}',None)\n",
    "        \n",
    "        #d0['balanced_accuracy']['all_present_features']\n",
    "        row['prefix_long'] = prefix\n",
    "        row['grouping'] = grouping\n",
    "        row['interval_set'] = iset\n",
    "        row['subject'] = subj\n",
    "        if len(rnparts) > 1:\n",
    "            row['medcond'] = mcstr\n",
    "        row['bacc_all'] = p\n",
    "        row['bacc_best'] = pb\n",
    "        row['bacc_best_contra'] = pbcl\n",
    "        \n",
    "        row['numpts'] = d1['total_num_datapoints']\n",
    "        \n",
    "        row['bacc_all_shuffled']         = p_s\n",
    "        row['bacc_best_shuffled']        = pb_s\n",
    "        row['bacc_best_contra_shuffled'] = pbcl_s\n",
    "        \n",
    "        row[f'bacc_all_perm_{permlvl}']         = p_p\n",
    "        row[f'bacc_best_perm_{permlvl}']        = pb_p\n",
    "        row[f'bacc_best_contra_perm_{permlvl}'] = pbcl_p\n",
    "\n",
    "        row['runCID'] = d1['runCID']\n",
    "        \n",
    "        row['num'] = d1['total_num_feats']\n",
    "        row['numpts'] = d1['total_num_datapoints']\n",
    "        row['fname_mod_time'] = d1['fname_mod_time']\n",
    "        \n",
    "        parts = prefix.split('_')\n",
    "        \n",
    "        if parts[-1].find('disj') >= 0:\n",
    "            row['disj'] = parts[-1]             \n",
    "            #i = -2\n",
    "        else:\n",
    "            row['disj'] = 'no'\n",
    "            #i = -1\n",
    "            \n",
    "        i,bstr = [(i,part) for (i,part) in enumerate(parts) if part.startswith('brain')][0]\n",
    "        row['brain_side'] = bstr[len('brain'):]     \n",
    "        #row['brain_side'] = parts[i][len('brain'):] \n",
    "        if parts[0] == 'modLFP':\n",
    "            row['modality'] = parts[0]\n",
    "            i0 = 1\n",
    "        else:\n",
    "            row['modality'] = 'LFP,msrc'\n",
    "            i0 = 0\n",
    "            \n",
    "        row['feat'] = '_'.join( parts[i0:i])\n",
    "        \n",
    "        \n",
    "        row['best_chn'] = chn\n",
    "        row['best_chn_contra'] = chn_cl\n",
    "                \n",
    "        \n",
    "        sidelet = row['brain_side'][0].upper()\n",
    "        if sidelet == 'B':\n",
    "            sidetempl = 'BB'\n",
    "        else:\n",
    "            sidetempl = sidelet2sideTempl( sidelet, subj )\n",
    "            sidetempl = sidetempl + sidetempl\n",
    "        if row['disj'] == 'disjoint':\n",
    "            subskip = 8\n",
    "        elif row['disj'] == 'semidisjoint':\n",
    "            subskip = 4\n",
    "        elif row['disj'] == 'no':\n",
    "            subskip = 1\n",
    "        else:\n",
    "            raise ValueError(f'wrong row[\\\"disj\\\"] = {row[\"disj\"]}')\n",
    "        row['prefix_templ'] = row['modality'] + \\\n",
    "            f'_{row[\"feat\"]}_' + f'subskip{subskip}' + sidetempl\n",
    "        \n",
    "        rows += [row]\n",
    "#         break\n",
    "#     break\n",
    "dfLFP = pd.DataFrame(rows)\n",
    "\n",
    "df = dfLFP.query('disj == \"disjoint\"').copy()\n",
    "df['best_LFP_sidelet'] = df['best_chn'].apply(lambda x: x[3])\n",
    "from utils_postprocess_HPC import sidelet2sideTempl\n",
    "def lbd(row):\n",
    "    let = row['best_LFP_sidelet']\n",
    "    r = sidelet2sideTempl(let, row['subject'] )\n",
    "    return r\n",
    "df['best_LFP_sidetempl'] = df.apply(lbd,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca37a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_LFP_info['S01']['onlyH_act_brainleft_exCB,merge_nothing,trem_vs_quiet'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295832ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLFP.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa604dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['subject','medcond','grouping','interval_set','prefix_templ','best_LFP_sidetempl',\n",
    "        'numpts','bacc_all', 'bacc_all_shuffled', \n",
    "    f'bacc_all_perm_{permlvl}',\n",
    "    'bacc_best', f'bacc_best_perm_{permlvl}', 'bacc_best_shuffled',\n",
    "    'bacc_best_contra','bacc_best_contra_shuffled','feat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee427bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['prefix_templ'].str.contains('onlyH_act')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b42bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb45bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ipsilateral or contralateral side gives best LFP?\n",
    "# let's test on LFP only data, only H_act\n",
    "dfc = df[df['prefix_templ'].str.endswith('BB') & \\\n",
    "         df['prefix_templ'].str.contains('modLFP_onlyH_act')].query(\n",
    "    'grouping == \"merge_nothing\" and interval_set == \"basic\"')\n",
    "dfc = dfc.sort_values(['subject','medcond'])\n",
    "dfc[['subject','medcond','grouping','interval_set','prefix_templ','best_LFP_sidetempl','bacc_all']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b74d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4a0c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "1030 % 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13870c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('feat == \"\"')['prefix_long']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6bce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['modality'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed673acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "parts[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0bab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bc7b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "row['brain_side']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20b98d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312188d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ad436c",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# select disjoint and restrucutre the table\n",
    "# this cell needs df_all\n",
    "dfLFPd = dfLFP[(dfLFP['disj'] == 'disjoint') & (dfLFP['grouping'] == 'merge_movements') \\\n",
    "              & (dfLFP['interval_set'] == 'basic')]\n",
    "\n",
    "grp = dfLFPd.groupby(['prefix_templ','grouping','interval_set'])\n",
    "display(grp.size())\n",
    "dfLFPdm = grp.mean()\n",
    "dfLFPdstd = grp.std()\n",
    "display(dfLFPdm,dfLFPdstd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e638bb0",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "dfLFPdm = dfLFPdm.reset_index()\n",
    "dfLFPdstd = dfLFPdstd.reset_index()\n",
    "\n",
    "finals = []\n",
    "\n",
    "prefsd = {'prefix':{}, 'ending':{}, 'prefix_short':{}}\n",
    "prefsd['ending']['contra'] = '_subskip8%%'\n",
    "prefsd['ending']['ipsi'] = '_subskip8^^'\n",
    "for s,end in prefsd['ending'].items():\n",
    "    prefsd['prefix'][s] = [f'modLFP_onlyH{end}',f'modLFP_onlyH_act{end}']\n",
    "    prefsd['prefix_short'][s] = [f'onlyH_act{end}', f'onlyH{end}']    \n",
    "\n",
    "    # now I want to make two tables each taking two rows\n",
    "    dfLFPdm_sub = dfLFPdm[dfLFPdm['prefix_templ'].isin(prefsd['prefix'][s])]\n",
    "    dfLFPdm_sub_allLFP  = dfLFPdm_sub[['prefix_templ','bacc_all','bacc_all_shuffled']]\n",
    "    dfLFPdm_sub_bestLFP = dfLFPdm_sub[['prefix_templ','bacc_best','bacc_best_shuffled']]\n",
    "\n",
    "    dfLFPdm_sub_allLFP['prefix_templ'] = dfLFPdm_sub_allLFP['prefix_templ'].str.\\\n",
    "        replace('_subskip','_allLFP_subskip')\n",
    "\n",
    "    dfLFPdm_sub_allLFP = dfLFPdm_sub_allLFP.rename(columns=\\\n",
    "                        {'bacc_all':'bacc', 'bacc_all_shuffled':'bacc_shuffled'})\n",
    "    #dfLFPdm_sub_allLFP.drop( ['bacc_best','bacc_best_shuffled'],1)\n",
    "\n",
    "    dfLFPdm_sub_bestLFP = dfLFPdm_sub_bestLFP.rename(columns=\\\n",
    "                        {'bacc_best':'bacc', 'bacc_best_shuffled':'bacc_shuffled'})\n",
    "    #dfLFPdm_sub_bestLFP.drop( ['bacc_all','bacc_all_shuffled'], 1)\n",
    "\n",
    "    dfLFPdm_sub_allLFP = dfLFPdm_sub_allLFP.reset_index()\n",
    "    dfLFPdm_sub_bestLFP = dfLFPdm_sub_bestLFP.reset_index()\n",
    "\n",
    "    dfc = pd.concat([dfLFPdm_sub_allLFP,dfLFPdm_sub_bestLFP])\n",
    "    #dfc = dfc.drop('level_0',1)\n",
    "    dfc = dfc.drop('index',1)\n",
    "    #dfc\n",
    "    #--------------------------------\n",
    "\n",
    "    df_allH = df_all[df_all['prefix_templ'].isin( prefsd['prefix_short'][s]) ]\\\n",
    "        [['prefix_templ','bacc', 'bacc_shuffled']]\n",
    "    df_allmod = df_allH.groupby('prefix_templ').mean().reset_index()\n",
    "    df_allmod['LFP channels'] = 'best'\n",
    "    \n",
    "    def lbd(row): \n",
    "        if row['prefix_templ'].find('allLFP') < 0:\n",
    "            return 'all' \n",
    "        else:\n",
    "            return 'best'\n",
    "    #dfc2['LFP channels'] = None\n",
    "    dfc['LFP channels'] = dfc.apply(lbd,1)\n",
    "    \n",
    "    dfc2 = pd.concat([dfc,df_allmod]).reset_index().drop('index',1)\n",
    "    dfc2['prefix_templ'] = dfc2['prefix_templ'].str.replace(end,'', regex=0)\n",
    "    dfc2['modality'] = dfc2['prefix_templ'].apply(lambda x: 'LFP + cortex' \\\n",
    "                                                  if x.find('modLFP') < 0 else 'LFP')\n",
    "    \n",
    "    dfc2['prefix_templ'] = dfc2['prefix_templ'].str.replace('modLFP_','')\n",
    "    dfc2['prefix_templ'] = dfc2['prefix_templ'].str.replace('_allLFP','')\n",
    "\n",
    "    dfc2['prefix_templ'] = dfc2['prefix_templ'].replace({'onlyH_act':'Hjorth activity',\n",
    "                                                        'onlyH':'all Hjorth parameters'})\n",
    "\n",
    "    dfc2['bacc'] = dfc2['bacc'].apply(lambda x : f'{x:.0f}%')\n",
    "    dfc2['bacc_shuffled'] = dfc2['bacc_shuffled'].apply(lambda x : f'{x:.0f}%')\n",
    "\n",
    "\n",
    "    rename_dict = {}\n",
    "    rename_dict['prefix_templ'] = 'Feature set'\n",
    "    rename_dict['modality'] = 'Data type'\n",
    "    #rename_dict['interval_set'] = 'behav. states used'\n",
    "    rename_dict['bacc'] = 'Performance'\n",
    "    rename_dict['bacc_shuffled'] = 'Performance shuffled'\n",
    "    #rename_dict['bacc_std'] = 'performance std'\n",
    "    dfc2.rename(columns=rename_dict, inplace = 1)\n",
    "    \n",
    "    dfc2['Brain side'] = s\n",
    "\n",
    "    dfc2r = dfc2[['Data type', 'LFP channels', 'Brain side', 'Feature set', 'Performance', 'Performance shuffled']]\n",
    "    display(dfc2r)\n",
    "    \n",
    "    finals += [dfc2r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe8875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42621a5b",
   "metadata": {},
   "source": [
    "# old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911db1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_LFP_dict[subj].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d148d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = best_LFP_dict[subj]['modLFP_onlyH_act_brainright_disjoint,merge_nothing,basic'][metric]['best_LFP']\n",
    "# 53 KeyError: 'modLFP_onlyH_act_brainright_disjoint,merge_nothing,basic'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec654817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "dt = datetime.datetime.now()\n",
    "dt.strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00523ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bcbff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_postprocess import getBestLFP_clToMove\n",
    "getBestLFP_clToMove(best_LFP_dict,subj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4be57da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to have easy to use cl to move best LFP\n",
    "for subj,vals in best_LFP_dict.items():\n",
    "    ks = list( vals.keys() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab66ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'_postproc','modLFP_onlyH_act_*_disjoint,merge_movements,basic'\n",
    "\n",
    "brainright_exCB\n",
    "\n",
    "best_LFP_dict[subj]['modLFP_onlyH_act_brainright_exCB_disjoint,merge_movements,basic']['balanced_accuracy']['best_LFP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c85c459",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = pjoin(gv.data_dir, 'best_LFP_info.json')\n",
    "with open(fname, 'r') as f:\n",
    "    jl = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50113b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc1092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jl['S01']['modLFP,merge_movements,basic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c38bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "jl['S02']['modLFP,merge_movements,basic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0231c07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for kk in jl['S01'].keys():\n",
    "    print(kk.split(',')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550b4520",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_thrs = mult_clf_output['feat_variance_q_thr']\n",
    "#thr0,thr1,thr2='0.6','0.75','0.9'\n",
    "thr0,thr1,thr2='0.87','0.92','0.99'\n",
    "\n",
    "all_LDA =  []\n",
    "all_XGB = ['all_present_features', \n",
    "           'best_LFP']\n",
    "\n",
    "\n",
    "perf_to_use_list = []\n",
    "if len(all_LDA):\n",
    "    for v in all_LDA[1:]:\n",
    "        perf_to_use_list += [('LDA',all_LDA[0],v)]\n",
    "for v in all_XGB[1:]:\n",
    "    perf_to_use_list += [('XGB',all_XGB[0],v)]\n",
    "\n",
    "###########################################\n",
    "display(perf_to_use_list)\n",
    "\n",
    "to_show = [('allsep','merge_nothing','basic'), ('trem_vs_all','merge_all_not_trem','basic'),\n",
    "        ('trem_vs_2class','merge_movements','basic')]\n",
    "to_show = [('trem_vs_2class','merge_movements','basic')]\n",
    "\n",
    "\n",
    "# warnings.simplefilter('error')\n",
    "# table_info_per_perf_type, table_per_perf_type = \\\n",
    "#     postp.prepTableInfo2(output_per_raw, prefixes=prefixes, \n",
    "#     perf_to_use_list=perf_to_use_list)\n",
    "\n",
    "#%debug\n",
    "# import warnings\n",
    "# with warnings.catch_warnings():\n",
    "#warnings.simplefilter('error')\n",
    "table_info_per_perf_type, table_per_perf_type = \\\n",
    "    postp.prepTableInfo3(output_per_raw, prefixes=prefixes, \n",
    "    perf_to_use_list=perf_to_use_list, to_show=to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac1d011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e366c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dumps(best_LFP_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perf_tuple = perf_to_use_list[0]\n",
    "#%debug\n",
    "#for perf_tuple in perf_to_use_list[:1]:\n",
    "for perf_tuple in perf_to_use_list:\n",
    "    print(perf_tuple)\n",
    "    postp.plotTableInfos2(table_info_per_perf_type, perf_tuple=perf_tuple, \n",
    "                          output_subdir=subdir) \n",
    "    plt.close()\n",
    "    import gc;gc.collect()\n",
    "#postp.plotTableInfos2(table_info_per_perf_type, perf_kind='LDA', keys = None, output_subdir=''): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe5d588",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(plt.suptitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d137273",
   "metadata": {},
   "outputs": [],
   "source": [
    "rncur = 'S01_off_hold'\n",
    "sind_str,mc,tk  = utils.getParamsFromRawname(rncur)\n",
    "sources_type='parcel_aal'\n",
    "src_file_grouping_ind = 10\n",
    "src_rec_info_fn = '{}_{}_grp{}_src_rec_info'.format(rncur,\n",
    "                                                    sources_type,src_file_grouping_ind)\n",
    "src_rec_info_fn_full = os.path.join(gv.data_dir, src_rec_info_fn + '.npz')\n",
    "rec_info = np.load(src_rec_info_fn_full, allow_pickle=True)\n",
    "\n",
    "\n",
    "print( list(rec_info.keys()) )\n",
    "\n",
    "labels_dict = rec_info['label_groups_dict'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe897e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_postprocess as pp\n",
    "\n",
    "prefixes_to_use = ['cross_freqmod_beta,gamma:HFO']\n",
    "prefixes_to_use = ['LFPrel_noself']\n",
    "#for prefix_cur in list(sorted( set(prefixes) - set(['all']) )):\n",
    "#for prefix_cur in ['cross_freqmod_beta,gamma:HFO']:\n",
    "#for prefix_cur in [ 'LFPrel_noself']:\n",
    "for prefix_cur in [ 'onlyH']:\n",
    "    prefixes_to_use = [prefix_cur]\n",
    "\n",
    "    outputs_grouped = pp.groupOutputs(output_per_raw, prefixes_to_use,['merge_movements'],['basic'])\n",
    "    #pp.printDict(outputs_grouped,1,print_leaves=1)\n",
    "\n",
    "\n",
    "    use_light_file = 1\n",
    "    perf_thr = 0.7\n",
    "\n",
    "    rname_crop = slice(0,3)\n",
    "\n",
    "    #(prefix,grp,int_type), output = u\n",
    "    print(f'Starting plotting for {len(outputs_grouped)} grouped outputs')\n",
    "    info_cur = {}\n",
    "    #sens,spec = res[rn].get(pref, (np.nan, np.nan))\n",
    "    (prefix,grp,int_type), mult_clf_output = list(outputs_grouped.values())[0]\n",
    "\n",
    "    output_subdir = ''\n",
    "    rnstr = ';'.join( list( outputs_grouped.values() )[0][0] )\n",
    "    out_name_plot = f'{\",\".join((prefix,grp,int_type) ) }_feat_signif'        \n",
    "    #chnames_LFP = ['LFPR01', 'LFPR12', 'LFPR23']\n",
    "\n",
    "    str_to_put_ = ''\n",
    "    #     pvec = mult_clf_output['XGB_analysis_versions']['all_present_features']['perf_dict']['perf_aver']\n",
    "    #     sens,spec,F1 = pvec\n",
    "    #     str_to_put_ =  '{:.0f}%,{:.0f}%,{:.0f}%'.format(100*pvec[0],100*pvec[1],100*pvec[2])\n",
    "    #     if min(sens,spec) < perf_thr:\n",
    "    #         print('  Skipping due to low perf ',str_to_put_)\n",
    "    #         continue\n",
    "    #hh = int( 20 * len(featnames) / 270  ), \n",
    "    #%debug\n",
    "\n",
    "    #outputs_grouped   # \n",
    "    #(prefix,grp,int_type), mult_clf_output = output_list[0]\n",
    "    #%debug\n",
    "    from matplotlib.backends.backend_pdf import PdfPages\n",
    "    try:\n",
    "        pdf= PdfPages(pjoin(gv.dir_fig, subdir, out_name_plot + '.pdf' ))    \n",
    "        postp.plotFeatSignifSHAP_list(pdf=None,\n",
    "                                 outputs_grouped=outputs_grouped, fshs='XGB_Shapley',                                  \n",
    "                                 figname_prefix=prefix, roi_labels=labels_dict['all_raw'],\n",
    "                                 body_side='left', chnames_LFP=chnames_LFP, \n",
    "                                 hh = 12, \n",
    "                                 tickfontsize = 10, markersize=8,\n",
    "                                 suptitle = str_to_put_, use_best_LFP=True,\n",
    "                                 suptitle_fontsize=20, show_bias=0, show_max = False, \n",
    "                                 show_std = False, average_over_subjects = True,\n",
    "                                 merge_Hjorth = prefix_cur != 'onlyH',alpha=0.4);                  \n",
    "\n",
    "        pdf.savefig()\n",
    "        plt.close()        \n",
    "\n",
    "        #plt.close('all')\n",
    "    except KeyError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    \n",
    "    cax,clrb = postp.plotConfmats(outputs_grouped, best_LFP=1)\n",
    "    kind = ';'.join( list( outputs_grouped.values() )[0][0] )\n",
    "    figname = ','.join( [k[0] for k in outputs_grouped.keys()] ) + f'_confmats_{kind}.pdf'\n",
    "    kind = ';  '.join( list( outputs_grouped.values() )[0][0] )\n",
    "    plt.suptitle(kind)\n",
    "    #plt.savefig( pjoin(gv.dir_fig,subdir,figname) )\n",
    "    \n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "    \n",
    "    pdf.close()\n",
    "\n",
    "#             break\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b6c095",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8972615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([np.eye(3),np.eye(3)])\n",
    "print( a.shape )\n",
    "ais = np.where(a)\n",
    "a[ais]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf0db33",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array( [np.zeros((2,2)), np.zeros((2,2))] ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4811337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[4.4,5],[4,5]]).dtype == np.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237146f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple( np.array([[4,5],[4,5]]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2eb320",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple( np.array(['fd','fds']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb754d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cobd",
   "language": "python",
   "name": "cobd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
