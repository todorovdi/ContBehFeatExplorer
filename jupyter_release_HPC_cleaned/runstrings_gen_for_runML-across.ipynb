{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a08aca9-b459-4921-a170-67f8948788b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e760cc1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "771461ae",
   "metadata": {},
   "source": [
    "### for Jupyter JSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ee79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!module load Stages/2022\n",
    "#!module load GCC\n",
    "#!module load Python/3.9.6\n",
    "\n",
    "import os\n",
    "os.environ['PROJECT_DIR']=os.path.expandvars( \"$PROJECT/OSCBAGDIS\" )\n",
    "os.environ['OSCBAGDIS_DATAPROC_CODE']=os.path.expandvars( \"$PROJECT/OSCBAGDIS/data_proc_code\" )\n",
    "os.environ['CODE']=os.path.expandvars( \"$PROJECT/OSCBAGDIS/data_proc_code\" )\n",
    "os.environ['DATA_DUSS']=os.path.expandvars( \"$PROJECT_DIR/data_proc_code\" )\n",
    "#os.environ['CODE_MEMORY_ERRORS'] = os.path.expandvars(\"$PROJECT/lyon/memerr/code\" )\n",
    "sys.path.append( os.path.expandvars( \"$OSCBAGDIS_DATAPROC_CODE\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d844d153",
   "metadata": {},
   "source": [
    "# Autoreload setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969bf5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import globvars as gv\n",
    "from globvars import gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2621f551",
   "metadata": {},
   "outputs": [],
   "source": [
    "#$RS --mods msrc --feat_types H_act --parcel_group_names Sensorimotor,OccipitalI    nf,FrontalSup,FrontalInf,TemporalMid  --prefix onlyH_act_SMyOIyFSyFIyTM_noLFP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c41dd8",
   "metadata": {},
   "source": [
    "# Set timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab80cc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "print(f'Set new timestamp at {datetime.datetime.now()}')\n",
    "run_corresp_id = int( time.time() * 10000 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62de14ae",
   "metadata": {},
   "source": [
    "# Set params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ecacaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not likely to be changed\n",
    "inc_S03 = True  # does not have ON and has dirty MEG\n",
    "inc_S05 = True  # has right as mvt side (whereas other 5 have left)\n",
    "inc_noMvt = False\n",
    "test_best_LFP_disjointness = False\n",
    "#subskips = [8] # 1, 4 ,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215f0348",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "join_medcond = True  # medconds merged\n",
    "join_subjects = False\n",
    "\n",
    "calc_all_Hjorth = False\n",
    "#subskips = [4,8] # here we will always use 8 and it is in params\n",
    "#disjoint_windows = False  # when it is False it just means we are not forcing it, rather using param file setup\n",
    "#overlapping_windows = False\n",
    "#if disjoint_windows == overlapping_windows and overlapping_windows == True:\n",
    "#    raise ValueError('not implemented, do only one for now')\n",
    "# first is cortex side, second is LFP side\n",
    "#side_tuples = [ ('both','both') ]\n",
    "#side_tuples = [ ('left','left'), ('right','right') ]\n",
    "\n",
    "# side_tuples = [ ('both','both') ]\n",
    "# side_tuples += [ ('left_exCB','left'), ('right_exCB','right') ]\n",
    "# side_tuples += [ ('left_onlyCB','left'),  ('both_onlyCB','left'), \n",
    "#                 ('right_onlyCB','right'),  ('both_onlyCB','right') ]\n",
    "\n",
    "\n",
    "side_tuples = [ ('both','copy_from_search_LFP') ]\n",
    "# side_tuples += [ ('left_exCB','copy_from_search_LFP'), ('right_exCB','copy_from_search_LFP') ]\n",
    "# side_tuples += [ ('left_onlyCB','copy_from_search_LFP'),  ('both_onlyCB','copy_from_search_LFP'), \n",
    "#                 ('right_onlyCB','copy_from_search_LFP') ]\n",
    "\n",
    "#('right_onlyCB','left'), ('left_onlyCB','right'),\n",
    "\n",
    "rawnames_dict = {}\n",
    "prefixes_types = []\n",
    "##prefixes_types += ['PREFIXES_MAIN']\n",
    "prefixes_types += ['PREFIXES_SPECIFIC_SIDED']\n",
    "#prefixes_types += ['PREFIXES_H_ACT_PER_PARCEL_GROUP_SIDED']\n",
    "#prefixes_types += ['PREFIXES_H_ACT_PER_PARCEL_GROUP_SIDED_LFP']\n",
    "assert not (('PREFIXES_MAIN' in prefixes_types) and ('PREFIXES_SPECIFIC' in prefixes_types))\n",
    "# TODO include in final\n",
    "\n",
    "#fname_runstr = '_runstrings_ML_test.txt'\n",
    "fname_runstr = '_runstrings_ML.txt'\n",
    "g_it_strs = []\n",
    "g_it_strs += [' --groupings_to_use merge_nothing --int_types_to_use basic,medcond']\n",
    "modes = ['only']  # exclude is boring anyway, other parcels compensate too much\n",
    "\n",
    "# comment = ('Per subject brain area significance both sides (separately), '\n",
    "#  'test which best LFP is better: disjoint or not -- max-overlap no prescale')\n",
    "comment = 'across medcond (test, few perm)'\n",
    "#comment = 'everything for join across medcond, exclude S05'\n",
    "\n",
    "runpars = {}\n",
    "runpars['inc_S03'] = inc_S03\n",
    "runpars['inc_S05'] = inc_S05\n",
    "runpars['join_subjects'] =join_subjects\n",
    "runpars['inc_noMvt'] = inc_noMvt\n",
    "runpars['join_medcond'] = join_medcond\n",
    "#\n",
    "#runpars['inc_disjoint_windows'] = disjoint_windows\n",
    "#runpars['inc_overlapping_windows'] = overlapping_windows\n",
    "runpars['side_tuples'] = side_tuples\n",
    "runpars['prefixes_types'] = prefixes_types\n",
    "runpars['fname_runstr'] = fname_runstr\n",
    "runpars['brain_area_inclusion_modes'] = modes # befere it was \"barain\"\n",
    "runpars['run_specific_args'] = (' --label_groups_to_use medcond '                       \n",
    "        ' --require_rawnames_consist_with_bestLFP 0 '\n",
    "        ' --force_use_bestLFP_first_rawname 1'\n",
    "        ' --use_matching_folds_main_LFP 0 '\n",
    "        ' --n_permutations_permtest 2')\n",
    "\n",
    "runpars['io_specargs_tuples'] = []\n",
    "best_LFP_info_file = ('searchLFP_both_sides_oversample2_LFP256_allaritf_medcondsep/'\n",
    "                      'best_LFP_info_both_sides_ext.json')\n",
    "# runpars['io_specargs_tuples'] += [('feats_wholectx_LFP256_covmat_entire',\n",
    "#       'per_subj_per_medcond_best_LFP_wholectx_oversample_LFP256_covmat_entire',\n",
    "#       f' --best_LFP_info_file {best_LFP_info_file}')]\n",
    "#  [('feats_wholectx_LFP256_covmat_rest',\n",
    "#      'per_subj_per_medcond_best_LFP_wholectx_oversample_LFP256_covmat_rest',\n",
    "#   f' --best_LFP_info_file {best_LFP_info_file}')]\n",
    "\n",
    "# runpars['io_specargs_tuples'] += [ ('feats_wholectx_LFP256_SSS_covmat_rest',\n",
    "#      'joint2_best_LFP_wholectx_oversample_LFP256_SSS_covmat_rest',\n",
    "#   f' --best_LFP_info_file {best_LFP_info_file}')]\n",
    "runpars['io_specargs_tuples'] += [ ('feats_wholectx_LFP256_SSS_covmat_rest',\n",
    "     'medcondjoin_best_LFP_wholectx_oversample_LFP256_SSS_covmat_rest',\n",
    "  f' --best_LFP_info_file {best_LFP_info_file}')]\n",
    "\n",
    "if join_subjects:\n",
    "    if join_medcond:\n",
    "        p = 'ML_joint2_one_LFP_wholectx_HPC.ini'\n",
    "        #TODO: create a new pfile for testing, this one does not exit\n",
    "        pf = 'ML_joint2_one_LFP_wholectx_HPC_fast.ini'\n",
    "    else:\n",
    "        p  = 'ML_joint_one_LFP_wholectx_HPC.ini'\n",
    "        pf = 'ML_joint_one_LFP_wholectx_HPC_fast.ini' \n",
    "else:\n",
    "    if not join_medcond:\n",
    "        #pfile_str      = ' --param_file ML_medcondsep_one_LFP_HPC.ini'\n",
    "        #pfile_str_test = ' --param_file ML_medcondsep_one_LFP_HPC_fast.ini' \n",
    "        p      = 'ML_medcondsep_one_LFP_wholectx_HPC.ini'\n",
    "        pf     = 'ML_medcondsep_one_LFP_wholectx_HPC_fast.ini' \n",
    "    else:\n",
    "        p      = 'ML_medcondjoin_one_LFP_wholectx_HPC.ini'\n",
    "        pf     = 'ML_medcondjoin_one_LFP_wholectx_HPC_fast.ini'\n",
    "        \n",
    "runpars['param_file_normal'] = p\n",
    "runpars['param_file_normal_fast'] = pf\n",
    "\n",
    "\n",
    "runpars['comment'] = comment\n",
    "print('Setting params finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501d7b49",
   "metadata": {},
   "source": [
    "# Apply params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597a776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inc_S05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761450c8",
   "metadata": {
    "code_folding": [
     24,
     111,
     126
    ]
   },
   "outputs": [],
   "source": [
    "rawnames_dict['off_Mvt_best'] = ['S01_off_hold',\n",
    " 'S01_off_move',\n",
    " 'S02_off_hold',\n",
    " 'S02_off_move',\n",
    " 'S04_off_hold',\n",
    " 'S04_off_move',\n",
    " 'S05_off_hold',\n",
    " 'S05_off_move',\n",
    " 'S07_off_hold',\n",
    " 'S07_off_move']\n",
    "rawnames_dict['off_unsure'] = ['S03_off_hold', 'S03_off_move']\n",
    "rawnames_dict['off_Mvt'] = rawnames_dict['off_Mvt_best'] +\\\n",
    "    rawnames_dict['off_unsure']\n",
    "rawnames_dict['on_Mvt'] = ['S01_on_hold',\n",
    " 'S01_on_move',\n",
    " 'S02_on_hold',\n",
    " 'S02_on_move',\n",
    " 'S04_on_hold',\n",
    " 'S04_on_move',\n",
    " 'S05_on_hold',\n",
    " 'S05_on_move',\n",
    " 'S07_on_hold',\n",
    " 'S07_on_move'] \n",
    "\n",
    "if not inc_S05:\n",
    "    for k in ['off_Mvt_best', 'on_Mvt', 'off_Mvt']:\n",
    "        rns_cur = rawnames_dict[k]\n",
    "        iS05 = []\n",
    "        for i,rncur in enumerate(rns_cur):\n",
    "            if rncur.startswith('S05'):\n",
    "                iS05 += [i]\n",
    "        for i in iS05[::-1]:\n",
    "            del rawnames_dict[k][i]\n",
    "\n",
    "rns = rawnames_dict['off_Mvt_best'] + rawnames_dict['on_Mvt']\n",
    "z = zip(rns[::2], rns[1::2])\n",
    "per_subj_tasks_merged = list(z)\n",
    "per_subj_tasks_merged = [ rawnames_dict['off_unsure'] ] + per_subj_tasks_merged\n",
    "\n",
    "import pandas as pd\n",
    "rns_all = rawnames_dict['off_Mvt_best'] + rawnames_dict['on_Mvt']\n",
    "df = pd.DataFrame({'rawname':rns_all})\n",
    "df['medcond'] = df['rawname'].apply(lambda x: x.split('_')[1])\n",
    "df['subject'] = df['rawname'].apply(lambda x: x.split('_')[0])\n",
    "df['task'] = df['rawname'].apply(lambda x: x.split('_')[2])\n",
    "# need both medcond otherwise we cannot do across them\n",
    "grp = df.groupby(['subject','task'])\n",
    "assert grp.size().min() == 2\n",
    "r = map(list, list(grp.apply(lambda dftmp: dftmp['rawname'].values).values) )\n",
    "per_medcond_tasks_merged = list(r)\n",
    "\n",
    "grp = df.groupby(['subject'])\n",
    "assert grp.size().min() == 4\n",
    "r = map(list, list(grp.apply(lambda dftmp: dftmp['rawname'].values).values) )\n",
    "per_subj_task_and_medcond_merged = list(r)\n",
    "##############################################\n",
    "rawnames_list = []\n",
    "if join_subjects:  # muti subject within one run\n",
    "    if not join_medcond:\n",
    "        if inc_S03:\n",
    "            rawnames_list += [ ('normal', rawnames_dict['off_Mvt'] ) ] \n",
    "        else:\n",
    "            rawnames_list += [ ('normal', rawnames_dict['off_Mvt_best'] ) ] \n",
    "        if inc_noMvt:\n",
    "            raise ValueError('not implemented')\n",
    "\n",
    "        rawnames_list += [ ('normal',rawnames_dict['on_Mvt']) ] \n",
    "\n",
    "        if inc_noMvt:\n",
    "            raise ValueError('not implemented')\n",
    "    else:\n",
    "        if inc_S03:\n",
    "            kk = 'off_Mvt'\n",
    "        else:\n",
    "            kk = 'off_Mvt_best'\n",
    "        rns = rawnames_dict[kk] + rawnames_dict['on_Mvt']\n",
    "\n",
    "        rawnames_list += [ ('normal',rns ) ] \n",
    "else:\n",
    "    if not join_medcond:\n",
    "        for tpl in per_subj_tasks_merged:\n",
    "            rawnames_list += [ ('normal', list(tpl) ) ] \n",
    "    else:\n",
    "        #rr = per_medcond_tasks_merged\n",
    "        #rawnames_list = list(zip(len(rr)*['normal'],rr))       \n",
    "        rr = per_subj_task_and_medcond_merged\n",
    "        rawnames_list = list(zip(len(rr)*['normal'],rr))\n",
    "\n",
    "############################################## def test rawnames\n",
    "if join_subjects:\n",
    "    if join_medcond:\n",
    "        rn_test =  ('test',[ 'S01_off_hold','S01_on_move', 'S04_off_hold', 'S05_off_move'] ) \n",
    "    else:\n",
    "        rn_test =  ('test',[ 'S01_off_hold', 'S04_off_hold', 'S04_off_move', ] ) \n",
    "else:\n",
    "    if not join_medcond:\n",
    "        rn_test =  ('test',[ 'S04_off_hold', 'S04_off_move'] ) \n",
    "    else: # need all 4 datasets because want to test all 4 classes\n",
    "        rn_test =  ('test',[ 'S04_off_hold','S04_off_move', 'S04_on_hold','S04_on_move'] ) \n",
    "rawnames_list += [rn_test]\n",
    "##############################################\n",
    "pfstr_per_rnt = {}    \n",
    "pfstr_per_rnt ['normal'] = ' --param_file ' + runpars['param_file_normal'] \n",
    "pfstr_per_rnt ['test']   = ' --param_file ' + runpars['param_file_normal_fast']\n",
    "\n",
    "#############################################\n",
    "BANDS_BETA = 'beta'\n",
    "BANDS_GAMMA = 'gamma'\n",
    "BANDS_TREMOR = 'tremor'\n",
    "rslist_cur = []\n",
    "\n",
    "if \"PREFIXES_MAIN\" in prefixes_types:  # no side\n",
    "    rslist_cur += [('modLFP',              '--mods LFP')]\n",
    "    rslist_cur += [('onlyH_act',           '--feat_types H_act')]        \n",
    "    rslist_cur += [('onlyH',               '--feat_types H_act,H_mob,H_compl')]        \n",
    "    rslist_cur += [('modSrc_self',         '--self_couplings_only 1 --mods msrc')]\n",
    "    rslist_cur += [('LFPrel_noself',       '--LFP_related_only 1  --cross_couplings_only 1')] \n",
    "    rslist_cur += [('allb_beta_noH',       f'--fbands {BANDS_BETA}  --feat_types con,rbcorr')]\n",
    "    rslist_cur += [('allb_gamma_noH',      f'--fbands {BANDS_GAMMA}   --feat_types con,rbcorr')]\n",
    "    rslist_cur += [('allb_tremor_noH',    f'--fbands {BANDS_TREMOR}  --feat_types con,rbcorr')]\n",
    "    rslist_cur += [('modSrc',              '--mods msrc')]   \n",
    "    \n",
    "if \"PREFIXES_SPECIFIC\" in prefixes_types:  # no side\n",
    "    rslist_cur += [('modLFP',              '--mods LFP')]\n",
    "    rslist_cur += [('onlyH_act',           '--feat_types H_act')]    \n",
    "    \n",
    "if \"PREFIXES_H_SEP\" in prefixes_types:   # no side\n",
    "    rslist_cur += [('onlyH_mob',             '--feat_types H_mob')]        \n",
    "    rslist_cur += [('onlyH_compl',           '--feat_types H_compl')]   \n",
    "    \n",
    "if \"PREFIXES_SPECIFIC_SIDED\" in prefixes_types:\n",
    "    # note that I don't want modLFP because I don't compute other feature types besides Hjorth\n",
    "    if test_best_LFP_disjointness:\n",
    "        rslist_cur += [('onlyH_act_bestLFPdisj',              '--feat_types H_act  --best_LFP_disjoint 1')]        \n",
    "        rslist_cur += [('onlyH_bestLFPdisj',                  '--feat_types H_act,H_mob,H_compl  --best_LFP_disjoint 1')]        \n",
    "        rslist_cur += [('onlyH_act_bestLFPoverlap',           '--feat_types H_act  --best_LFP_disjoint 0')]        \n",
    "        rslist_cur += [('onlyH_bestLFPoverlap',               '--feat_types H_act,H_mob,H_compl  --best_LFP_disjoint 0')]        \n",
    "    else:\n",
    "        rslist_cur += [('onlyH_act',           '--feat_types H_act')]                \n",
    "        rslist_cur += [('onlyH_act_modLFP',    '--mods LFP --feat_types H_act')]\n",
    "        # next two are specific to this runstrings set\n",
    "        for sfct in ['subj','task','no']:\n",
    "            adds =  f' --scale_feat_combine_type {sfct} '\n",
    "            rslist_cur += [(f'onlyH_act_sc{sfct}',           '--feat_types H_act' + adds)]                \n",
    "            rslist_cur += [(f'onlyH_act_modLFP_sc{sfct}',    '--mods LFP --feat_types H_act' + adds)]\n",
    "        \n",
    "        if calc_all_Hjorth:\n",
    "            rslist_cur += [('onlyH_modLFP',        '--mods LFP --feat_types H_act,H_mob,H_compl')]\n",
    "            rslist_cur += [('onlyH',               '--feat_types H_act,H_mob,H_compl')]        \n",
    "            rslist_cur += [('onlyH_mob',             '--feat_types H_mob')]        \n",
    "            rslist_cur += [('onlyH_compl',           '--feat_types H_compl')]        \n",
    "\n",
    "display('rawnames_list', rawnames_list)\n",
    "display('prefixes_types', prefixes_types)\n",
    "display('pfstr_per_rnt', pfstr_per_rnt)\n",
    "display( g_it_strs, rslist_cur )\n",
    "\n",
    "assert len(rslist_cur) == len(set(rslist_cur))  # I don't want reapeats\n",
    "prefs = list( list( zip(*rslist_cur) )[0] )\n",
    "assert len(prefs) == len(set(prefs)), prefs  # I don't want reapeats even in prefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2972089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = set(list(range(256 ))) - \\\n",
    "# set([0,1,2,5,6,9,10,13,14,17,18,21,22,25,26,29,30,33,34,35,36,37,38,41,42,43,45,46,47,49,50,53,54,55,56,57,58,59,60,61,62,65,66,69,70,73,74,77,78,79,80,81,82,83,84,85,86,89,90,93,94,97,98,99,101,102,103,105,106,107,108,109,110,113,114,117,118,121,122,125,126,127,128,129,130,131,132,133,134,137,138,141,142,145,146,149,150,151,152,153,154,155,156,157,158,161,162,165,166,169,170,171,172,173,174,175,176,177,178,179,180,181,182,185,186,187,188,189,190,193,194,197,198,199,200,201,202,203,204,205,206,209,210,213,214,217,218,221,222,223,224,225,226,227,229,230,233,234,237,238,241,242,245,246,247,249,250,253,254])\n",
    "# ','.join( map(str, list(r) )) \n",
    "\n",
    "# p = [100,104,11,11,111,112,115,115,116,116,119,12,12,120,123,123,124,135,135,136,139,140,143,144,147,148,15,159,159,16,160,160,163,164,167,168,183,184,19,191,192,195,196,20,207,208,211,212,215,216,219,220,228,23,231,232,235,236,239,24,240,243,244,248,251,252,255,27,28,3,31,32,39,4,40,44,48,51,52,63,64,67,68,7,71,72,75,75,76,8,87,88,91,92,95,96]\n",
    "# #-------------------- prefixes COMPLETED, N=176\n",
    "# c = [0,1,2,5,6,9,10,13,14,17,18,21,22,25,26,29,30,33,34,35,36,37,38,41,42,43,45,46,47,49,50,53,54,55,56,57,58,59,60,61,62,65,66,69,70,73,74,77,78,79,80,81,82,83,84,85,86,89,90,93,94,97,98,99,101,102,103,105,106,107,108,109,110,113,114,117,118,121,122,125,126,127,128,129,130,131,132,133,134,137,138,141,142,145,146,149,150,151,152,153,154,155,156,157,158,161,162,165,166,169,170,171,172,173,174,175,176,177,178,179,180,181,182,185,186,187,188,189,190,191,193,194,195,197,198,199,200,201,202,203,204,205,206,209,210,213,214,217,218,219,221,222,223,224,225,226,227,228,229,230,233,234,237,238,241,242,243,245,246,247,248,249,250,251,253,254]\n",
    "# #----\n",
    "# lst = list( set(c) - set(p) ) \n",
    "# print(  ','.join( map(str,lst))   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad821ad",
   "metadata": {},
   "source": [
    "# Generate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd842f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "rawnames_list,prefixes_types,g_it_strs,modes,runpars,run_corresp_id,pfstr_per_rnt,rslist_cur, side_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fea280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%debug\n",
    "save = True\n",
    "from utils_runstrings_gen_HPC import genRunstringsML\n",
    "runstrings,runstrings_per_rnt,pref2pgn = \\\n",
    "    genRunstringsML(rawnames_list,prefixes_types,g_it_strs,modes,runpars,\n",
    "               run_corresp_id,pfstr_per_rnt,rslist_cur, side_tuples)\n",
    "\n",
    "n_testrunstr_to_include = 1\n",
    "if n_testrunstr_to_include > 0:\n",
    "    runstrings = runstrings_per_rnt['test'][:n_testrunstr_to_include] + runstrings\n",
    "\n",
    "srs = set(runstrings)\n",
    "assert len(srs) == len(runstrings),  f'there are repeating runstrings {len(srs)} , {len(runstrings)}'\n",
    "\n",
    "####################\n",
    "        \n",
    "from os.path import join as pjoin\n",
    "import json\n",
    "\n",
    "if save:\n",
    "    fname_full_runstr = pjoin(gv.code_dir, 'run', fname_runstr)\n",
    "    with open( fname_full_runstr, 'w' ) as f:\n",
    "        for s in runstrings:\n",
    "            f.write(s + '\\n')\n",
    "    fname_full_runstr_archive = pjoin(gv.code_dir, 'run', f'__{fname_runstr[:-4]}_{run_corresp_id}.json')\n",
    "    with open( fname_full_runstr, 'w' ) as f:\n",
    "        for s in runstrings:\n",
    "            f.write(s + '\\n')\n",
    "            \n",
    "    print(fname_full_runstr)\n",
    "    print(fname_full_runstr_archive)\n",
    "\n",
    "c = {'correspondance':pref2pgn, 'prefixes_types':prefixes_types, \n",
    "         'param_dir_str':pfstr_per_rnt ['normal'], 'rawnames_list':rawnames_list,\n",
    "        'comment':comment, 'runpars':runpars, 'runstrings':runstrings}\n",
    "if save:\n",
    "    fn = pjoin(gv.code_dir, 'run', f'___run_corresp_{run_corresp_id}.txt')    \n",
    "    with open(fn , 'w' ) as f:\n",
    "        json.dump(c, f, indent =2)\n",
    "#     f.write(json.dumps(pref2pgn))\n",
    "\n",
    "    print(fn)\n",
    "    print(f'Saved res for run_corresp_id = {run_corresp_id}')\n",
    "    \n",
    "print('len(runstrings) = ', len(runstrings))\n",
    "#####################  check prefix repeats\n",
    "# yes, I want to run it AFTER saving so that I can eyeball runstrings and also because test \n",
    "# string is indeed repeating sometimes\n",
    "rows = []\n",
    "for rs in runstrings[1:]: # skip test runstring\n",
    "    tt = rs.split()[1:]\n",
    "    d = dict(zip( tt[::2], tt[1::2] ))\n",
    "    rows += [d]\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "grp = df.groupby(['--input_subdir', '-r','--groupings_to_use', '--int_types_to_use',  '--prefix'] )\n",
    "dfsz = grp.size().reset_index()\n",
    "\n",
    "mx = dfsz[0].max()\n",
    "dfbad = dfsz[dfsz[0] > 1]\n",
    "ds = dfbad.to_dict('records')\n",
    "#print('There are ', len(ds), ' prefixes like that' )\n",
    "assert mx == 1, f'Some prefixes repeates {mx} times, for {len(ds)} prefixes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fb0828",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db99071e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f265793",
   "metadata": {},
   "outputs": [],
   "source": [
    "runstrings[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de336804",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# query strings don't work with dashes, so bruteforce\n",
    "for ind in range(min(4, len(ds)) ):\n",
    "    c = np.ones(len(df), dtype=bool)\n",
    "    for k,v in ds[ind].items():\n",
    "        if k == 0:\n",
    "            continue\n",
    "        c &= df[k] == v\n",
    "    display(df[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925108d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6738d2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(runstrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807027c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "runpars['input_output_subdir_pairs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aed929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884c0677",
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "cts = Counter(runstrings)\n",
    "#for rs in runstrings:\n",
    "#    rs.count()\n",
    "#cts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77919eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyH_modLFP_subskip8BB, both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fde0be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "runstrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f33ad34",
   "metadata": {},
   "outputs": [],
   "source": [
    "unpars['run_specific_args']#len(runstrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84c22a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inds=[661,663,665,667,669,671,673,675,677,679,681,683,685,687,689,691,693,695,697,699,701,703]\n",
    "rs = np.array(runstrings)[inds]\n",
    "rs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fd08b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eb7406",
   "metadata": {},
   "source": [
    "## find inds to recalc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22a9d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd4a2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bf07c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "','.join( map(str, set( [i % 256 for i in inds] ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b7eb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set( [i % 256 for i in inds] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cc53b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rn = 'S05_off'\n",
    "for rsi,rs in enumerate(runstrings):\n",
    "    if rs.find('_test') >= 0 or rs.find('_fast') >= 0:\n",
    "        continue\n",
    "    items = rs.split()\n",
    "    a = items[1::2]\n",
    "    b = items[2::2]\n",
    "    d = dict( zip(a,b) )\n",
    "\n",
    "    c1 = d['-r'].find(rn) >= 0 \n",
    "    #c2 = d['--prefix'] in key_founds\n",
    "\n",
    "    if c1:\n",
    "        inds += [rsi]\n",
    "        rsis += [rsi]\n",
    "        print(f'{rsi:4} = {rn} ')\n",
    "        #print(rsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e56c9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_recalc = [('S05_on',   'onlyH_act_only22') ]\n",
    "to_recalc = [('S05_on',   None) ]\n",
    "\n",
    "\n",
    "rsis = []\n",
    "for rn,name in to_recalc:\n",
    "    key_founds = []\n",
    "    for key,item in pref2pgn.items():\n",
    "        if name is None:\n",
    "            continue\n",
    "        if item[1] == name:\n",
    "            key_founds += [key]\n",
    "    if not len(key_founds) and (name in pref2pgn):\n",
    "        key_founds = [name]\n",
    "        roi = pref2pgn[name][1]\n",
    "    else:\n",
    "        roi = name\n",
    "    print('key_founds = ', key_founds)\n",
    "        \n",
    "    for rsi,rs in enumerate(runstrings):\n",
    "        if rs.find('_test') >= 0 or rs.find('_fast') >= 0:\n",
    "            continue\n",
    "        items = rs.split()\n",
    "        a = items[1::2]\n",
    "        b = items[2::2]\n",
    "        d = dict( zip(a,b) )\n",
    "        \n",
    "        c1 = d['-r'].find(rn) >= 0 \n",
    "        c2 = d['--prefix'] in key_founds\n",
    "        \n",
    "        if c1 and c2:\n",
    "            rsis += [rsi]\n",
    "            print(f'{rsi:4} = {rn} : {roi:18} -> {d[\"--prefix\"]}')\n",
    "            #print(rsi)\n",
    "            \n",
    "rsis = list(sorted(set(rsis)))\n",
    "print('\\nto be given to sbatch: ', rsis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0507932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "264 - 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3ec847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e09eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e7d5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pref2pgn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6e4dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pref2pgn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90766197",
   "metadata": {},
   "outputs": [],
   "source": [
    "runpars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad62727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pref2pgn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e69f81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prefixes_types, pfstr_per_rnt ['normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e22a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#runstrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af4b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pref2pgn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2f90a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_globinds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbab422",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(runstrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c238bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#special_globinds_mod = special_globinds\n",
    "special_globinds_mod = [gi + n_testrunstr_to_include for gi in special_globinds]\n",
    "#[runstrings[gi][120:-93] for gi in special_globinds_mod]\n",
    "runstrings_sub = [runstrings[gi] for gi in special_globinds_mod]\n",
    "display( runstrings_sub )\n",
    "#special_globinds_mod\n",
    "print( ','.join(map(str,special_globinds_mod) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e45bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(runstrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e637094",
   "metadata": {},
   "outputs": [],
   "source": [
    "sis = []\n",
    "for rsi,rs in enumerate(runstrings):\n",
    "    #if rs.find('--mods LFP') >= 0:\n",
    "    if rs.find('15') >= 0:\n",
    "        sis += [rsi]\n",
    "        print(rs)\n",
    "print( ','.join(map(str,sis) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d513a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "corresp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de14e7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b6af71",
   "metadata": {},
   "outputs": [],
   "source": [
    "runstrings_per_rnt['test' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48317c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "runstrings_per_rnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ed2d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gv.data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896cd42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f2fe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pref2pgn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ef4c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8a1718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae592ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "runstrings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefc2479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3921962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1d1b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dddb865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cobd",
   "language": "python",
   "name": "cobd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
