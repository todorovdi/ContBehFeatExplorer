{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b3d8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vard = {}  # ONLY RUN IN THE VERY BEGINNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40709f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective':'reg:squarederror',\n",
    "}\n",
    "\n",
    "params['objective'] ='multi:softprob'\n",
    "params['eval_metric'] = 'mlogloss'\n",
    "\n",
    "num_boost_round = 100  #Its optimal value highly depends on the other parameters, and thus it should be re-tuned each time you update a parameter.\n",
    "Npts = 400\n",
    "np.set_printoptions(precision=4, suppress=1)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%precision %.4f\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa63334c",
   "metadata": {},
   "source": [
    "### 2 feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9785af85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_order = []\n",
    "# ['2_classes_2feats_1_signif_feat_corr0', '3_classes_2feats_1_signif_feat_corr0',\n",
    "#         '3_classes_3feats_1_signif_feat_corr0', '3_classes_3feats_2_signif_feat_corr2']\n",
    "\n",
    "dcur = {}\n",
    "keyname = '2_classes_2feats_1_signif_feat_corr0'\n",
    "tests_order += [keyname]\n",
    "vard[keyname] = dcur\n",
    "\n",
    "\n",
    "nfeats = 2; \n",
    "X_train = np.random.uniform(-1,1, size=(Npts,nfeats)) * 1e-1\n",
    "y_train = np.zeros(Npts,dtype=int) \n",
    "#\n",
    "y_train[:Npts//2] = 1\n",
    "#\n",
    "X_train[:Npts//2+2,0]  += 10\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "params_cur = dict(params.items())\n",
    "params_cur['num_class'] = len ( set(y_train) )\n",
    "\n",
    "dcur['X'] = X_train\n",
    "dcur['y'] = y_train\n",
    "dcur['dtrain'] = dtrain\n",
    "dcur['params'] = params_cur\n",
    "\n",
    "\n",
    "############################\n",
    "\n",
    "dcur = {}\n",
    "keyname = '2_classes_2feats_2_signif_feat_corr2'\n",
    "tests_order += [keyname]\n",
    "vard[keyname] = dcur\n",
    "\n",
    "\n",
    "nfeats = 2; \n",
    "X_train = np.random.uniform(-1,1, size=(Npts,nfeats)) * 1e-1\n",
    "y_train = np.zeros(Npts,dtype=int)\n",
    "#\n",
    "y_train[:Npts//2] = 1\n",
    "#\n",
    "X_train[:Npts//2+2,0]  += 10\n",
    "X_train[:,1]  += X_train[:,0]\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "params_cur = dict(params.items())\n",
    "params_cur['num_class'] = len ( set(y_train) )\n",
    "\n",
    "dcur['X'] = X_train\n",
    "dcur['y'] = y_train\n",
    "dcur['dtrain'] = dtrain\n",
    "dcur['params'] = params_cur\n",
    "\n",
    "############################\n",
    "\n",
    "dcur = {}\n",
    "keyname = '3_classes_2feats_1_signif_feat_corr0'\n",
    "tests_order += [keyname]\n",
    "vard[keyname] = dcur\n",
    "\n",
    "nfeats = 2; \n",
    "X_train = np.random.uniform(-1,1, size=(Npts,nfeats)) * 1e-1\n",
    "y_train = np.zeros(Npts,dtype=int)\n",
    "#\n",
    "y_train[:Npts//2] = 1\n",
    "y_train[Npts//4:Npts//2] = 2\n",
    "#\n",
    "X_train[:Npts//2+2,0]  += 1.5\n",
    "X_train[Npts//4:Npts//2,0]  += 10\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "params_cur = dict(params.items())\n",
    "params_cur['num_class'] = len ( set(y_train) )\n",
    "\n",
    "dcur['X'] = X_train\n",
    "dcur['y'] = y_train\n",
    "dcur['dtrain'] = dtrain\n",
    "dcur['params'] = params_cur\n",
    "\n",
    "############################\n",
    "\n",
    "dcur = {}\n",
    "keyname = '3_classes_2feats_1_signif_feat_corr2'\n",
    "tests_order += [keyname]\n",
    "vard[keyname] = dcur\n",
    "\n",
    "nfeats = 2; \n",
    "X_train = np.random.uniform(-1,1, size=(Npts,nfeats)) * 1e-1\n",
    "y_train = np.zeros(Npts,dtype=int)\n",
    "#\n",
    "y_train[:Npts//2] = 1\n",
    "y_train[Npts//4:Npts//2] = 2\n",
    "#\n",
    "X_train[:Npts//2+2,0]  += 1.5\n",
    "X_train[Npts//4:Npts//2,0]  += 10\n",
    "X_train[:,1]  += X_train[:,0]\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "params_cur = dict(params.items())\n",
    "params_cur['num_class'] = len ( set(y_train) )\n",
    "\n",
    "dcur['X'] = X_train\n",
    "dcur['y'] = y_train\n",
    "dcur['dtrain'] = dtrain\n",
    "dcur['params'] = params_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bde933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "\n",
    "dcur = {}\n",
    "keyname = '3_classes_3feats_1_signif_feat_corr0'\n",
    "tests_order += [keyname]\n",
    "vard[keyname] = dcur\n",
    "\n",
    "nfeats = 3; \n",
    "X_train = np.random.uniform(-1,1, size=(Npts,nfeats)) * 1e-1\n",
    "y_train = np.zeros(Npts,dtype=int)\n",
    "#\n",
    "y_train[:Npts//2] = 1\n",
    "y_train[Npts//4:Npts//2] = 2\n",
    "#\n",
    "X_train[:Npts//2+2,0]  += 1.5\n",
    "X_train[Npts//4:Npts//2,0]  += 10\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "params_cur = dict(params.items())\n",
    "params_cur['num_class'] = len ( set(y_train) )\n",
    "\n",
    "dcur['X'] = X_train\n",
    "dcur['y'] = y_train\n",
    "dcur['dtrain'] = dtrain\n",
    "dcur['params'] = params_cur\n",
    "\n",
    "\n",
    "####################\n",
    "\n",
    "dcur = {}\n",
    "keyname = '3_classes_3feats_2_signif_feat_corr2'\n",
    "tests_order += [keyname]\n",
    "vard[keyname] = dcur\n",
    "\n",
    "nfeats = 3\n",
    "X_train = np.random.uniform(-1,1, size=(Npts,nfeats)) * 1e-1\n",
    "y_train = np.zeros(Npts,dtype=int)\n",
    "#\n",
    "y_train[:Npts//2] = 1\n",
    "y_train[Npts//4:Npts//2] = 2\n",
    "#\n",
    "X_train[:Npts//2+2,0]  += 1.5\n",
    "X_train[Npts//4:Npts//2,0]  += 10\n",
    "X_train[:,1] += X_train[:,0] \n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "params_cur = dict(params.items())\n",
    "params_cur['num_class'] = len ( set(y_train) )\n",
    "\n",
    "dcur['X'] = X_train\n",
    "dcur['y'] = y_train\n",
    "dcur['dtrain'] = dtrain\n",
    "dcur['params'] = params_cur\n",
    "\n",
    "####################\n",
    "\n",
    "dcur = {}\n",
    "keyname = '3_classes_3feats_2_signif_feat_corr2_0.5'\n",
    "tests_order += [keyname]\n",
    "vard[keyname] = dcur\n",
    "\n",
    "nfeats = 3\n",
    "X_train = np.random.uniform(-1,1, size=(Npts,nfeats)) * 1e-1\n",
    "y_train = np.zeros(Npts,dtype=int)\n",
    "#\n",
    "y_train[:Npts//2] = 1\n",
    "y_train[Npts//4:Npts//2] = 2\n",
    "#\n",
    "X_train[:Npts//2+2,0]  += 1.5\n",
    "X_train[Npts//4:Npts//2,0]  += 10\n",
    "X_train[:,1] += X_train[:,0] / 2\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "params_cur = dict(params.items())\n",
    "params_cur['num_class'] = len ( set(y_train) )\n",
    "\n",
    "dcur['X'] = X_train\n",
    "dcur['y'] = y_train\n",
    "dcur['dtrain'] = dtrain\n",
    "dcur['params'] = params_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0438f4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "\n",
    "dcur = {}\n",
    "keyname = '3_classes_6feats_2_signif_feat_corr2'\n",
    "tests_order += [keyname]\n",
    "vard[keyname] = dcur\n",
    "\n",
    "nfeats = 6\n",
    "X_train = np.random.uniform(-1,1, size=(Npts,nfeats)) * 1e-1\n",
    "y_train = np.zeros(Npts,dtype=int)\n",
    "#\n",
    "y_train[:Npts//2] = 1\n",
    "y_train[Npts//4:Npts//2] = 2\n",
    "#\n",
    "X_train[:Npts//2+2,5]  += 1.5\n",
    "X_train[Npts//4:Npts//2,5]  += 10\n",
    "X_train[:,3] += X_train[:,5] \n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "params_cur = dict(params.items())\n",
    "params_cur['num_class'] = len ( set(y_train) )\n",
    "\n",
    "dcur['X'] = X_train\n",
    "dcur['y'] = y_train\n",
    "dcur['dtrain'] = dtrain\n",
    "dcur['params'] = params_cur\n",
    "\n",
    "####################\n",
    "\n",
    "dcur = {}\n",
    "keyname = '3_classes_10feats_8_signif_feat_corr8'\n",
    "tests_order += [keyname]\n",
    "vard[keyname] = dcur\n",
    "\n",
    "nfeats = 10\n",
    "X_train = np.random.uniform(-1,1, size=(Npts,nfeats)) * 1e-1\n",
    "y_train = np.zeros(Npts,dtype=int)\n",
    "#\n",
    "y_train[:Npts//2] = 1\n",
    "y_train[Npts//4:Npts//2] = 2\n",
    "#\n",
    "X_train[:Npts//2+2,0]  += 1.5\n",
    "X_train[Npts//4:Npts//2,0]  += 10\n",
    "X_train[:,1:8] += X_train[:,0][:,None] \n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "params_cur = dict(params.items())\n",
    "params_cur['num_class'] = len ( set(y_train) )\n",
    "\n",
    "dcur['X'] = X_train\n",
    "dcur['y'] = y_train\n",
    "dcur['dtrain'] = dtrain\n",
    "dcur['params'] = params_cur\n",
    "\n",
    "\n",
    "####################\n",
    "\n",
    "dcur = {}\n",
    "keyname = '3_classes_10feats_8_signif_feat_corr8_network'\n",
    "tests_order += [keyname]\n",
    "vard[keyname] = dcur\n",
    "\n",
    "nfeats = 10\n",
    "X_train = np.random.uniform(-1,1, size=(Npts,nfeats)) * 1e-1\n",
    "y_train = np.zeros(Npts,dtype=int)\n",
    "#\n",
    "y_train[:Npts//2] = 1\n",
    "y_train[Npts//4:Npts//2] = 2\n",
    "# 0 and 5 have meaningful info but they are not correlated\n",
    "X_train[:Npts//2+2,0]       += 1.5\n",
    "X_train[Npts//4:Npts//2,0]  += 10\n",
    "#\n",
    "X_train[:Npts//2+2,6]       -= 10 * np.linspace(1,2, (X_train.shape[0]-Npts//2+2) )\n",
    "X_train[Npts//4:Npts//2,6]  -= 2.5\n",
    "# 0->1   \n",
    "X_train[:,1] += X_train[:,0] \n",
    "# 6->7  (0.5)\n",
    "X_train[:,7] += X_train[:,6]  / 0.5\n",
    "# 6->2 noise   \n",
    "X_train[:,2] += X_train[:,6] + np.random.uniform(-1,1, size=(Npts)) * 2\n",
    "# 0,6 -> 4\n",
    "X_train[:,4] += X_train[:,0]  * 0.25 + X_train[:,6]  * 0.75\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "params_cur = dict(params.items())\n",
    "params_cur['num_class'] = len ( set(y_train) )\n",
    "\n",
    "dcur['X'] = X_train\n",
    "dcur['y'] = y_train\n",
    "dcur['dtrain'] = dtrain\n",
    "dcur['params'] = params_cur\n",
    "\n",
    "ground_truth_graph = [(1,0,1.,None), (7,6,1/0.5,None), (2,6,1.,2.), (4,0,0.25,None), (4,6,0.75,None) ]\n",
    "dcur['ground_truth_graph'] = ground_truth_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18d8d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vard['3_classes_10feats_8_signif_feat_corr8_network']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d264aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(vard) == len(tests_order)\n",
    "for dcur in vard.values():\n",
    "    dcur['X'] += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71639d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vard['3_classes_10feats_8_signif_feat_corr8_network']['X'][:,0] )\n",
    "plt.plot(vard['3_classes_10feats_8_signif_feat_corr8_network']['X'][:,6] )\n",
    "plt.plot(vard['3_classes_10feats_8_signif_feat_corr8_network']['X'][:,4] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ec1945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7e1213",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vard['3_classes_10feats_8_signif_feat_corr8_network']['X'][:,2] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ce8186",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = int(np.ceil( len(vard) / 3) ) ; nr = int(np.ceil(len(vard) / nc) );  ww = 5; hh = 3\n",
    "fig,axs = plt.subplots(nr,nc,figsize=(nc*ww,nr*hh))\n",
    "axs = axs.reshape((1,nr*nc))\n",
    "#for i,(k,dcur) in enumerate(vard.items() ):\n",
    "for i,k in enumerate(tests_order ):\n",
    "    dcur = vard[k]\n",
    "    ax = axs[0,i]\n",
    "    X = dcur['X']\n",
    "    y = dcur['y']\n",
    "    ax.plot(y,label='label',ls='--')\n",
    "    for i in range(X.shape[1]):\n",
    "        ax.plot(X[:,i], label=f'feat {i}')\n",
    "    ax.set_title(k)\n",
    "    ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b24e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for to,fr,v,noise in ground_truth_graph:\n",
    "#     print(f'{fr}->{to}',v,noise,  scores_reconstructed[:,fr], scores_reconstructed[:,to])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73268d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_tSNE import reconstructFullScoresFromVIFScores\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from interpret.privacy import DPExplainableBoostingClassifier\n",
    "\n",
    "    \n",
    "from utils_tSNE import getScoresPerClass\n",
    "from utils_tSNE import findBadColumnsVIF\n",
    "rev = 1\n",
    "for k in tests_order:\n",
    "    print(f' {k}')\n",
    "    dcur = vard[k]\n",
    "    X_train = dcur['X']\n",
    "    y_train = dcur['y']\n",
    "    dtrain = dcur['dtrain']\n",
    "    params_cur = dcur['params']\n",
    "    params_cur['random_state'] = 9\n",
    "\n",
    "    bst = xgb.train(params_cur, dtrain ) #, early_stopping_rounds=10)\n",
    "    shap_values = bst.predict(dtrain, pred_contribs=True)\n",
    "    dcur['shap_values'] = shap_values\n",
    "    scores_per_class,bias = getScoresPerClass(y_train ,   shap_values, 1)\n",
    "    dcur['scores_per_class'] = scores_per_class\n",
    "    dcur['bias'] = bias\n",
    "    \n",
    "    ebm = ExplainableBoostingClassifier( feature_names=list( map(str, range(X_train.shape[1])) )  )\n",
    "    ebm.fit(X_train,y_train)\n",
    "    #break\n",
    "    dcur['ebm'] = ebm\n",
    "    \n",
    "    ebm2 = DPExplainableBoostingClassifier( feature_names=list( map(str, range(X_train.shape[1])) )  )\n",
    "    ebm2.fit(X_train,y_train)\n",
    "    #break\n",
    "    dcur['dpebm'] = ebm2\n",
    "    continue\n",
    "    \n",
    "    colinds_bad,cols_good, vfs_list, featsets_list, linreg_objs, exogs_list = \\\n",
    "        findBadColumnsVIF(dcur['X'], n_jobs=-1,printLog=0, rev=rev)\n",
    "    dcur['VIF_info'] = colinds_bad,cols_good, vfs_list, featsets_list, linreg_objs, exogs_list\n",
    "    print(f'num VIF sel good {len(cols_good)} of all {X_train.shape[1]}' )\n",
    "    \n",
    "    dtrain_VIF = xgb.DMatrix(X_train[:,cols_good],y_train)\n",
    "    bst_VIF = xgb.train(params_cur, dtrain_VIF ) #, early_stopping_rounds=10)\n",
    "    shap_values_VIF = bst_VIF.predict(dtrain_VIF, pred_contribs=True)\n",
    "    scores_per_class_VIF,bias_VIF = getScoresPerClass(y_train ,   shap_values_VIF, 1)\n",
    "    dcur['scores_per_class_VIF'] = scores_per_class_VIF\n",
    "    dcur['bias_VIF'] = bias_VIF\n",
    "    \n",
    "    scores_reconstructed = reconstructFullScoresFromVIFScores(scores_per_class_VIF, scores_per_class.shape[1],\n",
    "                                   colinds_bad,cols_good, featsets_list, linreg_objs, exogs_list )\n",
    "    dcur['scores_reconstructed'] = scores_reconstructed\n",
    "    \n",
    "#     if k == '2_classes_2feats_2_signif_feat_corr2':\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f093ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "expl = ebm2.explain_local(X_train,y_train)\n",
    "loc_expls = expl.data(slice(None,None))\n",
    "\n",
    "expl2 = ebm2.explain_local(X_train,y_train)\n",
    "loc_expls2 = expl.data(slice(None,None))\n",
    "\n",
    "from utils_postprocess_HPC import EBMlocExpl2scores\n",
    "r,true_labels,predicted_labels,featnames_ebm = EBMlocExpl2scores(loc_expls,1)\n",
    "r2,true_labels2,predicted_labels2,featnames_ebm2 = EBMlocExpl2scores(loc_expls2,1)\n",
    "r.shape, r2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c434eab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_expls[i]['scores'], loc_expls[i]['names'], loc_expls[i]['extra']['scores'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44670084",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_expls2[i]['scores'], loc_expls2[i]['names'], loc_expls2[i]['extra']['scores'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722e8b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loc_expls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e96f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret import show\n",
    "show(expl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5b568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I expect 0-th feature (column) to be important everywhere\n",
    "for k in tests_order:\n",
    "    print('    ',k)\n",
    "    dcur = vard[k]\n",
    "    sc = dcur['scores_per_class']\n",
    "    for classid in range(sc.shape[0]):\n",
    "        print(classid,sc[classid])\n",
    "        \n",
    "    print('  VIF', dcur['VIF_info'][1])\n",
    "    sc = dcur['scores_per_class_VIF']\n",
    "    for classid in range(sc.shape[0]):\n",
    "        print(classid,sc[classid])\n",
    "        \n",
    "    print('  reconstructed')\n",
    "    sc = dcur['scores_reconstructed']\n",
    "    for classid in range(sc.shape[0]):\n",
    "        print(classid,sc[classid])\n",
    "        \n",
    "    print('                        bias = ',dcur['bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dffd216",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a76354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test reversal\n",
    "# revinds = np.arange(dcur['X'].shape[1])[::-1]\n",
    "# colinds_bad,cols_good, vfs_list, featsets_list, linreg_objs, exogs_list = \\\n",
    "#     findBadColumnsVIF(dcur['X'][:,revinds], n_jobs=-1,printLog=1)\n",
    "# colinds_bad = revinds[colinds_bad]\n",
    "# cols_good = revinds[cols_good]\n",
    "# for i,fs in enumerate(featsets_list):\n",
    "#     exogs = exogs_list[i]\n",
    "#     exogs_list[i] = revinds[ fs[exogs] ] # elements of colinds_good\n",
    "#     featsets_list[i] = revinds[fs]\n",
    "#     linreg_objs[i].coef_ = linreg_objs[i].coef_[::-1]\n",
    "colinds_bad,cols_good, vfs_list, featsets_list, linreg_objs, exogs_list = \\\n",
    "     findBadColumnsVIF(dcur['X'], n_jobs=-1,printLog=1, rev=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b0b1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check regression quality\n",
    "for i,badind in list(enumerate(colinds_bad)):\n",
    "    linreg_coef = linreg_objs[i].coef_\n",
    "    intercept = linreg_objs[i].intercept_\n",
    "    # these are indices (global) which we tried to regress FROM featsets_list[i]\n",
    "    exogs_glob_inds = featsets_list[i][exogs_list[i]]  # colinds_good\n",
    "    inds_regressed_from = np.setdiff1d( featsets_list[i] , [badind] )\n",
    "\n",
    "    s = list(zip(inds_regressed_from,[f'{c:.3f}' for c in linreg_coef]) )\n",
    "    print(badind,'<-', s, intercept )\n",
    "    \n",
    "    X_train = dcur['X']\n",
    "    y_train = dcur['y']\n",
    "    plt.figure(figsize=(10,2))\n",
    "    plt.plot(X_train[:,badind],lw=4)\n",
    "    tmp = np.dot( X_train[:,inds_regressed_from] , linreg_coef[:,None]) + intercept\n",
    "    plt.plot(tmp,ls='--',lw=4)\n",
    "    plt.plot(y_train)\n",
    "    plt.title(f'{badind} from {inds_regressed_from}__{s}\\n{scores_reconstructed[:,badind]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160c1ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_good, colinds_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c784ad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "featsets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529a10e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_per_class_VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bf2491",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructFullScoresFromVIFScores(scores_per_class_VIF, scores_per_class.shape[1],\n",
    "                                   colinds_bad,cols_good, featsets_list, linreg_objs, exogs_list ,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b53ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50172aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44cf227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.glassbox import ExplainableBoostingClassifier as EBM\n",
    "for k in tests_order:\n",
    "    print('    ',k)\n",
    "    dcur = vard[k]\n",
    "    X_train = dcur['X']\n",
    "    y_train = dcur['y']\n",
    "    ebm = EBM(random_state=0,n_jobs=-1)\n",
    "    ebm.fit(X_train, y_train)\n",
    "    global_exp = ebm.explain_global()\n",
    "    #dcur['EBM'] = ebm\n",
    "    dcur['EBM_global_exp'] = global_exp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fdcb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6def1756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret import show\n",
    "keyname = '3_classes_10feats_8_signif_feat_corr8'\n",
    "show(vard[keyname]['EBM_global_exp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d132af4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
