{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i run_process_FTsources.py -r S01_off_hold --do_save 1\\\n",
    "--groupings all_raw --alg_type all_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i run_process_FTsources.py -r S01_off_move --do_save 0\\\n",
    "--groupings all --alg_type \"PCA+ICA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_test = ['Cerebellum_L', 'Cerebellum_R']\n",
    "for lbl in lbl_test:\n",
    "    ind = labels.index(lbl)\n",
    "    print(lbl, ind)\n",
    "    print(ind-1, np.where( srcgroups_all  == ind-1)[0] )\n",
    "    print(ind  , np.where( srcgroups_all  == ind)[0] )\n",
    "    print(ind+1, np.where( srcgroups_all  == ind+1)[0] )\n",
    "#np.where( srcgroups_all  == 60)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(srcgroups_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels_deford)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(labels)[srcgroups_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for srcgroups_\n",
    "# the index of roi label should be same as in matlab. \n",
    "# The indeces of cources corresponding to this roi are shifted by -1, compared to matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_test = ['Cerebellum_L', 'Cerebellum_R']\n",
    "for lbl in lbl_test:\n",
    "    ind = labels.index(lbl)\n",
    "    print(lbl, ind)\n",
    "    print(ind-1, np.where( srcgroups_  == ind-1)[0] )\n",
    "    print(ind  , np.where( srcgroups_  == ind)[0] )\n",
    "    print(ind+1, np.where( srcgroups_  == ind+1)[0] )\n",
    "#np.where( srcgroups_all  == 60)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_groups_dict, srcgroups_dict  = utils.prepareSourceGroups(labels,srcgroups_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_groups_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iii =5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.src_grouping_names_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdn = 'all_raw'\n",
    "#sgdn = 'all'\n",
    "#sgdn = 'merged_by_side'\n",
    "sgdn = gp.src_grouping_names_order[iii]\n",
    "#sgdn = 'motor-related_incCB_vs_rest'\n",
    "print(sgdn)\n",
    "\n",
    "# motor-related_only inludes CB\n",
    "labels_cur = label_groups_dict[sgdn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrs = utils.vizGroup(sind_str,coords_resorted,labels_cur,\n",
    "               srcgroups_dict[sgdn], show=False, labels_to_skip = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mayavi.mlab as mam\n",
    "mam.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iii+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib as mpl\n",
    "# legels = []\n",
    "# s = 12\n",
    "# for i in range(len(labels_cur)):\n",
    "#     legel = mpl.lines.Line2D([0], [0], marker='o', color='w', label=labels[i],\n",
    "#                                     markerfacecolor=clrs[i], markersize=s)\n",
    "#     legels += [legel]\n",
    "# plt.legend(handles = legels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.legend\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import mne\n",
    "import utils  #my code\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import time\n",
    "import scipy.io as sio\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "if os.environ.get('DATA_DUSS') is not None:\n",
    "    data_dir = os.path.expandvars('$DATA_DUSS')\n",
    "else:\n",
    "    data_dir = '/home/demitau/data'\n",
    "    \n",
    "#rawname_ = 'S01_off_hold'\n",
    "#rawname_ = 'S01_on_hold'\n",
    "#rawname_ = 'S01_off_move'\n",
    "#rawname_ = 'S01_on_move'\n",
    "\n",
    "#rawname_ = 'S02_off_hold'\n",
    "#rawname_ = 'S02_on_hold'\n",
    "#rawname_ = 'S02_off_move'  \n",
    "#rawname_ = 'S02_on_move'\n",
    "\n",
    "rawname_ = 'S03_off_hold'  \n",
    "#rawname_ = 'S03_off_move'  \n",
    "\n",
    "#rawname_ = 'S04_off_hold'\n",
    "#rawname_ = 'S04_off_move'\n",
    "#rawname_ = 'S04_on_hold'\n",
    "#rawname_ = 'S04_on_move'\n",
    "\n",
    "#rawname_ = 'S05_off_hold'\n",
    "#rawname_ = 'S05_off_move'\n",
    "#rawname_ = 'S05_on_hold'\n",
    "#rawname_ = 'S05_on_move'\n",
    "\n",
    "#rawname_ = 'S07_off_hold'\n",
    "#rawname_ = 'S07_off_move'\n",
    "#rawname_ = 'S07_on_hold'\n",
    "#rawname_ = 'S07_on_move'\n",
    "\n",
    "#sources_type = 'HirschPt2011'\n",
    "sources_type = 'parcel_aal'\n",
    "\n",
    "sind_str,medcond,task = utils.getParamsFromRawname(rawname_)\n",
    "\n",
    "\n",
    "rawname = rawname_ + '_resample_raw.fif'\n",
    "fname_full = os.path.join(data_dir,rawname)\n",
    "    \n",
    "# read file -- resampled to 256 Hz,  Electa MEG, EMG, LFP, EOG channels\n",
    "raw = mne.io.read_raw_fif(fname_full, None)\n",
    "\n",
    "reconst_name = rawname_ + '_resample_afterICA_raw.fif'\n",
    "reconst_fname_full = os.path.join(data_dir,reconst_name)\n",
    "reconst_raw = mne.io.read_raw_fif(reconst_fname_full, None)\n",
    "\n",
    "src_fname_noext = 'srcd_{}_{}'.format(rawname_, sources_type)\n",
    "\n",
    "src_fname = src_fname_noext + '.mat'\n",
    "src_fname_full = os.path.join(data_dir,src_fname)\n",
    "print(src_fname_full)\n",
    "src_ft = h5py.File(src_fname_full, 'r')\n",
    "ff = src_ft\n",
    "\n",
    "\n",
    "#os.path.getmtime(src_fname_full)\n",
    "timeinfo = os.stat(src_fname_full)\n",
    "print('Last mod of src was ', time.ctime(timeinfo.st_mtime) )\n",
    "timeinfo = os.stat(reconst_fname_full)\n",
    "print('Last raw was        ', time.ctime(timeinfo.st_mtime) )\n",
    "\n",
    "display( ff.keys() )\n",
    "display( ff['source_data'] )\n",
    "#display( ff['source_data'].keys() )\n",
    "display( ff['source_data'][0,0] )\n",
    "f = ff[ ff['source_data'][0,0] ]\n",
    "display( f.keys() )\n",
    "display( ''.join( map(chr, f['source_data']['method'][:,0] ) ) )\n",
    "display( f['source_data']['avg'].keys() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymatreader as pymr\n",
    "r = pymr.read_mat('cortical_grid.mat')\n",
    "template_grid_cm = r['cortical_grid'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(coord_labels_corresp_coord)\n",
    "\n",
    "#max(srcgroups_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read aux info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coord_labels_corresp_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_labels_corresp_coord[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coord_labels_corresp_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcgroups_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(crdf['labels']),crdf['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crdf['point_ind_corresp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('.','coord_labels.json') ) as jf:\n",
    "    coord_labels = json.load(jf)\n",
    "#    gv.gparams['coord_labels'] = coord_labels\n",
    "\n",
    "\n",
    "srcCoords_fn = 'coordsJan.mat'\n",
    "coords_MNI_f = sio.loadmat(srcCoords_fn)\n",
    "coords_MNI = coords_MNI_f['coords']\n",
    "\n",
    "\n",
    "if sources_type == 'parcel_aal':\n",
    "    srcCoords_fn = sind_str + '_modcoord_parcel_aal.mat'\n",
    "    \n",
    "    crdf = pymr.read_mat(srcCoords_fn)\n",
    "    \n",
    "    coord_labels_corresp_coord = crdf['labels']\n",
    "    #crdf = sio.loadmat(srcCoords_fn)\n",
    "    #lbls = crdf['labels'][0]\n",
    "    #coord_labels_corresp_coord = [  lbls[i][0] for i in range(len(lbls)) ]\n",
    "    \n",
    "    coords = crdf['coords_Jan_actual']\n",
    "    srcgroups_ = crdf['point_ind_corresp']  # note that it has Matlab indexing starting 1\n",
    "    \n",
    "    if min(srcgroups_) == 0:\n",
    "        srcgroups_ #+= 1\n",
    "        #after we add one element to labels, they start to correspond one another\n",
    "        coord_labels_corresp_coord = ['unlabeled'] + coord_labels_corresp_coord\n",
    "        \n",
    "    print(coord_labels_corresp_coord)      \n",
    "    #crdf['pointlabel']\n",
    "    \n",
    "elif sources_type == 'HirschPt2011':\n",
    "    #<0 left\n",
    "    \n",
    "    srcCoords_fn = sind_str + '_modcoord.mat'\n",
    "    coord_labels_corresp_coord = ['']* len(coords_MNI)\n",
    "    assert len(coord_labels_corresp_coord ) == len(coord_labels) * 2\n",
    "    for coordi in range(len(coords_MNI)):\n",
    "        labeli = coordi // 2\n",
    "        if coords_MNI[coordi,0] < 0:\n",
    "            side = 'L'\n",
    "        else:\n",
    "            side = 'R'    \n",
    "        coord_labels_corresp_coord[coordi]= coord_labels[labeli] + '_{}'.format(side)\n",
    "\n",
    "    srcgroups_ = crdf['point_ind_corresp'][0]\n",
    "    print(coords_MNI,coord_labels_corresp_coord)        \n",
    "        \n",
    "\n",
    "print(srcgroups_)\n",
    "\n",
    "numcenters = np.max(srcgroups_)\n",
    "print(numcenters)\n",
    "print(coords.shape, coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispGroupInfo(grps):\n",
    "    ugrps = np.unique(grps)\n",
    "    print('min {}, max {}; ulen {}, umin {}, umax {}'.\n",
    "          format(min(grps), max(grps), len(ugrps), min(ugrps), max(ugrps)) )\n",
    "dispGroupInfo(srcgroups_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from globvars import gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_selected_by_me = False\n",
    "if desired_selected_by_me:\n",
    "    desired = gp.areas_list_my_guess\n",
    "else:\n",
    "    desired = coord_labels_corresp_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crdf['point_ind_corresp'][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load LCMV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrgroups_dict = {}\n",
    "stcs = []\n",
    "fbands = {}\n",
    "custom_raws = {}\n",
    "vertices_inds_dict = {} # values are lists of lists of indices in the original data\n",
    "\n",
    "if sources_type == 'HirschPt2011':\n",
    "    indsets = {'centers': slice(0,numcenters), 'surround': slice(numcenters,None)}\n",
    "elif sources_type == 'parcel_aal':\n",
    "    indsets = {'surround':slice(None,None)}\n",
    "    \n",
    "pos_ = f['source_data']['pos'][:,:].T\n",
    "\n",
    "# check that correspondence of sides is correct\n",
    "if sources_type == 'HirschPt2011':\n",
    "    for posi in range(len(pos_) ):\n",
    "        corresp_cnt_coord = coords[ srcgroups_[posi] - 1 ]\n",
    "        cur_pt_coord = pos_[posi]\n",
    "        assert np.sign(cur_pt_coord[0] ) == np.sign( corresp_cnt_coord[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ff['source_data'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcData_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defSideFromLabel = True\n",
    "if ff['source_data'].shape[0] == 1:\n",
    "    bandnames = ['allf']\n",
    "else:\n",
    "    bandnames = ['tremor', 'beta', 'gamma', 'allf']\n",
    "for srcdi in range(ff['source_data'].shape[0] ):\n",
    "    bandname = bandnames[srcdi]\n",
    "    f = ff[ ff['source_data'][srcdi,0] ]\n",
    "\n",
    "    freqBand = f['bpfreq'][:].flatten()\n",
    "    \n",
    "    t0 = f['source_data']['time'][0,0]\n",
    "    tstep = np.diff( f['source_data']['time'][:10,0] ) [0]\n",
    "\n",
    "    mom = f['source_data']['avg']['mom']\n",
    "    # extractring unsorted data\n",
    "    if sources_type == 'HirschPt2011':\n",
    "        srcRefs = mom[0,:] \n",
    "        srcData_ = [0]* len(srcRefs)\n",
    "        for srci in range(len(srcRefs)):\n",
    "            print(srci)\n",
    "            srcData_[srci] = f[srcRefs[srci] ][:,0]\n",
    "            srcData_ = np.vstack(srcData_)\n",
    "    else:\n",
    "        srcData_= mom[:,:].T\n",
    "        \n",
    "    assert pos_.shape[0] == srcData_.shape[0]\n",
    "    \n",
    "    numsrc_total = len(srcData_)\n",
    "    for indset_name in indsets:\n",
    "        allinds = np.arange(numsrc_total)[indsets[indset_name] ]\n",
    "        pos = pos_[allinds]\n",
    "        # first coord is the left-right coord\n",
    "        #posinds = np.argsort( pos[:,0] )  # I'll need to sort correspondance as well\n",
    "        #print(posinds)\n",
    "        #sortedPos = pos[posinds]\n",
    "        #leftInds = np.where(sortedPos[:,0]<= 0)[0]\n",
    "        #rightInds = np.where(sortedPos[:,0] > 0)[0]\n",
    "\n",
    "        labels_deford = np.array(coord_labels_corresp_coord)[srcgroups_[allinds ] ]\n",
    "        Lchnis = [labi for labi,lab in enumerate(labels_deford) if lab.endswith('_L') ]\n",
    "        #Rchnis = [labi for labi,lab in enumerate(labels_deford) if lab.endswith('_R') ]\n",
    "        Rchnis = [labi for labi,lab in enumerate(labels_deford) if not lab.endswith('_L') ]\n",
    "        \n",
    "        # create MNE structure that I'm actually not using later\n",
    "        #(data, vertices=None, tmin=None, tstep=None, subject=None, verbose=None\n",
    "\n",
    "        \n",
    "        ####  Create my\n",
    "        if sources_type == 'parcel_aal' and defSideFromLabel:\n",
    "            lhi = map(str, Lchnis )\n",
    "            rhi = map(str, Rchnis )\n",
    "            \n",
    "            concat = Lchnis + Rchnis\n",
    "            vertices = [Lchnis, Rchnis]\n",
    "        else:  #define side from coordinate\n",
    "            leftInds_coord = np.where(pos[:,0]<= 0)[0]\n",
    "            rightInds_coord = np.where(pos[:,0] > 0)[0]\n",
    "            vertices = [leftInds_coord, rightInds_coord]\n",
    "        \n",
    "            lhi = map(str, list( vertices[0] ) )\n",
    "            rhi = map(str, list( vertices[1] ) )\n",
    "            \n",
    "            concat = np.concatenate((leftInds_coord, rightInds_coord))\n",
    "            \n",
    "            #srcData = srcData_[posinds]\n",
    "\n",
    "            #if sources_type == 'HirschPt2011':\n",
    "            labels_coord_ord = np.array(coord_labels_corresp_coord)[srcgroups_[allinds[concat] ]-1 ]\n",
    "            #print(labels)\n",
    "        vertices_inds_dict[indset_name] = vertices\n",
    "            \n",
    "        srcData = srcData_[ allinds [concat]  ]   # with special ordering\n",
    "            \n",
    "        stc = mne.SourceEstimate(data = srcData, tmin = t0, tstep= tstep  , \n",
    "                                 subject = sind_str , vertices=vertices)\n",
    "        stcs += [stc]\n",
    "\n",
    "        fbands[bandname] = freqBand\n",
    "    \n",
    "        if indset_name == 'centers':\n",
    "            # for compatibility\n",
    "            srcnames =  [ 'msrcL_{}_'.format(bandname) + s for s in lhi ] \n",
    "            srcnames += [ 'msrcR_{}_'.format(bandname) + s for s in rhi ]\n",
    "        else:\n",
    "            srcnames =  [ 'srcL_{}_'.format(bandname) + s for s in lhi ] \n",
    "            srcnames += [ 'srcR_{}_'.format(bandname) + s for s in rhi ]\n",
    "\n",
    "        # Initialize an info structure\n",
    "        info = mne.create_info(\n",
    "            ch_names=srcnames,\n",
    "            ch_types=['csd'] * len(srcnames),\n",
    "            sfreq=int ( 1/tstep ))\n",
    "        \n",
    "        srcgroups = srcgroups_[indsets[indset_name] ]#-1\n",
    "        srcgroups = srcgroups [ allinds [concat] ]\n",
    "        #srcgroups = srcgroups_[posinds]-1\n",
    "        assert min(srcgroups) == 0\n",
    "        if sources_type == 'HirschPt2011':\n",
    "            assert max(srcgroups) == len(coords)-1, ( max(srcgroups)+1, len(coords) )\n",
    "        info['srcgroups'] = srcgroups\n",
    "        scrgroups_dict[indset_name] = srcgroups\n",
    "\n",
    "        custom_raw_cur = mne.io.RawArray(srcData, info)\n",
    "        for chi in range(len(custom_raw_cur.info['chs']) ):\n",
    "            custom_raw_cur.info['chs'][chi]['loc'][:3] = pos[concat][chi,:3]\n",
    "        \n",
    "        \n",
    "        rawtmp = custom_raws.get(indset_name, None)\n",
    "        if rawtmp is None:\n",
    "            custom_raws[indset_name] = custom_raw_cur\n",
    "        else:\n",
    "            custom_raws[indset_name].add_channels([custom_raw_cur])\n",
    "            \n",
    "        \n",
    "        #print(custom_raw)\n",
    "        #reconst_raw.add_channels([custom_raw])\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "from globvars import gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "','.join(['sfd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.src_grouping_names_order.index('motor-related_vs_CB_vs_rest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = coord_labels_corresp_coord\n",
    "srcgroups_all = custom_raws['surround'].info['srcgroups']\n",
    "#%debug\n",
    "labels_dict, srcgroups_dict  = utils.prepareSourceGroups(labels,srcgroups_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict['motor-related_vs_CB_vs_rest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(srcgroups_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrgroups_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict['merged_by_side']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple(clrs[grpi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind__ = 9\n",
    "pc = pos[concat]\n",
    "sgdn = ['all',\n",
    "'CB_vs_rest',\n",
    "'CBmerged_vs_rest',\n",
    "'merged',\n",
    "'merged_by_side',\n",
    "'motor-related_only',\n",
    "'motor-related_vs_CB_vs_rest_merge_across_sides',\n",
    "'motor-related_incCB_vs_rest',\n",
    "'motor-related_vs_CBmerged_vs_rest',\n",
    "'motor-related_vs_CB_vs_rest'][ind__]\n",
    "\n",
    "\n",
    "utils.visGroup(sgdn,pos[concat],labels_dict,scrgroups_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(['a', 'b']) == set(['b', 'a', 'c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mayavi.mlab as mam\n",
    "\n",
    "mam.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#srcgroups_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispGroupInfo(srcgroups_), dispGroupInfo(srcgroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcgroups_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### diplay some mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import mne, os\n",
    "\n",
    "print(sind_str )\n",
    "\n",
    "pc = pos[concat]\n",
    "sgdn = 'surround'\n",
    "grpi = 59\n",
    "inds = np.where(scrgroups_dict[sgdn] == grpi)[0]\n",
    "x,y,z = pc[inds].T\n",
    "\n",
    "\n",
    "# renderer = mne.viz.backends.renderer.create_3d_figure(\n",
    "#     size=(600, 600), bgcolor='w')#, scene=False)\n",
    "\n",
    "import pymatreader as pymr\n",
    "import os\n",
    "headfile = pymr.read_mat(os.path.join(data_dir, 'headmodel_grid_{}_surf.mat'.format(sind_str)) )\n",
    "tris = headfile['hdm']['bnd']['tri'].astype(int)\n",
    "rr_mm = headfile['hdm']['bnd']['pos']\n",
    "\n",
    "import mayavi.mlab as mam\n",
    "\n",
    "mam.triangular_mesh(rr_mm[:,0], rr_mm[:,1], rr_mm[:,2], tris-1, color=(0.5,0.5,0.5),\n",
    "                    opacity = 0.8, transparent=False)\n",
    "mam.points3d(x,y,z, scale_factor=0.5)\n",
    "\n",
    "mam.show()\n",
    "\n",
    "#mam.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pymatreader as pymr\n",
    "headfile = pymr.read_mat(os.path.join(data_dir, 'headmodel_grid_{}_surf.mat'.format(sind_str)) )\n",
    "tris = headfile['hdm']['bnd']['tri'].astype(int)\n",
    "rr_mm = headfile['hdm']['bnd']['pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot mesh\n",
    "\n",
    "# rr  array, shape=(n_vertices, 3)\n",
    "\n",
    "#     Coordinate points.\n",
    "# tri  sint array, shape=(n_faces, 3)\n",
    "\n",
    "#     Triangulation (each line contains indices for three points which together form a face).\n",
    "\n",
    "renderer = mne.viz.backends.renderer.create_3d_figure(\n",
    "    size=(600, 600), bgcolor='w')#, scene=False)\n",
    "gray = (0.5, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "renderer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "renderer.mesh(*rr_mm.T, triangles=tris, color=gray)\n",
    "view_kwargs = dict(elevation=90, azimuth=0)\n",
    "mne.viz.set_3d_view(\n",
    "    figure=renderer.figure, distance=350, focalpoint=(0., 0., 40.),\n",
    "    **view_kwargs)\n",
    "renderer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "len(Lchnis) + len(Rchnis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(allinds), len(concat), srcData_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if np.any( np.diff(allinds) > 1 ):\n",
    "    print('warning: allinds is not trivial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dispGroupInfo(srcgroups_[indsets[indset_name] ]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dispGroupInfo( scrgroups_dict['surround'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find inconsidtent (L but >=  0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coord_labels_corresp_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coord_labels_corresp_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chns = custom_raw_cur.ch_names\n",
    "Lchns = [chn for chn in chns if chn.find('srcL') >= 0]\n",
    "for chni,chn in enumerate(chns):\n",
    "    lab = coord_labels_corresp_coord[srcgroups[chni] ]\n",
    "    loc = custom_raw_cur.info['chs'][chni]['loc']\n",
    "    leftlab = lab.find('_L') >= 0\n",
    "    leftside = loc[0] <= 0\n",
    "    if leftlab ^ leftside:\n",
    "        print(chni, chn, loc[0], lab)\n",
    "print(len(Lchns), len(chns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f['source_data']['avg']['mom']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save centers (of my subroi) activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sources_type == 'HirschPt2011':\n",
    "    newsrc_fname_full = os.path.join( data_dir, 'cnt_' + src_fname_noext + '.fif' )\n",
    "    print( newsrc_fname_full )\n",
    "\n",
    "    custom_raws['centers'].save(newsrc_fname_full, overwrite=1)\n",
    "else:\n",
    "    print('other sources, do nothing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(custom_raws['surround'].ch_names))\n",
    "print(custom_raws['surround'].ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FastICA\n",
    "nPCA_comp = 0.95\n",
    "algType = 'PCA+ICA' #'PCA' # 'mean'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define sources groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = coord_labels_corresp_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s#rcgroups_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcgroups_all = custom_raws['surround'].info['srcgroups']\n",
    "labels_dict, srcgroups_dict  = utils.prepareSourceGroups(labels,srcgroups_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import globvars\n",
    "gp = globvars.globparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert labels to what I had\n",
    "s = ''\n",
    "for l in labels:\n",
    "    uuu = 0\n",
    "    for ll in gp.areas_list_aal_my_guess:\n",
    "        if l.find(ll) >= 0 and uuu == 0 and l[-1] == 'L':\n",
    "            uuu += 1\n",
    "            print(l)\n",
    "            s+='\"{}\", '.format(l[:-2])\n",
    "s = s[:-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = [\"Precentral\", \"Rolandic_Oper\", \"Supp_Motor_Area\", \"Postcentral\", \"Parietal_Sup\", \"Parietal_Inf\", \"Precuneus\", \"Paracentral_Lobule\", \"Cerebellum\"]\n",
    "gp.areas_list_aal_my_guess = yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motorlike_both_sides = [0] * len(gp.areas_list_aal_my_guess)*2\n",
    "for i in range(len(motorlike_both_sides)):\n",
    "    side_let = ['_L','_R'][i % 2]\n",
    "    motorlike_both_sides[i] = gp.areas_list_aal_my_guess[ i // 2 ] + side_let\n",
    "motorlike_both_sides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#srcgroups_cb_vs_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " dispGroupInfo(srcgroups_) \n",
    "\n",
    "dispGroupInfo(srcgroups_all)\n",
    "\n",
    "dispGroupInfo(srcgroups_cb_vs_rest)\n",
    "\n",
    "print(cbinds),\n",
    "print( np.sum(1-b ), len(b) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_labels_corresp_coord_cb_vs_rest = ['Cerebellum_L', 'Cerebellum_R', \n",
    "                                         'notCerebellum_L', 'notCerebellum_R', \n",
    "                                         'unlabeled']\n",
    "\n",
    "srcgroups_all = custom_raws['surround'].info['srcgroups']\n",
    "\n",
    "cbinds = [i for i in range(len(coord_labels_corresp_coord) ) if \n",
    " coord_labels_corresp_coord[i].find('Cerebellum') >= 0 ]  # indices ofcb in original\n",
    "\n",
    "assert len(cbinds )  == 2\n",
    "\n",
    "srcgroups_cb_vs_rest = srcgroups_all.copy() # copy needed\n",
    "b = [True] * len(srcgroups_cb_vs_rest)  # first include all\n",
    "# mark those that are not cerebellum\n",
    "for i in cbinds:\n",
    "    b = np.logical_and( srcgroups_cb_vs_rest != i, b)\n",
    "\n",
    "#srcgroups_cb_vs_rest\n",
    "\n",
    "#addCBinds = True\n",
    "\n",
    "for j in range(len(srcgroups_cb_vs_rest)):\n",
    "    curi = srcgroups_cb_vs_rest[j]\n",
    "    if b[j]:  # rename not-cerebellum\n",
    "        parcel_name = coord_labels_corresp_coord[curi]\n",
    "        if parcel_name == 'unlabeled':\n",
    "            newlabi = coord_labels_corresp_coord_cb_vs_rest.index(parcel_name)\n",
    "        else:\n",
    "            sidelet = parcel_name[-1]\n",
    "            newlabi = coord_labels_corresp_coord_cb_vs_rest.index('notCerebellum_' + sidelet)\n",
    "        srcgroups_cb_vs_rest[srcgroups_all == curi] = newlabi\n",
    "#     else if srcgroups[j] in cbinds  and addCBinds:\n",
    "#         srcgroups_cb_vs_rest\n",
    "\n",
    "set_CB_unlab = False #make sense if we compute Cerbellum for other srcgroups\n",
    "for newlabi,newlab in enumerate(coord_labels_corresp_coord_cb_vs_rest[:2] ):\n",
    "    oldind = np.array(coord_labels_corresp_coord)[cbinds].tolist().index(newlab)\n",
    "    print(oldind,newlab,newlabi)\n",
    "    if set_CB_unlab:\n",
    "        newlabi = coord_labels_corresp_coord_cb_vs_rest.index('unlabeled')\n",
    "    srcgroups_cb_vs_rest[srcgroups_all == cbinds[oldind] ] = newlabi  # its on purpose that I use 'old' srcgroups\n",
    "\n",
    "dispGroupInfo(srcgroups_cb_vs_rest)\n",
    "print(srcgroups_cb_vs_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcgroups_cbm_vs_rest = srcgroups_cb_vs_rest.copy()\n",
    "\n",
    "lind = coord_labels_corresp_coord_cb_vs_rest.index('Cerebellum_L')\n",
    "rind = coord_labels_corresp_coord_cb_vs_rest.index('Cerebellum_R')\n",
    "srcgroups_cbm_vs_rest[srcgroups_cbm_vs_rest == rind] = lind\n",
    "srcgroups_cbm_vs_rest[srcgroups_cbm_vs_rest > 1] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_labels_corresp_coord_cbm_vs_rest = coord_labels_corresp_coord_cb_vs_rest[:]\n",
    "del coord_labels_corresp_coord_cbm_vs_rest[0]\n",
    "coord_labels_corresp_coord_cbm_vs_rest[0] = 'Cerebellum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_labels_corresp_coord_cbm_vs_rest\n",
    "\n",
    "dispGroupInfo(srcgroups_cb_vs_rest)\n",
    "dispGroupInfo(srcgroups_cbm_vs_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#srcgroups_cbm_vs_rest\n",
    "\n",
    "unlabi = coord_labels_corresp_coord_cbm_vs_rest.index('unlabeled'); unlabi\n",
    "srcgroups_merged = srcgroups_cbm_vs_rest.copy()\n",
    "srcgroups_merged[srcgroups_merged != unlabi] = 0\n",
    "srcgroups_merged[srcgroups_merged == unlabi] = 1\n",
    "coord_labels_corresp_coord_merged = ['cortex', 'unlabeled']\n",
    "\n",
    "#coord_labels_corresp_coord\n",
    "\n",
    "#coord_labels_corresp_coord\n",
    "\n",
    "coord_labels_corresp_coord_merged_by_side = ['left_hemisphere', \n",
    "                                             'right_hemisphere', 'unlabeled']\n",
    "srcgroups_merged_by_side = srcgroups_all.copy()\n",
    "for labi, label in enumerate(coord_labels_corresp_coord):\n",
    "    if label.endswith('_L'):\n",
    "        srcgroups_merged_by_side[srcgroups_all == labi] = 0\n",
    "    elif label.endswith('_R'):\n",
    "        srcgroups_merged_by_side[srcgroups_all == labi] = 1    \n",
    "    else:\n",
    "        srcgroups_merged_by_side[srcgroups_all == labi] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#srcgroups_all\n",
    "\n",
    "#srcgroups_merged_by_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcgroups_dict = {}\n",
    "srcgroups_dict['all'] = srcgroups_all\n",
    "srcgroups_dict['CB_vs_rest'] = srcgroups_cb_vs_rest\n",
    "srcgroups_dict['CBmerged_vs_rest'] = srcgroups_cbm_vs_rest\n",
    "srcgroups_dict['merged'] = srcgroups_merged\n",
    "srcgroups_dict['merged_by_side'] = srcgroups_merged_by_side\n",
    "\n",
    "\n",
    "\n",
    "#coord_labels_corresp_coord\n",
    "\n",
    "coord_labels_corresp_dict = {}\n",
    "coord_labels_corresp_dict['all'] = coord_labels_corresp_coord\n",
    "coord_labels_corresp_dict['CB_vs_rest'] = coord_labels_corresp_coord_cb_vs_rest\n",
    "coord_labels_corresp_dict['CBmerged_vs_rest'] = coord_labels_corresp_coord_cbm_vs_rest\n",
    "coord_labels_corresp_dict['merged'] = coord_labels_corresp_coord_merged\n",
    "coord_labels_corresp_dict['merged_by_side'] = coord_labels_corresp_coord_merged_by_side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute average/PCA/PCA+ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Cerebellum' not in desired:\n",
    "    desired += ['Cerebellum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we we will work with\n",
    "srcgroups_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del srcgroups_dict['all']\n",
    "del srcgroups_dict['CB_vs_rest']\n",
    "del srcgroups_dict['CBmerged_vs_rest']\n",
    "del srcgroups_dict['merged']\n",
    "del srcgroups_dict['merged_by_side']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#srcgroups_list += [custom_raws['surround'].info['srcgroups']]\n",
    "skip_ulabeled = True\n",
    "duplicate_merged_across_sides = True # applies to 'merged' and 'CBmerged_vs_rest'\n",
    "newchnames = []\n",
    "newdatas = []\n",
    "avpos = []\n",
    "pcas = []\n",
    "icas = []\n",
    "sort_keys = list( sorted(srcgroups_dict.keys()) )\n",
    "#sort_keys = ['CBmerged_vs_rest']\n",
    "# cycle over parcellations\n",
    "for srcgi,srcgroups_key in enumerate(sort_keys):\n",
    "    print('   Starting working wtih grouping ',srcgroups_key)\n",
    "    srcgroups = srcgroups_dict[srcgroups_key]\n",
    "    if srcgroups_key == 'all':\n",
    "        assert min(srcgroups) == 0\n",
    "    if sources_type == 'HirschPt2011':\n",
    "        assert max(srcgroups) == len(coords)-1, ( max(srcgroups)+1, len(coords) )\n",
    "\n",
    "    # cycle over parcel indices\n",
    "    for i in range( max(srcgroups)+1 ):\n",
    "        merge_needed = False\n",
    "        # get the (orderd) list of parcels in the current parcellation\n",
    "        coord_labels_corresp = coord_labels_corresp_dict[srcgroups_key]\n",
    "        cur_parcel = coord_labels_corresp[i]\n",
    "        desired_ind = False  # whether we desire this index or not\n",
    "        for des in desired:\n",
    "            desired_ind = desired_ind or (cur_parcel.find(des) >= 0)\n",
    "        if not desired_ind or (skip_ulabeled and cur_parcel.find('unlabeled') >= 0):\n",
    "            continue\n",
    "\n",
    "        inds = np.where(srcgroups == i)[0]\n",
    "        #srcData[inds]\n",
    "        if cur_parcel == 'Cerebellum':  # NOT 'Cerebellum_L' or 'Cerebellum_R':\n",
    "            if duplicate_merged_across_sides:\n",
    "                merge_needed = True\n",
    "            brainside = 'B'\n",
    "        else:\n",
    "            if defSideFromLabel:\n",
    "                if cur_parcel.endswith('_L'):\n",
    "                    brainside = 'L'\n",
    "                else:\n",
    "                    brainside = 'R'\n",
    "            else:\n",
    "                #L or R?\n",
    "                if coords[i][0] <= 0:\n",
    "                    brainside = 'L'\n",
    "                else:\n",
    "                    brainside = 'R'\n",
    "\n",
    "        for bandname in bandnames:\n",
    "            if sources_type == 'HirschPt2011':\n",
    "                chnames = [ 'src{}_{}_{}'.format(brainside,bandname,s) for s in inds ] \n",
    "            else:\n",
    "                chnames = np.array(custom_raws['surround'].ch_names)[inds]\n",
    "                \n",
    "            if len(chnames) == 0:\n",
    "                print('! {}: no channels found for {}, index {}'.\n",
    "                      format(cur_parcel, srcgroups_key, i))\n",
    "                continue\n",
    "            chdata, times = custom_raws['surround'][chnames]\n",
    "\n",
    "            if algType.startswith('PCA'):\n",
    "                pca = PCA(n_components=nPCA_comp)\n",
    "                pca.fit(chdata.T)\n",
    "                newdata = pca.transform(chdata.T).T\n",
    "                #newchnames += ['msrc{}_{}_{}_c{}'.format(brainside,bandname,i,ci) \\\n",
    "                #               for ci in range(newdata.shape[0])]\n",
    "                \n",
    "                pcas += [pca]\n",
    "                if algType.find('ICA') >= 0:\n",
    "                    max_iter = 200 \n",
    "                    ica = FastICA(n_components=len(newdata),\n",
    "                                  random_state=0, max_iter=max_iter)\n",
    "                    ica.fit(newdata.T)\n",
    "                    if ica.n_iter_ < max_iter:\n",
    "                        newdata = ica.transform(newdata.T).T\n",
    "                    else:\n",
    "                        print('Did not converge')\n",
    "                        \n",
    "                    icas += [ica]\n",
    "\n",
    "                if merge_needed:\n",
    "                    pcas += [pca] # same pca and ica again\n",
    "                    icas += [ica]\n",
    "                    \n",
    "                    cur_newchnames = ['msrc{}_{}_{}_{}_c{}'.\n",
    "                                   format('L',bandname,srcgi,i,ci) \\\n",
    "                                   for ci in range(newdata.shape[0])]\n",
    "                    cur_newchnames += ['msrc{}_{}_{}_{}_c{}'.\n",
    "                                   format('R',bandname,srcgi,i,ci) \\\n",
    "                                   for ci in range(newdata.shape[0])]\n",
    "                else:\n",
    "                    cur_newchnames = ['msrc{}_{}_{}_{}_c{}'.\n",
    "                                   format(brainside,bandname,srcgi,i,ci) \\\n",
    "                                   for ci in range(newdata.shape[0])]\n",
    "\n",
    "                newchnames += cur_newchnames\n",
    "\n",
    "            elif algType == 'mean':\n",
    "                newdata = np.mean(chdata,axis=0)[None,:]\n",
    "                newchnames += ['msrc{}_{}_{}'.format(brainside,bandname,i)]\n",
    "            #print(chnames)\n",
    "            print('{}={}: {} over {}, newdata shape {}'.\n",
    "                  format(i,coord_labels_corresp[i], algType, \n",
    "                         chdata.shape[0],newdata.shape))\n",
    "\n",
    "            newdatas    += [newdata]\n",
    "            if merge_needed: # adding again\n",
    "                newdatas    += [newdata]\n",
    "\n",
    "            avpos_cur = np.zeros(3)\n",
    "            for chi in mne.pick_channels(custom_raws['surround'].ch_names,chnames):\n",
    "                avpos_cur += custom_raws['surround'].info['chs'][chi]['loc'][:3]\n",
    "            avpos_cur /= len(chnames)\n",
    "            avpos += [avpos_cur] * newdata.shape[0]\n",
    "            if merge_needed: # adding again\n",
    "                avpos += [avpos_cur] * newdata.shape[0]\n",
    "    \n",
    "assert len(newchnames) == len(avpos)\n",
    "assert len(icas) == len(pcas)\n",
    "assert len(newchnames) == np.sum([nd.shape[0] for nd in newdatas])\n",
    "print('We got {} new channels '.format( len(newchnames)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newchnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pcas[-4].explained_variance_ratio_)\n",
    "print(pcas[-3].explained_variance_ratio_)\n",
    "print(pcas[-2].explained_variance_ratio_)\n",
    "print(pcas[-1].explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newchnames[-25:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrgroups_per_indset = {}\n",
    "for crt in custom_raws:\n",
    "    scrgroups_per_indset[crt] = custom_raws[crt].info['srcgroups'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# srcCoords_fn = 'coordsJan.mat'\n",
    "# coords_MNI_f = sio.loadmat(srcCoords_fn)\n",
    "# coords_MNI = coords_MNI_f['coords']\n",
    "\n",
    "# coord_labels_corresp_coord = ['']* len(coords_MNI)\n",
    "# assert len(coord_labels_corresp_coord ) == len(coord_labels) * 2\n",
    "# for coordi in range(len(coords_MNI)):\n",
    "#     labeli = coordi // 2\n",
    "#     if coords_MNI[coordi,0] < 0:\n",
    "#         side = 'L'\n",
    "#     else:\n",
    "#         side = 'R'    \n",
    "#     coord_labels_corresp_coord[coordi]= coord_labels[labeli] + '_{}'.format(side)\n",
    "# #<0 left\n",
    "# print(coords_MNI,coord_labels_corresp_coord)\n",
    "\n",
    "# srcCoords_fn = sind_str + '_modcoord.mat'\n",
    "# crdf = sio.loadmat(srcCoords_fn)\n",
    "# coords = crdf['coords_Jan_actual']\n",
    "# srcgroups_ = crdf['point_ind_corresp'][0]\n",
    "# print(srcgroups_)\n",
    "\n",
    "# numcenters = np.max(srcgroups_)\n",
    "# print(numcenters)\n",
    "# print(coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save aux info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import globvars as gv\n",
    "src_rec_info_fn = '{}_{}_src_rec_info'.format(rawname_,sources_type)\n",
    "src_rec_info_fn_full = os.path.join(gv.data_dir, src_rec_info_fn + '.npz')\n",
    "print(src_rec_info_fn_full)\n",
    "np.savez(src_rec_info_fn_full, scrgroups_dict=scrgroups_dict,\n",
    "         scrgroups_per_indset = scrgroups_per_indset,\n",
    "         coords_Jan_actual=coords,\n",
    "         coord_labels_corresp_dict = coord_labels_corresp_dict,\n",
    "         srcgroups_key_order = sort_keys,\n",
    "         coords_MNI=coords_MNI,\n",
    "         pcas=pcas, icas=icas,\n",
    "        avpos=avpos, algType=algType, vertices_inds_dict=vertices_inds_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add average channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avpos, coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = 0\n",
    "for chn in newchnames:\n",
    "    ml = max (ml, len(chn))\n",
    "print('Max chname len = ',ml)\n",
    "assert ml <= 15, 'max chan name len is {} > 15'.format(ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ml > 15:\n",
    "    for chni in range(len(newchnames) ):\n",
    "        newchnames[chni] = newchnames[chni].replace('allf_','')\n",
    "#     for chni in range(len(newchnames) ):\n",
    "#         newchnames[chni] = newchnames[chni].replace('Cerebelum','CB')\n",
    "    shortened_chnames = True\n",
    "    print('Shortened namees')\n",
    "else:\n",
    "    shortened_chnames = False\n",
    "\n",
    "print('newchnames =', newchnames )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nd in newdatas:\n",
    "    print(nd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iii = 66\n",
    "newraw.ch_names[iii], utils.parseMEGsrcChnameShort(newraw.ch_names[iii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newchnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_labels_corresp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_keys[srcgroup_ind] == 'CB_vs_rest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose data from which groupings do we want to save (not all perhpas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = np.vstack(newdatas)\n",
    "\n",
    "#onlyCB_and_notCB = True\n",
    "#group_names_to_keep = ['CB_vs_rest', 'CBmerged_vs_rest']\n",
    "onlyCB_and_notCB = False\n",
    "group_names_to_keep = ['all']\n",
    "if onlyCB_and_notCB:\n",
    "    inds = []\n",
    "    newchnames_filtered = []\n",
    "    newdatas_filtered = []\n",
    "    for chni,chn in enumerate(newchnames):\n",
    "        nn = utils.getMEGsrc_chname_nice(chn,coord_labels_corresp_dict, sort_keys)\n",
    "        srcgroup_ind, ind, subind = utils.parseMEGsrcChnameShort(chn) \n",
    "        #print(nn)\n",
    "        # computed CB twice, so we don't want to save it twice\n",
    "        if nn.find('Cerebellum') >= 0 and sort_keys[srcgroup_ind] in sort_keys:\n",
    "            \n",
    "            print(chni,nn, srcgroup_ind, ind, subind)\n",
    "            inds += [chni]\n",
    "            newchnames_filtered += [chn]\n",
    "            newdatas_filtered += [dd[chni] ]\n",
    "            #newdatas_filtered += [ newdatas[ind][subind] ]\n",
    "            \n",
    "else:\n",
    "    newchnames_filtered = newchnames\n",
    "    newdatas_filtered = newdatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(newchnames_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newchnames_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = np.vstack(newdatas_filtered)\n",
    "rawdata_flt = dd\n",
    "\n",
    "ml = 0\n",
    "for chn in newchnames_filtered:\n",
    "    ml = max (ml, len(chn))\n",
    "assert ml <= 15\n",
    "\n",
    "\n",
    "info = mne.create_info(\n",
    "    ch_names=newchnames_filtered,\n",
    "    ch_types=['csd'] * len(newchnames_filtered),\n",
    "    sfreq=int ( 1/tstep ))\n",
    "\n",
    "for chi in range(len(info['chs']) ):\n",
    "    info['chs'][chi]['loc'][:3] = avpos[chi]\n",
    "\n",
    "srcgroups_backup = custom_raws['surround'].info['srcgroups']\n",
    "\n",
    "newraw = mne.io.RawArray(dd, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newchnames_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_raws['surround'].add_channels( [newraw] )\n",
    "custom_raws['surround'].info['srcgroups'] = srcgroups_backup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_tSNE as utsne\n",
    "\n",
    "\n",
    "utsne.plotBasicStatsMultiCh(rawdata_flt, chan_names=newraw.ch_names, \n",
    "                      printMeans = True, singleAx = 0,\n",
    "                          shift_std_mult = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newraw.ch_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsrc_fname_full = os.path.join( data_dir, 'av_' + src_fname_noext + '.fif' )\n",
    "print( newsrc_fname_full )\n",
    "\n",
    "if sources_type == 'HirschPt2011':\n",
    "    custom_raws['surround'].save(newsrc_fname_full, overwrite=1)\n",
    "else:\n",
    "    newraw.save(newsrc_fname_full, overwrite=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect info about dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawnames =   ['S01_off_hold', 'S01_off_move'] + ['S01_on_hold', 'S01_on_move']\n",
    "rawnames +=  ['S02_off_hold', 'S02_off_move'] + ['S02_on_hold', 'S02_on_move'] \n",
    "rawnames +=  ['S03_off_hold', 'S03_off_move']\n",
    "rawnames +=  ['S04_off_hold', 'S04_off_move'] + ['S04_on_hold', 'S04_on_move'] \n",
    "rawnames +=  ['S05_off_hold', 'S05_off_move'] + ['S05_on_hold', 'S05_on_move'] \n",
    "rawnames +=  ['S07_off_hold', 'S07_off_move'] + ['S07_on_hold', 'S07_on_move'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_type = 'parcel_aal'\n",
    "import mne,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import globvars as gv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "chns_pri = {}\n",
    "for rawname_cur in rawnames:\n",
    "    src_fname_noext = 'srcd_{}_{}'.format(rawname_cur, sources_type)\n",
    "    src_fname_full = os.path.join( gv.data_dir, 'av_' + src_fname_noext + '.fif' )\n",
    "    if not os.path.exists(src_fname_full):\n",
    "        print('{} does not exist, skipping '.format(src_fname_full))\n",
    "        continue\n",
    "    raw_src_cur = mne.io.read_raw_fif(src_fname_full, None) \n",
    "    chns_pri[rawname_cur] = raw_src_cur.ch_names\n",
    "    del raw_src_cur\n",
    "    gc.collect()\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "nregions = 61\n",
    "nums = nregions*[[]]\n",
    "maxNums = nregions*[0]\n",
    "minNums = nregions*[1e10]\n",
    "minNums[0]= 0\n",
    "for rawname_cur in chns_pri:\n",
    "    chns_cur = chns_pri[rawname_cur]\n",
    "    for chn in chns_cur:\n",
    "        side,srcgrpind,ind,subind = utils.parseMEGsrcChnameShort(chn)\n",
    "        maxNums[ind] = max(maxNums[ind], subind+1)\n",
    "        minNums[ind] = min(minNums[ind], subind+1)\n",
    "        nums[ind] += [subind]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chns_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(maxNums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "np.sum(minNums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(maxNums) - np.array(minNums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(maxNums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(minNums[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play with results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(newraw.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newraw.ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata_flt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curband = [3,100]\n",
    "freqs = np.arange(curband[0],curband[1], 1)    \n",
    "tfrres = mne.time_frequency.tfr_array_morlet(rawdata_flt[None,:], \n",
    "                                             freqs=freqs, n_cycles=freqs * 0.75, \n",
    "                                         sfreq=int(newraw.info['sfreq']), \n",
    "                                             n_jobs=10, \n",
    "                                   output='complex', decim = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(tfrres.shape) == 4:\n",
    "    tfrres = tfrres[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrres.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decim = 8\n",
    "chni = 0\n",
    "import matplotlib.colors as colors\n",
    "#tfr_abs = np.abs( tfrres )\n",
    "#mn,mx = np.percentile( tfr_abs, [5,95] )\n",
    "#norm=colors.LogNorm(vmin=mn, vmax=mx)\n",
    "\n",
    "tfr_abs = np.log( np.abs( tfrres ) )\n",
    "mn,mx = np.percentile( tfr_abs, [5,95] )\n",
    "norm=colors.Normalize(vmin=mn, vmax=mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncb_comp = pcas[0].n_components_\n",
    "ncb_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(newraw.ch_names) - ncb_comp\n",
    "nc = 1\n",
    "nr = n\n",
    "ww = 15; hh = 4;\n",
    "fig,axs = plt.subplots(nr,nc, figsize= (nc*ww, nr * hh))\n",
    "plt.subplots_adjust(right=0.99,left=0.05,top=0.96,bottom=0.03)\n",
    "\n",
    "for chni in range(n):\n",
    "    ax = axs[chni]\n",
    "    chni_eff = chni\n",
    "    if chni >= ncb_comp:\n",
    "        chni_eff = ncb_comp + chni\n",
    "    chn = newraw.ch_names[chni_eff]\n",
    "    chn_nice = utils.getMEGsrc_chname_nice(chn,coord_labels_corresp_dict, sort_keys)\n",
    "\n",
    "\n",
    "    #norm = None\n",
    "    ax.pcolormesh(times[::decim], freqs,  tfr_abs[chni] , norm = norm, \n",
    "                  shading = 'auto' )\n",
    "    ax.set_title(chn_nice)\n",
    "    \n",
    "plt.savefig('tfrs.png')\n",
    "plt.close()\n",
    "#ax.pcolormesh( np.abs( tfrres[chni] ) )#, norm = norm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(range(4),range(5), np.zeros((5,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Plotting of one channel vs its surrounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meansrcind = 1\n",
    "inds = np.where(srcgroups == meansrcind)[0]\n",
    "bandname = 'beta'\n",
    "if coords[meansrcind][0] <= 0:\n",
    "    brainside = 'L'\n",
    "else:\n",
    "    brainside = 'R'\n",
    "formatstr = 'src{}_{}_{}'\n",
    "chns = [formatstr.format(brainside,bandname,i) for i in inds]   #msrcR_tremor_0\n",
    "chns += ['m'+formatstr.format(brainside,bandname,meansrcind) ]\n",
    "chns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_curband[None,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatstr.format(brainside,bandname,i)\n",
    "# 'm'+formatstr.format(brainside,bandname,meansrcind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chname_bases = []\n",
    "for ind in inds:\n",
    "    chname_bases +=  [ formatstr.format(brainside,'{}',ind) ]\n",
    "chname_bases +=  [ 'm'+formatstr.format(brainside,'{}',meansrcind) ]\n",
    "chname_bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrs = {}\n",
    "for chname_base in chname_bases:\n",
    "    tfrs_perchan = {}\n",
    "    for bandname in fbands.keys():\n",
    "        chname = chname_base.format(bandname)\n",
    "        data_curband, times = custom_raw[chname]\n",
    "        curband = fbands[bandname].copy()\n",
    "        if curband[0] < 0:\n",
    "            curband[0] = 4\n",
    "        if curband[1] < 0:\n",
    "            curband[1] = 100\n",
    "            \n",
    "        if bandname != 'allf':\n",
    "            curband[0] -= 2\n",
    "            curband[1] += 2\n",
    "        freqs = np.arange(curband[0],curband[1], 1)\n",
    "        tfrres = mne.time_frequency.tfr_array_morlet(data_curband[None,:], freqs=freqs, n_cycles=freqs * 0.75, \n",
    "                                                     sfreq=int(custom_raw.info['sfreq']), n_jobs=10, \n",
    "                                               output='complex')\n",
    "        \n",
    "        tfrs_perchan[bandname] = tfrres[0,0]\n",
    "    tfrs[chname_base] = tfrs_perchan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#partial_fbands = [k for k in fbands.keys() if k != 'allf' ]\n",
    "partial_fbands = list( set(bandnames) - set(['allf']) )\n",
    "assert 'allf' not in partial_fbands\n",
    "\n",
    "if len(partial_fbands):\n",
    "    chname_base =  chname_bases[0]\n",
    "\n",
    "    all_freqs = []\n",
    "\n",
    "    complete_tfr = []\n",
    "    for bandname in partial_fbands:\n",
    "        chname = chname_base.format(bandname)\n",
    "        curband = fbands[bandname].copy()\n",
    "        if curband[0] < 0:\n",
    "            curband[0] = 4\n",
    "        if curband[1] < 0:\n",
    "            curband[1] = 100\n",
    "\n",
    "        all_freqs += [np.arange(curband[0],curband[1] ) ]\n",
    "\n",
    "        complete_tfr += [ tfrs[chname_base][bandname][2:-2] ]\n",
    "\n",
    "    all_freqs = np.hstack( all_freqs )\n",
    "\n",
    "    complete_tfr = np.vstack( complete_tfr )\n",
    "\n",
    "    assert complete_tfr.shape[0] == all_freqs.shape[0]\n",
    "else:\n",
    "    all_freqs = freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allfchans = []\n",
    "for chname_base in chname_bases[:-1]:\n",
    "    chname = chname_base.format('allf')\n",
    "    print(chname)\n",
    "    allfchans += [tfrs[chname_base]['allf'][None,:] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allfchans = np.vstack( allfchans )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allfchans_mean = np.mean(allfchans, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allfchans_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors\n",
    "allfchans_mean_abs = np.abs( allfchans_mean )\n",
    "mn,mx = np.percentile(allfchans_mean_abs, [5,95] )\n",
    "norm=colors.LogNorm(vmin=mn, vmax=mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected = np.abs(complete_tfr)\n",
    "allf_single = np.abs(tfrs[chname_base]['allf'])\n",
    "allf_msrc = np.abs(tfrs[chname_bases[-1]]['allf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allf_single.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "ax = plt.gca()\n",
    "#ax = plt.subplot(4,1,1)\n",
    "if collected.size:\n",
    "    lbl = 'arranged from separately applied beamformer'\n",
    "    ax.semilogy(all_freqs,  np.mean(collected, axis=1) ,label=lbl)\n",
    "\n",
    "#ax = plt.subplot(4,1,2)\n",
    "lbl = 'broadband beamformer'\n",
    "ax.semilogy(all_freqs,  np.mean(allf_single, axis=1) ,label=lbl)\n",
    "\n",
    "#ax = plt.subplot(4,1,3)\n",
    "lbl = 'averaged channel'\n",
    "ax.semilogy(all_freqs,  np.mean(allf_msrc, axis=1) ,label=lbl)\n",
    "\n",
    "\n",
    "#ax = plt.subplot(4,1,4)\n",
    "lbl = 'averaged tfr'\n",
    "ax.semilogy(all_freqs,  np.mean(allfchans_mean_abs, axis=1),label=lbl) \n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allf_single.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decim = 8\n",
    "plt.figure(figsize=(20,8))\n",
    "ax = plt.subplot(4,1,1)\n",
    "if collected.size:\n",
    "    ax.pcolormesh(times[::decim], all_freqs,  collected[:,::decim], norm = norm )\n",
    "    ax.set_title('arranged from separately applied beamformer')\n",
    "\n",
    "ax = plt.subplot(4,1,2)\n",
    "ax.pcolormesh(times[::decim], all_freqs,  allf_single[:,::decim], norm = norm )\n",
    "ax.set_title('broadband beamformer')\n",
    "\n",
    "ax = plt.subplot(4,1,3)\n",
    "ax.pcolormesh(times[::decim], all_freqs,  allf_msrc[:,::decim], norm = norm )\n",
    "ax.set_title('averaged channel')\n",
    "\n",
    "ax = plt.subplot(4,1,4)\n",
    "ax.pcolormesh(times[::decim], all_freqs,  allfchans_mean_abs[:,::decim], norm = norm )\n",
    "ax.set_title('averaged tfr')\n",
    "\n",
    "plt.savefig('compare_tfr.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.subplot(2,1,1).pcolor(  tfrs[chname]['allf'].T )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v,f = plt.psd(td,Fs=1/(tt[1]-tt[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sum(v) * (f[1]-f[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at averaged (in time domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msrcOnly = custom_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picks =  mne.pick_channels_regexp(msrcOnly.ch_names, 'msrc._all_*'  )  \n",
    "picks_names = [msrcOnly.ch_names[i] for i in picks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picks_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msrcOnly.pick_channels(   picks_names  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strec = 0\n",
    "endrec = msrcOnly.times[-1]\n",
    "epdur = endrec\n",
    "events_one = mne.make_fixed_length_events(msrcOnly, start=strec, stop=endrec, duration=epdur)\n",
    "epochs_one = mne.Epochs(msrcOnly,events_one, tmin=0,tmax = epdur, baseline=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mne.connectivity.spectral_connectivity(epochs_one.get_data(), method='coh' , \n",
    "                                       n_jobs = 10, indices = None, sfreq = custom_raw.info['sfreq'],\n",
    "                                      mode='multitaper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con, freqs, times, n_epochs, n_tapers = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqinds_trem = np.where( (freqs >= 4) * (freqs <= 10) )[0]\n",
    "freqinds_beta = np.where( (freqs >= 10) * (freqs <= 30) )[0]\n",
    "freqinds_gamma = np.where( (freqs >= 30) * (freqs <= 100) )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fii = 0\n",
    "plt.figure(figsize = (15,4))\n",
    "#plt.subplot(1,3,1).pcolormesh(con[:,:,freqinds_beta[fii]])\n",
    "plt.subplot(1,3,1).pcolormesh( np.mean( con[:,:,freqinds_trem], axis=-1 )  )\n",
    "plt.subplot(1,3,2).pcolormesh( np.mean( con[:,:,freqinds_beta], axis=-1 )  )\n",
    "plt.subplot(1,3,3).pcolormesh( np.mean( con[:,:,freqinds_gamma], axis=-1 )  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# PAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chdata = epochs_one.get_data()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorpac import Pac\n",
    "p = Pac(idpac=(6, 0, 0), f_pha=(4, 20, 1, 1), f_amp=(10, 100, 5, 5))\n",
    "# Filter the data and extract PAC :\n",
    "xpac = p.filterfit(custom_raw.info['sfreq'], x_pha = chdata[0], x_amp = chdata[2])\n",
    "\n",
    "# Plot your Phase-Amplitude Coupling :\n",
    "p.comodulogram(xpac.mean(-1), title='Contour plot with 5 regions',\n",
    "               cmap='Spectral_r', plotas='contour', ncontours=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p = Pac(idpac=(6, 0, 0), f_pha=(4, 20, 1, 1), f_amp=(10, 100, 5, 5))\n",
    "# Filter the data and extract PAC :\n",
    "xpac = p.filterfit(custom_raw.info['sfreq'], x_pha = chdata[2], x_amp = chdata[0])\n",
    "\n",
    "# Plot your Phase-Amplitude Coupling :\n",
    "p.comodulogram(xpac.mean(-1), title='Contour plot with 5 regions',\n",
    "               cmap='Spectral_r', plotas='contour', ncontours=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p = Pac(idpac=(6, 0, 0), f_pha=(4, 20, 1, 1), f_amp=(10, 100, 5, 5))\n",
    "# Filter the data and extract PAC :\n",
    "xpac = p.filterfit(custom_raw.info['sfreq'], x_pha = chdata[0], x_amp = chdata[4])\n",
    "\n",
    "# Plot your Phase-Amplitude Coupling :\n",
    "p.comodulogram(xpac.mean(-1), title='Contour plot with 5 regions',\n",
    "               cmap='Spectral_r', plotas='contour', ncontours=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "msrcOnly_Hilbert = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "freqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#tfr_array_morlet\n",
    "freqs = np.arange(4,100)\n",
    "tfrres = mne.time_frequency.tfr_morlet(epochs_one, freqs, freqs * 0.75, return_itc=0, n_jobs=10, \n",
    "                                       output='complex', average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# MNE:   _csd_morlet(...)\n",
    "#     n_channels = data.shape[0]\n",
    "#     csds = np.vstack([np.mean(psds[[i]] * psds_conj[i:], axis=2)\n",
    "#                       for i in range(n_channels)])\n",
    "\n",
    "#     # Scaling by sampling frequency for compatibility with Matlab\n",
    "#     csds /= sfreq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " ## mne.SourceEstimate\n",
    "\n",
    "data\n",
    "    \n",
    "    array of shape (n_dipoles, n_times) | tuple, shape (2,)\n",
    "\n",
    "    The data in source space. When it is a single array, the left hemisphere is stored in data[:len(vertices[0])] and the right hemisphere is stored in data[-len(vertices[1]):]. When data is a tuple, it contains two arrays:\n",
    "\n",
    "        “kernel” shape (n_vertices, n_sensors) and\n",
    "\n",
    "        “sens_data” shape (n_sensors, n_times).\n",
    "\n",
    "    In this case, the source space data corresponds to np.dot(kernel, sens_data).\n",
    "vertices\n",
    "\n",
    "    list of array, shape (2,)\n",
    "\n",
    "    Vertex numbers corresponding to the data. The first element of the list contains vertices of left hemisphere and the second element contains vertices of right hemisphere.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# DICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f['source_data']['avg']['noise'][0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f['source_data']['avg']['pow'][0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f['source_data']['freq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f = src_ft\n",
    "times = f['source_data']['time'][ts:te,0]\n",
    "\n",
    "src = f['source_data'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ref = src['avg']['mom'] [0,srci]\n",
    "# maybe I can make more efficient data extraction of multiple channels at once \n",
    "# later if needed, if I bundle all channels from the same source file \n",
    "if f[ref].size > 10:\n",
    "    srcval = f[ref ][ts:te,0]   # 1D array with reconstructed source activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "freqdat_fname_full =  os.path.join(data_dir, 'tmp_freq_data.mat' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "freqd = h5py.File(freqdat_fname_full, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "freqd['#refs#']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "freqd['freqdata'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "freqd['freqdata']['grad'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "freqd['freqdata']['freq'][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "freqd['freqdata']['labelcmb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fr = freqd[ freqd['freqdata']['labelcmb'][1,0] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "''.join( map(chr, fr[:,0] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "freqd['freqdata']['powspctrm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "freqd['freqdata']['crsspctrm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "freqd['freqdata']['dimord'][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "''.join( map(chr, freqd['freqdata']['dimord'][:,0] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "freqd['freqdata']['crsspctrm'][0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
