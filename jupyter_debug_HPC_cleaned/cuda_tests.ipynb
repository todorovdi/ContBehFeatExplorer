{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5935ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ~/soft/_pyenvs/obddp/lib/python3.8/site-packages/pycuda/autoinit.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693c31f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pycuda.driver as cuda_driver\n",
    "    cuda_driver.init()\n",
    "except pycuda.driver.Error as e:\n",
    "    print(f'CUDA problem: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f459b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "    from timeit import timeit\n",
    "    import pycuda.gpuarray as gpuarray\n",
    "    import pycuda.autoinit\n",
    "    import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a816ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    " from skcuda.linalg import svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2284f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    import skcuda\n",
    "    skcuda.misc.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bd9884",
   "metadata": {},
   "outputs": [],
   "source": [
    "    N = 6400\n",
    "    Y = np.random.randn(N, N) + 1j*np.random.randn(N, N)\n",
    "    X = np.asarray(Y, np.complex64)\n",
    "    a_gpu = gpuarray.to_gpu(X)\n",
    "         \n",
    "    tm = timeit(\"svd(a_gpu, jobu='A', jobvt='A', lib='cusolver')\", \n",
    "                    globals={'a_gpu': a_gpu, 'svd': svd}, \n",
    "                    number=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9163be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "import numpy\n",
    "a = numpy.random.randn(4,4)\n",
    "\n",
    "a = a.astype(numpy.float32)\n",
    "\n",
    "a_gpu = cuda.mem_alloc(a.size * a.dtype.itemsize)\n",
    "\n",
    "cuda.memcpy_htod(a_gpu, a)\n",
    "\n",
    "mod = SourceModule(\"\"\"\n",
    "    __global__ void doublify(float *a)\n",
    "    {\n",
    "      int idx = threadIdx.x + threadIdx.y*4;\n",
    "      a[idx] *= 2;\n",
    "    }\n",
    "    \"\"\")\n",
    "\n",
    "func = mod.get_function(\"doublify\")\n",
    "func(a_gpu, block=(4,4,1))\n",
    "\n",
    "a_doubled = numpy.empty_like(a)\n",
    "cuda.memcpy_dtoh(a_doubled, a_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e2f3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"original array:\" )\n",
    "print( a )\n",
    "print( \"doubled with kernel:\" )\n",
    "print( a_doubled )\n",
    "\n",
    "# alternate kernel invocation -------------------------------------------------\n",
    "\n",
    "func(cuda.InOut(a), block=(4, 4, 1))\n",
    "print (\"doubled with InOut:\")\n",
    "print (a)\n",
    "\n",
    "# part 2 ----------------------------------------------------------------------\n",
    "\n",
    "import pycuda.gpuarray as gpuarray\n",
    "a_gpu = gpuarray.to_gpu(numpy.random.randn(4,4).astype(numpy.float32))\n",
    "a_doubled = (2*a_gpu).get()\n",
    "\n",
    "print (\"original array:\")\n",
    "print (a_gpu)\n",
    "print (\"doubled with gpuarray:\")\n",
    "print (a_doubled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812b2dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "#The cupy.ndarray class is in its core, which is a compatible GPU alternative of numpy.ndarray.\n",
    "\n",
    "x_gpu = cp.array([1, 2, 3])\n",
    "#x_gpu in the above example is an instance of cupy.ndarray. You can see its creation of identical to NumPyâ€™s one, except that numpy is replaced with cupy. The main difference of cupy.ndarray from numpy.ndarray is that the content is allocated on the device memory. Its data is allocated on the current device, which will be explained later.\n",
    "\n",
    "#Most of the array manipulations are also done in the way similar to NumPy. Take the Euclidean norm (a.k.a L2 norm) for example. NumPy has numpy.linalg.norm() to calculate it on CPU.\n",
    "\n",
    "x_cpu = np.array([1, 2, 3])\n",
    "l2_cpu = np.linalg.norm(x_cpu)\n",
    "#We can calculate it on GPU with CuPy in a similar way:\n",
    "\n",
    "x_gpu = cp.array([1, 2, 3])\n",
    "l2_gpu = cp.linalg.norm(x_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7671623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
