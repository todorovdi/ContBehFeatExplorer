{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%history -g -f ~/jupyter_hist.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%history -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Brain object (BrainObj) : complete tutorial\n",
    "===========================================\n",
    "\n",
    "This example illustrate the main functionalities and inputs of the brain\n",
    "object i.e :\n",
    "\n",
    "  * Use included MNI brain template\n",
    "  * Select the hemisphere ('both', 'left', 'right')\n",
    "  * Use a translucent or opaque brain\n",
    "  * Project source's activity on the surface of the brain\n",
    "  * Parcellize the brain and send data to selected parcellates\n",
    "  * Add fMRI activation and MEG inverse solution\n",
    "\n",
    "Data for fMRI activations and MEG inverse solutoin comes from the PySurfer\n",
    "software (https://github.com/nipy/PySurfer/). Parcellation file comes from\n",
    "MNE-Python (https://github.com/mne-tools/mne-python).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from visbrain.objects import BrainObj, ColorbarObj, SceneObj, SourceObj\n",
    "from visbrain.io import download_file, read_stc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scene creation\n",
    "##############################################################################\n",
    " The SceneObj is Matplotlib subplot like in which, you can add visbrain's\n",
    " objects. We first create the scene with a black background, a fixed size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scene creation\n",
    "sc = SceneObj(bgcolor='black', size=(1400, 1000))\n",
    "# Colorbar default arguments. See `visbrain.objects.ColorbarObj`\n",
    "CBAR_STATE = dict(cbtxtsz=12, txtsz=10., width=.1, cbtxtsh=3.,\n",
    "                  rect=(-.3, -2., 1., 4.))\n",
    "KW = dict(title_size=14., zoom=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>The BrainObj can interact with sources (SourceObj). For example, if the\n",
    "    source object represent intracranial data (e.g iEEG) those sources can\n",
    "    be projected on the surface of the brain. This is an important feature\n",
    "    because intracranial implantations is usually subject dependant and the\n",
    "    projection is a good way to plot results across subjects. To illustrate\n",
    "    this feature, we provide a set of intracranial MNI coordinates.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download iEEG coordinates and define some random data\n",
    "mat = np.load(download_file('xyz_sample.npz', astype='example_data'))\n",
    "xyz, subjects = mat['xyz'], mat['subjects']\n",
    "data = np.random.rand(xyz.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic brain using MNI template\n",
    "##############################################################################\n",
    " By default, Visbrain include several MNI brain templates (B1, B3, B3,\n",
    " inflated, white and shere).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translucent inflated BrainObj with both hemispheres displayed\n",
    "b_obj_fs = BrainObj('inflated', translucent=True, hemisphere='both')\n",
    "# Add the brain to the scene. Note that `row_span` means that the plot will\n",
    "# occupy two rows (row 0 and 1)\n",
    "sc.add_to_subplot(b_obj_fs, row=0, col=0, row_span=2,\n",
    "                  title='Translucent inflated brain template', **KW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the left or the right hemisphere\n",
    "##############################################################################\n",
    " You can use the `hemisphere` input to select either the 'left', 'right' or\n",
    " 'both' hemispheres.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opaque left hemispehre of the white matter\n",
    "b_obj_lw = BrainObj('white', hemisphere='left', translucent=False)\n",
    "sc.add_to_subplot(b_obj_lw, row=0, col=1, rotate='right',\n",
    "                  title='Left hemisphere', **KW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projection iEEG data on the surface of the brain\n",
    "##############################################################################\n",
    " As explain above, we define a source object and project the source's activity\n",
    " on the surface of the brain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, define a brain object used for the projection\n",
    "b_obj_proj = BrainObj('B3', hemisphere='both', translucent=False)\n",
    "# Define the source object\n",
    "s_obj = SourceObj('iEEG', xyz, data=data, cmap='inferno')\n",
    "# Just for fun, color sources according to the data :)\n",
    "s_obj.color_sources(data=data)\n",
    "# Project source's activity\n",
    "s_obj.project_sources(b_obj_proj, cmap='plasma')\n",
    "# Finally, add the source and brain objects to the subplot\n",
    "sc.add_to_subplot(s_obj, row=0, col=2, title='Project iEEG data', **KW)\n",
    "sc.add_to_subplot(b_obj_proj, row=0, col=2, rotate='left', use_this_cam=True)\n",
    "# Finally, add the colorbar :\n",
    "cb_proj = ColorbarObj(s_obj, cblabel='Projection of niEEG data', **CBAR_STATE)\n",
    "sc.add_to_subplot(cb_proj, row=0, col=3, width_max=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>Here, we used s_obj.project_sources(b_obj) to project source's activity\n",
    "    on the surface. We could also have used to b_obj.project_sources(s_obj)</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parcellize the brain\n",
    "##############################################################################\n",
    " Here, we parcellize the brain (using all parcellated included in the file).\n",
    " Note that those parcellates files comes from MNE-python.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the annotation file of the left hemisphere lh.aparc.a2009s.annot\n",
    "path_to_file1 = download_file('lh.aparc.a2009s.annot', astype='example_data')\n",
    "# Define the brain object (now you should know how to do it)\n",
    "b_obj_parl = BrainObj('inflated', hemisphere='left', translucent=False)\n",
    "# Print parcellates included in the file\n",
    "# print(b_obj_parl.get_parcellates(path_to_file1))\n",
    "# Finally, parcellize the brain and add the brain to the scene\n",
    "b_obj_parl.parcellize(path_to_file1)\n",
    "sc.add_to_subplot(b_obj_parl, row=1, col=1, rotate='left',\n",
    "                  title='Parcellize using the Desikan Atlas', **KW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>Those annotations files from MNE-python are only compatibles with the\n",
    "    inflated, white and sphere templates</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send data to parcellates\n",
    "##############################################################################\n",
    " Again, we download an annotation file, but this time for the right hemisphere\n",
    " The difference with the example above, is that this time we send some data\n",
    " to some specific parcellates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the annotation file of the right hemisphere rh.aparc.annot\n",
    "path_to_file2 = download_file('rh.aparc.annot', astype='example_data')\n",
    "# Define the brain object (again... I know, this is redundant)\n",
    "b_obj_parr = BrainObj('inflated', hemisphere='right', translucent=False)\n",
    "# Print parcellates included in the file\n",
    "# print(b_obj_parr.get_parcellates(path_to_file2))\n",
    "# From the list of printed parcellates, we only select a few of them\n",
    "select_par = ['paracentral', 'precentral', 'fusiform', 'postcentral',\n",
    "              'superiorparietal', 'superiortemporal', 'inferiorparietal',\n",
    "              'inferiortemporal']\n",
    "# Now we define some data for each parcellates (one value per pacellate)\n",
    "data_par = [10., .1, 5., 7., 11., 8., 4., 6.]\n",
    "# Parcellize the brain with the selected parcellates. The data range is\n",
    "# between [.1, 11.]. Then, we use `vmin` and `vmax` to specify that we want\n",
    "# every parcellates under vmin to be gray and every parcellates over vmax\n",
    "# darkred\n",
    "b_obj_parr.parcellize(path_to_file2, select=select_par, hemisphere='right',\n",
    "                      cmap='viridis', data=data_par, clim=[.1, 11.], vmin=1.,\n",
    "                      vmax=10, under='gray', over='darkred')\n",
    "# Add the brain object to the scene\n",
    "sc.add_to_subplot(b_obj_parr, row=1, col=2, rotate='right',\n",
    "                  title='Send data to Desikan-Killiany parcellates', **KW)\n",
    "# Get the colorbar of the brain object and add it to the scene\n",
    "cb_parr = ColorbarObj(b_obj_parr, cblabel='Data to parcellates', **CBAR_STATE)\n",
    "sc.add_to_subplot(cb_parr, row=1, col=3, width_max=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom brain template\n",
    "##############################################################################\n",
    " All of the examples above use MNI brain templates that are included inside\n",
    " visbrain. But you can define your own brain template using vertices and faces\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the vertices, faces and normals\n",
    "mat = np.load(download_file('Custom.npz', astype='example_data'))\n",
    "vert, faces, norms = mat['vertices'], mat['faces'], mat['normals']\n",
    "# By default, vertices are in millimeters so we multiply by 1000.\n",
    "vert *= 1000.\n",
    "# If your template represent a brain with both hemispheres, you can use the\n",
    "# `lr_index` to specify which vertices belong to the left or the right\n",
    "# hemisphere. Basically, `lr_index` is a boolean vector of shape (n_vertices,)\n",
    "# where True reflect locatino of the left hemisphere and False, the right\n",
    "# hemisphere\n",
    "lr_index = vert[0, :] <= 0.\n",
    "# Create the brain object and add it to the scene (this time it's a bit\n",
    "# different)\n",
    "b_obj_custom = BrainObj('Custom', vertices=vert, faces=faces,\n",
    "                        normals=norms, translucent=False)\n",
    "sc.add_to_subplot(b_obj_custom, row=2, col=0, title='Use a custom template',\n",
    "                  rotate='left', **KW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>If you doesn't have the normals, it's not a big deal because if no\n",
    "    normals are provided, normals are going to be computed but it's a bit\n",
    "    slower. Then, you can save your template using `BrainObj.save`. This can\n",
    "    be convenient to reload your template later.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fMRI activation\n",
    "##############################################################################\n",
    " Add fMRI activations (included in a nii.gz file) to the surface. The provided\n",
    " file comes from MNE-python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the lh.sig.nii.gz file\n",
    "file = download_file('lh.sig.nii.gz', astype='example_data')\n",
    "# Define the [...] you know\n",
    "b_obj_fmri = BrainObj('inflated', translucent=False, sulcus=True)\n",
    "# Add fMRI activation and hide every activation that is under 5.\n",
    "b_obj_fmri.add_activation(file=file, clim=(5., 20.), hide_under=5,\n",
    "                          cmap='viridis', hemisphere='left')\n",
    "sc.add_to_subplot(b_obj_fmri, row=2, col=1, title='Add fMRI activation',\n",
    "                  rotate='left', **KW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MEG inverse solution\n",
    "##############################################################################\n",
    " Finally, plot MEG inverse solution. The provided file comes from MNE-python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dowload meg_source_estimate-rh.stc file and load the data\n",
    "file = read_stc(download_file('meg_source_estimate-rh.stc',\n",
    "                              astype='example_data'))\n",
    "# Get the data of index 2 and the vertices\n",
    "data = file['data'][:, 2]\n",
    "vertices = file['vertices']\n",
    "# You know...\n",
    "b_obj_meg = BrainObj('inflated', translucent=False, hemisphere='right',\n",
    "                     sulcus=True)\n",
    "# Add MEG data to the surface and hide every values under 5.\n",
    "b_obj_meg.add_activation(data=data, vertices=vertices, hemisphere='right',\n",
    "                         smoothing_steps=21, clim=(5., 17.), hide_under=5.,\n",
    "                         cmap='plasma')\n",
    "# Add the brain and the colorbar object to the scene\n",
    "sc.add_to_subplot(b_obj_meg, row=2, col=2, title='MEG inverse solution',\n",
    "                  rotate='right', **KW)\n",
    "cb_parr = ColorbarObj(b_obj_meg, cblabel='MEG data', **CBAR_STATE)\n",
    "sc.add_to_subplot(cb_parr, row=2, col=3, width_max=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Fun\" stuff\n",
    "##############################################################################\n",
    " You can link 3D rotations of subplots which means that if you rotate one\n",
    " brain, the other linked object inherit from the same rotations. Finally, you\n",
    " can take a screenshot of the scene, without the need to open the window.\n",
    " This can be particulary convenient when scenes are included inside loops to\n",
    " automatize figure generation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG['MPL_RENDER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link the rotation of subplots (row=0, col=1) and (row=1, col=2)\n",
    "# sc.link((0, 1), (1, 2))\n",
    "# Screenshot of the scene\n",
    "# sc.screenshot('ex_brain_obj.png', transparent=True)\n",
    "\n",
    "sc.preview()\n",
    "#/home/demitau/osccode/data_proc/\n",
    "#sc.screenshot(saveas='/home/demitau/visbrain.png', print_size=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This hack is needed when running visbrain in jupyter\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_render import RenderingImShow \n",
    "\n",
    "render_result = sc.render()\n",
    "render_result = np.flip(render_result, axis = 0)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1) \n",
    "# |  The `user_render()` method is expected to return an image with\n",
    "# |  size `self.size`, representing area `self.extent`, where `extent`\n",
    "# |  describes a rectangle `(x0, x1, y0, y1)`\n",
    "# size is just size of the image (in pixels)\n",
    "extent = (0, 7, 0, 5) \n",
    "p = RenderingImShow( ax, extent = extent, render_callback = (lambda size, extent: render_result))\n",
    "\n",
    "# here I delete axis and colorbar, which somehow get added while applying mpl_render\n",
    "plt.axis('off') \n",
    "plt.delaxes(fig.axes[1])\n",
    "\n",
    "# save the figure in high resolution now possible\n",
    "fig.savefig(\"/home/demitau/osccode/data_proc/output/visbrain.png\", dpi=300) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(fig.savefig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(RenderingImShow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from visbrain.objects import SourceObj  # Import a source object\n",
    "\n",
    "# Define 100 random 3D (x, y, z) coordinates :\n",
    "xyz = np.random.rand(100, 3)\n",
    "\n",
    "# Define a source object :\n",
    "s_obj = SourceObj('obj_name', xyz, color='green', symbol='square',\n",
    "                  edge_color='white')\n",
    "\n",
    "# Object preview with a black background:\n",
    "s_obj.preview(bgcolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from visbrain.objects import BrainObj, SceneObj, SourceObj\n",
    "\n",
    "# Define a source and a brain objects :\n",
    "b_obj_1 = BrainObj('white', translucent=False)\n",
    "b_obj_2 = BrainObj('B1')\n",
    "s_obj = SourceObj('my_sources', 50 * np.random.uniform(-1, 1, (100, 3)))\n",
    "\n",
    "# Define a scene with a black background:\n",
    "sc = SceneObj(bgcolor='black')\n",
    "\n",
    "# Add the first brain object to the scene :\n",
    "sc.add_to_subplot(b_obj_1, row=0, col=0)\n",
    "\n",
    "# Add the source and the first brain object to same subplot :\n",
    "sc.add_to_subplot(b_obj_2, row=0, col=1)\n",
    "sc.add_to_subplot(s_obj, row=0, col=1)\n",
    "\n",
    "# Finally, display the scene :\n",
    "sc.preview()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
